{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "NcDhtxLCV8Tw",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, LayerNormalization, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from numpy.random import seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 426
    },
    "id": "vI12F-E9V8T1",
    "outputId": "869138a1-ef3d-4c37-86c8-e408129de90a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "Xl = pd.read_csv('Xl.csv',header=None)\n",
    "Xs = pd.read_csv('Xs.csv',header=None)\n",
    "R = pd.read_csv('y.csv',header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_agg=R.iloc[::-1].rolling(window=12).sum().iloc[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "Psf8guRAV8T1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "t_train_start = list(range(46*12))\n",
    "t_train_end =[x+120 for x in t_train_start]\n",
    "t_val_start= [x for x in t_train_end]\n",
    "t_val_end = [x+60 for x in t_val_start]\n",
    "t_test_start = [x for x in t_val_end]\n",
    "t_test_end = [x for x in t_test_start]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(552,)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(t_test_end) #model needed to be retrained every month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "731"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_test_end[551]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_4972 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 0.3703 - val_loss: 0.0443\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0481 - val_loss: 0.0373\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0378 - val_loss: 0.0376\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0255 - val_loss: 0.0379\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0184 - val_loss: 0.0376\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb23aeef8b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_4973 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.0814 - val_loss: 0.0388\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0264 - val_loss: 0.0357\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0119 - val_loss: 0.0384\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0113 - val_loss: 0.0449\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0099 - val_loss: 0.0516\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb23a9b1310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_4974 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.0327 - val_loss: 0.0448\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0179 - val_loss: 0.0413\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0139 - val_loss: 0.0314\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0119 - val_loss: 0.0331\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0098 - val_loss: 0.0337\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0088 - val_loss: 0.0354\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb25729fdc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_4975 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.1890 - val_loss: 0.0390\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0196 - val_loss: 0.0354\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0214 - val_loss: 0.0349\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0183 - val_loss: 0.0344\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0140 - val_loss: 0.0349\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0096 - val_loss: 0.0358\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0084 - val_loss: 0.0370\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb25a582790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_4976 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.2491 - val_loss: 0.0375\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0646 - val_loss: 0.0314\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0258 - val_loss: 0.0317\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0199 - val_loss: 0.0320\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0167 - val_loss: 0.0323\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb292cdf0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_4977 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.0419 - val_loss: 0.0557\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0310 - val_loss: 0.0490\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0158 - val_loss: 0.0424\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0158 - val_loss: 0.0437\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0103 - val_loss: 0.0465\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0124 - val_loss: 0.0451\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb25a791700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_4978 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.0299 - val_loss: 0.0303\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0130 - val_loss: 0.0312\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0122 - val_loss: 0.0329\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0107 - val_loss: 0.0337\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb27795c790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_4979 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.1328 - val_loss: 0.0305\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0275 - val_loss: 0.0309\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0218 - val_loss: 0.0313\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0229 - val_loss: 0.0314\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb272bfad30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_4980 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.1038 - val_loss: 0.0325\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0155 - val_loss: 0.0324\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0165 - val_loss: 0.0329\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0126 - val_loss: 0.0338\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0104 - val_loss: 0.0351\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3237c0670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_4981 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.0862 - val_loss: 0.0714\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0471 - val_loss: 0.0601\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0189 - val_loss: 0.0544\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0150 - val_loss: 0.0498\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0128 - val_loss: 0.0476\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0127 - val_loss: 0.0451\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0113 - val_loss: 0.0434\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0109 - val_loss: 0.0421\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0101 - val_loss: 0.0411\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0117 - val_loss: 0.0395\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0103 - val_loss: 0.0377\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0112 - val_loss: 0.0360\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0095 - val_loss: 0.0348\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0091 - val_loss: 0.0348\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 0.0349\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0088 - val_loss: 0.0349\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb32b165550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_4982 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.0305 - val_loss: 0.0348\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0223 - val_loss: 0.0341\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0160 - val_loss: 0.0340\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0129 - val_loss: 0.0338\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0112 - val_loss: 0.0335\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0097 - val_loss: 0.0340\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0080 - val_loss: 0.0329\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0088 - val_loss: 0.0318\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0084 - val_loss: 0.0318\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0077 - val_loss: 0.0316\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0062 - val_loss: 0.0312\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0059 - val_loss: 0.0312\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0059 - val_loss: 0.0314\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0051 - val_loss: 0.0314\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0051 - val_loss: 0.0315\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2c294db80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_4983 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.0702 - val_loss: 0.0319\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0203 - val_loss: 0.0375\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0171 - val_loss: 0.0358\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0155 - val_loss: 0.0300\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0118 - val_loss: 0.0300\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0098 - val_loss: 0.0324\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0087 - val_loss: 0.0334\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0080 - val_loss: 0.0342\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb270dbdb80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_4984 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.0784 - val_loss: 0.0359\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0155 - val_loss: 0.0349\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0149 - val_loss: 0.0361\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0134 - val_loss: 0.0364\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0108 - val_loss: 0.0360\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2be1e9670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_4985 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.4053 - val_loss: 0.2570\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0679 - val_loss: 0.1209\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0240 - val_loss: 0.0519\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0271 - val_loss: 0.0351\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0261 - val_loss: 0.0368\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0198 - val_loss: 0.0380\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0148 - val_loss: 0.0403\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2bbce3160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_4986 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 0.2505 - val_loss: 0.0978\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0784 - val_loss: 0.0713\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0362 - val_loss: 0.0566\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0243 - val_loss: 0.0487\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0160 - val_loss: 0.0466\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0125 - val_loss: 0.0465\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0113 - val_loss: 0.0456\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0114 - val_loss: 0.0457\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0121 - val_loss: 0.0450\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0114 - val_loss: 0.0445\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0102 - val_loss: 0.0444\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0099 - val_loss: 0.0440\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0093 - val_loss: 0.0438\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0084 - val_loss: 0.0445\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0097 - val_loss: 0.0448\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0078 - val_loss: 0.0429\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0083 - val_loss: 0.0412\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0082 - val_loss: 0.0405\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0076 - val_loss: 0.0400\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0076 - val_loss: 0.0391\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0071 - val_loss: 0.0390\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0066 - val_loss: 0.0387\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0071 - val_loss: 0.0384\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0066 - val_loss: 0.0382\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0066 - val_loss: 0.0376\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0059 - val_loss: 0.0373\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0060 - val_loss: 0.0375\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0053 - val_loss: 0.0376\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0050 - val_loss: 0.0380\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2b1b654c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_4987 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 0.0436 - val_loss: 0.0470\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0196 - val_loss: 0.0465\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0139 - val_loss: 0.0441\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0142 - val_loss: 0.0414\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0110 - val_loss: 0.0392\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0113 - val_loss: 0.0386\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0098 - val_loss: 0.0385\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0104 - val_loss: 0.0384\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0100 - val_loss: 0.0381\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0088 - val_loss: 0.0384\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0084 - val_loss: 0.0399\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0072 - val_loss: 0.0415\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2a9986430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_4988 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.0242 - val_loss: 0.0383\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0180 - val_loss: 0.0410\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0142 - val_loss: 0.0367\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0137 - val_loss: 0.0349\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0110 - val_loss: 0.0371\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0105 - val_loss: 0.0373\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0099 - val_loss: 0.0368\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb292a0e940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_4989 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.0240 - val_loss: 0.0378\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0183 - val_loss: 0.0369\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0164 - val_loss: 0.0362\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0116 - val_loss: 0.0353\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0110 - val_loss: 0.0357\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0095 - val_loss: 0.0349\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0091 - val_loss: 0.0343\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0087 - val_loss: 0.0337\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0078 - val_loss: 0.0335\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0077 - val_loss: 0.0334\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0066 - val_loss: 0.0330\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0056 - val_loss: 0.0325\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0057 - val_loss: 0.0322\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0053 - val_loss: 0.0318\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0051 - val_loss: 0.0314\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0049 - val_loss: 0.0314\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0044 - val_loss: 0.0314\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0037 - val_loss: 0.0310\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0063 - val_loss: 0.0307\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0045 - val_loss: 0.0305\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0054 - val_loss: 0.0299\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0039 - val_loss: 0.0294\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0034 - val_loss: 0.0289\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0036 - val_loss: 0.0285\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0040 - val_loss: 0.0286\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0044 - val_loss: 0.0300\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0034 - val_loss: 0.0334\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb27d7d00d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_4990 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.1502 - val_loss: 0.0427\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0379 - val_loss: 0.0367\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0227 - val_loss: 0.0385\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0148 - val_loss: 0.0393\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0244 - val_loss: 0.0493\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb28fb92ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_4991 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.1014 - val_loss: 0.0353\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0355 - val_loss: 0.0328\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0225 - val_loss: 0.0299\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0179 - val_loss: 0.0305\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0194 - val_loss: 0.0333\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0117 - val_loss: 0.0327\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb28f438160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_4992 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.2336 - val_loss: 0.0368\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0258 - val_loss: 0.0372\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0282 - val_loss: 0.0384\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0201 - val_loss: 0.0387\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb28a5bb430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_4993 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.0608 - val_loss: 0.0407\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0194 - val_loss: 0.0333\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0176 - val_loss: 0.0309\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0147 - val_loss: 0.0297\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0121 - val_loss: 0.0311\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 0.0325\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0085 - val_loss: 0.0328\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2a2754c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_4994 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.1662 - val_loss: 0.0284\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0752 - val_loss: 0.0229\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0283 - val_loss: 0.0240\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0181 - val_loss: 0.0257\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0150 - val_loss: 0.0286\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb29a6e6d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_4995 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.0496 - val_loss: 0.0327\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0265 - val_loss: 0.0353\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0146 - val_loss: 0.0343\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0117 - val_loss: 0.0323\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0108 - val_loss: 0.0323\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 0.0327\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0086 - val_loss: 0.0341\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0076 - val_loss: 0.0354\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2c2a9f280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_4996 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.1420 - val_loss: 0.0367\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0340 - val_loss: 0.0302\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0140 - val_loss: 0.0335\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0111 - val_loss: 0.0358\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0100 - val_loss: 0.0348\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2d785f040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_4997 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.0214 - val_loss: 0.0364\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0150 - val_loss: 0.0320\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0132 - val_loss: 0.0312\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0124 - val_loss: 0.0316\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0114 - val_loss: 0.0312\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0108 - val_loss: 0.0307\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0092 - val_loss: 0.0307\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0085 - val_loss: 0.0308\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0094 - val_loss: 0.0314\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2c55603a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_4998 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.1092 - val_loss: 0.0379\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0225 - val_loss: 0.0387\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0133 - val_loss: 0.0358\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0110 - val_loss: 0.0328\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0117 - val_loss: 0.0313\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0098 - val_loss: 0.0311\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0098 - val_loss: 0.0313\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0084 - val_loss: 0.0314\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0077 - val_loss: 0.0314\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2d4c29820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_4999 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 0.0451 - val_loss: 0.0325\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0192 - val_loss: 0.0351\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0162 - val_loss: 0.0360\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0149 - val_loss: 0.0351\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2e9b4df70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5000 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.0501 - val_loss: 0.0357\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0374 - val_loss: 0.0410\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0154 - val_loss: 0.0465\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0101 - val_loss: 0.0539\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb35df531f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5001 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 0.0643 - val_loss: 0.0412\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0284 - val_loss: 0.0313\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0149 - val_loss: 0.0325\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0143 - val_loss: 0.0350\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0131 - val_loss: 0.0362\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb314077670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5002 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.0635 - val_loss: 0.0359\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0218 - val_loss: 0.0343\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0179 - val_loss: 0.0317\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0132 - val_loss: 0.0286\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0098 - val_loss: 0.0270\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 0.0287\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0088 - val_loss: 0.0309\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0072 - val_loss: 0.0327\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb35e4959d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5003 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 538ms/step - loss: 0.3836 - val_loss: 0.0422\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0936 - val_loss: 0.0375\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0267 - val_loss: 0.0354\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0177 - val_loss: 0.0347\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0161 - val_loss: 0.0345\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0174 - val_loss: 0.0343\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0151 - val_loss: 0.0342\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0151 - val_loss: 0.0343\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0143 - val_loss: 0.0351\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0140 - val_loss: 0.0354\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3795c7c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5004 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.0836 - val_loss: 0.0370\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0231 - val_loss: 0.0498\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0166 - val_loss: 0.0468\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0128 - val_loss: 0.0417\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3a8943550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5005 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.0557 - val_loss: 0.0856\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0763 - val_loss: 0.0676\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0168 - val_loss: 0.0668\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0125 - val_loss: 0.0674\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0105 - val_loss: 0.0623\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0111 - val_loss: 0.0563\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0095 - val_loss: 0.0530\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0104 - val_loss: 0.0494\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0087 - val_loss: 0.0474\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0081 - val_loss: 0.0460\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0075 - val_loss: 0.0451\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0077 - val_loss: 0.0444\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0069 - val_loss: 0.0436\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0057 - val_loss: 0.0432\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0052 - val_loss: 0.0419\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0045 - val_loss: 0.0409\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0048 - val_loss: 0.0411\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0043 - val_loss: 0.0417\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0037 - val_loss: 0.0417\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb35e4ef3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5006 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.1046 - val_loss: 0.0522\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0259 - val_loss: 0.0560\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0175 - val_loss: 0.0336\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0077 - val_loss: 0.0306\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0084 - val_loss: 0.0301\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 0.0305\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0079 - val_loss: 0.0316\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0084 - val_loss: 0.0375\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3138c4c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5007 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.2281 - val_loss: 0.0357\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0279 - val_loss: 0.0361\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0214 - val_loss: 0.0364\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0176 - val_loss: 0.0365\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2eeb09c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5008 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.1734 - val_loss: 0.0453\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0185 - val_loss: 0.0370\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0189 - val_loss: 0.0307\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0112 - val_loss: 0.0363\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0074 - val_loss: 0.0474\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0073 - val_loss: 0.0564\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2db4b5940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5009 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.2811 - val_loss: 0.3130\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0313 - val_loss: 0.0469\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0418 - val_loss: 0.0247\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0285 - val_loss: 0.0857\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0164 - val_loss: 0.1504\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0122 - val_loss: 0.1647\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2fb21a550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5010 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.5043 - val_loss: 0.0534\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0882 - val_loss: 0.0355\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0290 - val_loss: 0.0326\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0163 - val_loss: 0.0364\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0099 - val_loss: 0.0397\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0074 - val_loss: 0.0418\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2c55aeb80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5011 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 1.2721 - val_loss: 0.1219\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1538 - val_loss: 0.0463\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0380 - val_loss: 0.0316\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0172 - val_loss: 0.0341\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0139 - val_loss: 0.0351\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0148 - val_loss: 0.0355\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb373b9d430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5012 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.0492 - val_loss: 0.0324\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0166 - val_loss: 0.0317\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0119 - val_loss: 0.0307\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0085 - val_loss: 0.0304\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0060 - val_loss: 0.0299\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0067 - val_loss: 0.0299\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0067 - val_loss: 0.0302\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0055 - val_loss: 0.0303\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0053 - val_loss: 0.0304\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2a24f9a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5013 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 1.8757 - val_loss: 0.4826\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1697 - val_loss: 0.2622\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0380 - val_loss: 0.1277\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0243 - val_loss: 0.0606\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0217 - val_loss: 0.0472\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0184 - val_loss: 0.0425\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0151 - val_loss: 0.0413\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0128 - val_loss: 0.0398\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0118 - val_loss: 0.0375\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0122 - val_loss: 0.0352\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0093 - val_loss: 0.0336\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0090 - val_loss: 0.0323\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0077 - val_loss: 0.0317\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0078 - val_loss: 0.0312\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0064 - val_loss: 0.0302\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0061 - val_loss: 0.0292\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0053 - val_loss: 0.0282\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0051 - val_loss: 0.0274\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0054 - val_loss: 0.0268\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0049 - val_loss: 0.0263\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0046 - val_loss: 0.0261\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0047 - val_loss: 0.0260\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0050 - val_loss: 0.0260\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0043 - val_loss: 0.0259\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0050 - val_loss: 0.0258\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0044 - val_loss: 0.0256\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0045 - val_loss: 0.0254\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0041 - val_loss: 0.0253\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0039 - val_loss: 0.0251\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0050 - val_loss: 0.0250\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0043 - val_loss: 0.0248\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0037 - val_loss: 0.0247\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0036 - val_loss: 0.0246\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0035 - val_loss: 0.0245\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0036 - val_loss: 0.0245\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0035 - val_loss: 0.0244\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0031 - val_loss: 0.0242\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0034 - val_loss: 0.0241\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0031 - val_loss: 0.0241\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0042 - val_loss: 0.0241\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0042 - val_loss: 0.0242\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0035 - val_loss: 0.0245\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0036 - val_loss: 0.0250\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb28af03ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5014 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.0565 - val_loss: 0.0355\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0216 - val_loss: 0.0320\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0095 - val_loss: 0.0346\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0101 - val_loss: 0.0367\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0074 - val_loss: 0.0381\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb28f772670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5015 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.0207 - val_loss: 0.0312\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0117 - val_loss: 0.0323\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0080 - val_loss: 0.0323\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 0.0304\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0055 - val_loss: 0.0308\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0062 - val_loss: 0.0317\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0053 - val_loss: 0.0324\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb28c3594c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5016 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.0774 - val_loss: 0.0195\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0369 - val_loss: 0.0243\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0127 - val_loss: 0.0338\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0112 - val_loss: 0.0327\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb27dcd2ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5017 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.2668 - val_loss: 0.0400\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0844 - val_loss: 0.1196\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0225 - val_loss: 0.1304\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0150 - val_loss: 0.1242\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb281ab2280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5018 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 0.1981 - val_loss: 0.0355\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0455 - val_loss: 0.0334\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0147 - val_loss: 0.0311\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0155 - val_loss: 0.0300\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0140 - val_loss: 0.0282\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0069 - val_loss: 0.0276\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0052 - val_loss: 0.0280\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0058 - val_loss: 0.0287\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0052 - val_loss: 0.0291\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb285e9dd30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5019 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 0.0176 - val_loss: 0.0312\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0110 - val_loss: 0.0351\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0064 - val_loss: 0.0415\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0062 - val_loss: 0.0466\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb41c335820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5020 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.2591 - val_loss: 0.0393\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0266 - val_loss: 0.0324\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0236 - val_loss: 0.0321\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0238 - val_loss: 0.0310\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0139 - val_loss: 0.0310\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0082 - val_loss: 0.0321\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0069 - val_loss: 0.0332\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0071 - val_loss: 0.0339\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb4319a5790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5021 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.0514 - val_loss: 0.0421\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0286 - val_loss: 0.0380\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0119 - val_loss: 0.0312\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0062 - val_loss: 0.0289\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0055 - val_loss: 0.0285\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0065 - val_loss: 0.0283\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0043 - val_loss: 0.0274\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0045 - val_loss: 0.0266\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0045 - val_loss: 0.0261\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0043 - val_loss: 0.0262\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0043 - val_loss: 0.0262\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0039 - val_loss: 0.0262\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb297d1d3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5022 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.1160 - val_loss: 0.0383\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0274 - val_loss: 0.0334\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0152 - val_loss: 0.0302\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0105 - val_loss: 0.0297\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0085 - val_loss: 0.0326\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0075 - val_loss: 0.0339\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0066 - val_loss: 0.0350\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2bc380430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5023 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.0643 - val_loss: 0.0322\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0149 - val_loss: 0.0303\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0091 - val_loss: 0.0344\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0066 - val_loss: 0.0351\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0055 - val_loss: 0.0343\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb27e3f7700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5024 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 0.0555 - val_loss: 0.0308\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0203 - val_loss: 0.0326\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0088 - val_loss: 0.0350\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0072 - val_loss: 0.0336\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb26e9c29d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5025 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.2293 - val_loss: 0.0480\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0355 - val_loss: 0.0898\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0156 - val_loss: 0.1208\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0142 - val_loss: 0.1112\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb26d21f940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5026 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.0218 - val_loss: 0.0343\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0141 - val_loss: 0.0323\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0109 - val_loss: 0.0299\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0089 - val_loss: 0.0282\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0069 - val_loss: 0.0268\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0062 - val_loss: 0.0264\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0046 - val_loss: 0.0268\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0042 - val_loss: 0.0270\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0038 - val_loss: 0.0265\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb27b64d0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5027 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.2407 - val_loss: 0.0244\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0373 - val_loss: 0.0325\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0118 - val_loss: 0.0349\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0104 - val_loss: 0.0347\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb27ffa4670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5028 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.0578 - val_loss: 0.0298\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0154 - val_loss: 0.0269\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0087 - val_loss: 0.0258\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0085 - val_loss: 0.0263\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0063 - val_loss: 0.0265\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0056 - val_loss: 0.0269\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb257daf4c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5029 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 0.0654 - val_loss: 0.0303\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0278 - val_loss: 0.0279\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0191 - val_loss: 0.0241\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0118 - val_loss: 0.0237\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0116 - val_loss: 0.0253\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0077 - val_loss: 0.0279\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0067 - val_loss: 0.0300\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb258cb45e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5030 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.0221 - val_loss: 0.0255\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0135 - val_loss: 0.0261\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0116 - val_loss: 0.0289\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0082 - val_loss: 0.0327\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb25c6e5a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5031 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.0233 - val_loss: 0.0275\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0208 - val_loss: 0.0256\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0115 - val_loss: 0.0244\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0102 - val_loss: 0.0239\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0077 - val_loss: 0.0232\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0065 - val_loss: 0.0221\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0059 - val_loss: 0.0219\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0053 - val_loss: 0.0242\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0050 - val_loss: 0.0300\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0037 - val_loss: 0.0343\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb25f57d5e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5032 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.0419 - val_loss: 0.0322\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0208 - val_loss: 0.0284\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0149 - val_loss: 0.0296\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0105 - val_loss: 0.0303\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0079 - val_loss: 0.0315\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb247cee820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5033 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.0925 - val_loss: 0.0233\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0197 - val_loss: 0.0207\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0193 - val_loss: 0.0192\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0122 - val_loss: 0.0188\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0112 - val_loss: 0.0184\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0081 - val_loss: 0.0182\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0062 - val_loss: 0.0180\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0063 - val_loss: 0.0179\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0059 - val_loss: 0.0179\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0066 - val_loss: 0.0177\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0054 - val_loss: 0.0173\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0049 - val_loss: 0.0170\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0048 - val_loss: 0.0169\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0050 - val_loss: 0.0169\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0050 - val_loss: 0.0169\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0049 - val_loss: 0.0168\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0049 - val_loss: 0.0167\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0051 - val_loss: 0.0166\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0040 - val_loss: 0.0167\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0041 - val_loss: 0.0170\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0058 - val_loss: 0.0175\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3c33959d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5034 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.0294 - val_loss: 0.0172\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0138 - val_loss: 0.0162\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0091 - val_loss: 0.0182\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0064 - val_loss: 0.0186\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0072 - val_loss: 0.0193\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb31f325e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5035 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 0.0350 - val_loss: 0.0283\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0192 - val_loss: 0.0233\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0139 - val_loss: 0.0192\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0108 - val_loss: 0.0171\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0100 - val_loss: 0.0163\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0096 - val_loss: 0.0164\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0076 - val_loss: 0.0164\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0069 - val_loss: 0.0167\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb35ae8c8b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5036 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3489 - val_loss: 0.0131\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0608 - val_loss: 0.0144\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0332 - val_loss: 0.0147\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0164 - val_loss: 0.0182\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2964b9700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5037 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.1355 - val_loss: 0.0228\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0523 - val_loss: 0.0417\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0239 - val_loss: 0.0457\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0112 - val_loss: 0.0379\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb229612e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5038 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.0343 - val_loss: 0.0443\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0226 - val_loss: 0.0496\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0091 - val_loss: 0.0481\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0081 - val_loss: 0.0484\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb24633b3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5039 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 0.0437 - val_loss: 0.0133\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0231 - val_loss: 0.0129\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0128 - val_loss: 0.0132\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0116 - val_loss: 0.0133\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0095 - val_loss: 0.0137\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb24e500550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5040 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.0849 - val_loss: 0.0279\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0161 - val_loss: 0.0227\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0123 - val_loss: 0.0183\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0102 - val_loss: 0.0193\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 0.0206\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0091 - val_loss: 0.0213\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb24c943a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5041 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.0371 - val_loss: 0.0564\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0206 - val_loss: 0.0501\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0158 - val_loss: 0.0485\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0130 - val_loss: 0.0526\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0107 - val_loss: 0.0559\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0090 - val_loss: 0.0600\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb257813310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5042 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.0437 - val_loss: 0.0414\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0178 - val_loss: 0.0403\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0100 - val_loss: 0.0382\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0085 - val_loss: 0.0369\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0075 - val_loss: 0.0354\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0088 - val_loss: 0.0327\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0084 - val_loss: 0.0270\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0063 - val_loss: 0.0196\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0056 - val_loss: 0.0145\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0057 - val_loss: 0.0128\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0048 - val_loss: 0.0121\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0046 - val_loss: 0.0119\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0049 - val_loss: 0.0121\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0037 - val_loss: 0.0122\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0041 - val_loss: 0.0121\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb23468ae50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5043 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.1843 - val_loss: 0.0182\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0261 - val_loss: 0.0336\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0167 - val_loss: 0.0503\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0147 - val_loss: 0.0601\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb234fc2550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5044 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.0547 - val_loss: 0.0326\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0228 - val_loss: 0.0336\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0114 - val_loss: 0.0347\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0090 - val_loss: 0.0369\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb235951ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5045 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 0.0692 - val_loss: 0.0183\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0169 - val_loss: 0.0185\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0116 - val_loss: 0.0180\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0105 - val_loss: 0.0156\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0086 - val_loss: 0.0140\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0071 - val_loss: 0.0128\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0058 - val_loss: 0.0110\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0053 - val_loss: 0.0101\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0043 - val_loss: 0.0106\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0058 - val_loss: 0.0108\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2360c69d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5046 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.0819 - val_loss: 0.0207\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0234 - val_loss: 0.0384\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0180 - val_loss: 0.0422\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0144 - val_loss: 0.0398\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb236930af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5047 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.0972 - val_loss: 0.0371\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0598 - val_loss: 0.0491\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0244 - val_loss: 0.0542\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0135 - val_loss: 0.0516\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb236fc4310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5048 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.0365 - val_loss: 0.0271\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0223 - val_loss: 0.0308\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0187 - val_loss: 0.0339\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0141 - val_loss: 0.0353\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb237523d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5049 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.0951 - val_loss: 0.0233\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0165 - val_loss: 0.0332\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0137 - val_loss: 0.0450\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0123 - val_loss: 0.0489\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb238c153a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5050 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.0460 - val_loss: 0.0257\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0198 - val_loss: 0.0185\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0113 - val_loss: 0.0182\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0104 - val_loss: 0.0171\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0089 - val_loss: 0.0149\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0083 - val_loss: 0.0140\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0063 - val_loss: 0.0135\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0052 - val_loss: 0.0130\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0052 - val_loss: 0.0127\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0049 - val_loss: 0.0125\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0057 - val_loss: 0.0122\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0043 - val_loss: 0.0114\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0043 - val_loss: 0.0108\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0058 - val_loss: 0.0103\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0036 - val_loss: 0.0102\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0037 - val_loss: 0.0102\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0038 - val_loss: 0.0100\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0031 - val_loss: 0.0100\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0036 - val_loss: 0.0098\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0044 - val_loss: 0.0098\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0037 - val_loss: 0.0099\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0034 - val_loss: 0.0099\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb21a08f940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5051 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.1206 - val_loss: 0.0182\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0379 - val_loss: 0.0381\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0216 - val_loss: 0.0481\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0143 - val_loss: 0.0469\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb220265040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5052 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.1981 - val_loss: 0.0216\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0387 - val_loss: 0.0118\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0255 - val_loss: 0.0125\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0239 - val_loss: 0.0173\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0208 - val_loss: 0.0262\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb224435280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5053 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.0450 - val_loss: 0.0306\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0242 - val_loss: 0.0252\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0202 - val_loss: 0.0191\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0146 - val_loss: 0.0213\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0115 - val_loss: 0.0257\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0113 - val_loss: 0.0264\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2a557ddc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5054 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.0993 - val_loss: 0.0237\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0311 - val_loss: 0.0186\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0233 - val_loss: 0.0172\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0161 - val_loss: 0.0162\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0116 - val_loss: 0.0152\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0098 - val_loss: 0.0145\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0082 - val_loss: 0.0141\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0080 - val_loss: 0.0139\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0071 - val_loss: 0.0139\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0057 - val_loss: 0.0137\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0056 - val_loss: 0.0137\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0055 - val_loss: 0.0137\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0055 - val_loss: 0.0137\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0050 - val_loss: 0.0138\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0042 - val_loss: 0.0139\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb28fa28280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5055 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 122ms/step - loss: 0.0638 - val_loss: 0.0174\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0223 - val_loss: 0.0119\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0123 - val_loss: 0.0117\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0097 - val_loss: 0.0116\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0078 - val_loss: 0.0116\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0097 - val_loss: 0.0119\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0063 - val_loss: 0.0117\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2ae37e430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5056 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.0652 - val_loss: 0.0185\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0216 - val_loss: 0.0366\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0168 - val_loss: 0.0392\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0126 - val_loss: 0.0338\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2f4598dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5057 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.1161 - val_loss: 0.0213\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0470 - val_loss: 0.0133\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0271 - val_loss: 0.0105\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0175 - val_loss: 0.0127\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0126 - val_loss: 0.0169\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0112 - val_loss: 0.0164\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb30bb619d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5058 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.0446 - val_loss: 0.0179\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0465 - val_loss: 0.0297\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0188 - val_loss: 0.0272\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0123 - val_loss: 0.0245\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2c27894c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5059 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.1675 - val_loss: 0.0157\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0333 - val_loss: 0.0147\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0195 - val_loss: 0.0182\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0156 - val_loss: 0.0157\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0160 - val_loss: 0.0142\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0142 - val_loss: 0.0136\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0119 - val_loss: 0.0136\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0103 - val_loss: 0.0153\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0100 - val_loss: 0.0193\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3f1b94af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5060 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.1847 - val_loss: 0.0223\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0353 - val_loss: 0.0420\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0229 - val_loss: 0.0477\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0138 - val_loss: 0.0438\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2eb7455e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5061 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.0986 - val_loss: 0.0174\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0284 - val_loss: 0.0172\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0152 - val_loss: 0.0154\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0119 - val_loss: 0.0145\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0070 - val_loss: 0.0146\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0064 - val_loss: 0.0153\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0099 - val_loss: 0.0159\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2574868b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5062 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.2677 - val_loss: 0.0279\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0519 - val_loss: 0.0202\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0276 - val_loss: 0.0196\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0237 - val_loss: 0.0194\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0200 - val_loss: 0.0191\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0167 - val_loss: 0.0184\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0140 - val_loss: 0.0181\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0130 - val_loss: 0.0181\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0114 - val_loss: 0.0178\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0101 - val_loss: 0.0178\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 0.0182\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0115 - val_loss: 0.0186\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0069 - val_loss: 0.0187\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb23e9571f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5063 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.1974 - val_loss: 0.0923\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0663 - val_loss: 0.0607\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0206 - val_loss: 0.0375\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0138 - val_loss: 0.0249\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0107 - val_loss: 0.0175\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 0.0151\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0091 - val_loss: 0.0164\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0077 - val_loss: 0.0177\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0080 - val_loss: 0.0190\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb20e6e1c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5064 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.0768 - val_loss: 0.0257\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0245 - val_loss: 0.0218\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0170 - val_loss: 0.0205\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0150 - val_loss: 0.0199\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0149 - val_loss: 0.0194\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0113 - val_loss: 0.0192\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0100 - val_loss: 0.0188\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0089 - val_loss: 0.0185\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0084 - val_loss: 0.0185\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0079 - val_loss: 0.0194\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0067 - val_loss: 0.0198\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb236d62670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5065 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.1164 - val_loss: 0.0477\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0303 - val_loss: 0.0405\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0323 - val_loss: 0.0384\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0268 - val_loss: 0.0349\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0199 - val_loss: 0.0338\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0139 - val_loss: 0.0327\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0132 - val_loss: 0.0301\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0139 - val_loss: 0.0279\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0111 - val_loss: 0.0265\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0097 - val_loss: 0.0251\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0087 - val_loss: 0.0238\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0085 - val_loss: 0.0225\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0075 - val_loss: 0.0214\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0082 - val_loss: 0.0207\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0069 - val_loss: 0.0200\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0063 - val_loss: 0.0194\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0058 - val_loss: 0.0188\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0061 - val_loss: 0.0183\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0060 - val_loss: 0.0180\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0044 - val_loss: 0.0178\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0046 - val_loss: 0.0176\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.004 - 0s 15ms/step - loss: 0.0053 - val_loss: 0.0174\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0041 - val_loss: 0.0172\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0059 - val_loss: 0.0170\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0051 - val_loss: 0.0167\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0037 - val_loss: 0.0164\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0040 - val_loss: 0.0163\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0040 - val_loss: 0.0162\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0034 - val_loss: 0.0163\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0041 - val_loss: 0.0165\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0037 - val_loss: 0.0167\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb21125f790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5066 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.0711 - val_loss: 0.0242\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0320 - val_loss: 0.0199\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0231 - val_loss: 0.0158\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0214 - val_loss: 0.0173\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0181 - val_loss: 0.0220\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0122 - val_loss: 0.0242\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb25702dd30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5067 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3688 - val_loss: 0.0248\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0346 - val_loss: 0.0143\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0314 - val_loss: 0.0170\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0236 - val_loss: 0.0182\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0231 - val_loss: 0.0177\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb236ca71f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5068 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 0.1723 - val_loss: 0.0272\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0270 - val_loss: 0.0379\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0193 - val_loss: 0.0422\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0156 - val_loss: 0.0432\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2110454c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5069 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.2824 - val_loss: 0.0474\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0327 - val_loss: 0.0250\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0219 - val_loss: 0.0174\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0189 - val_loss: 0.0153\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0167 - val_loss: 0.0149\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0165 - val_loss: 0.0149\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0141 - val_loss: 0.0150\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0114 - val_loss: 0.0151\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb235cb1700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5070 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.1926 - val_loss: 0.0164\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0472 - val_loss: 0.0303\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0196 - val_loss: 0.0406\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0170 - val_loss: 0.0465\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1fda48d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5071 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 0.1024 - val_loss: 0.0317\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0312 - val_loss: 0.0598\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0208 - val_loss: 0.0524\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0175 - val_loss: 0.0419\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb20b0861f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5072 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.0263 - val_loss: 0.0456\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0218 - val_loss: 0.0339\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0129 - val_loss: 0.0240\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0081 - val_loss: 0.0224\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0084 - val_loss: 0.0220\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0076 - val_loss: 0.0216\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0094 - val_loss: 0.0216\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0071 - val_loss: 0.0214\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0095 - val_loss: 0.0213\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0055 - val_loss: 0.0193\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0060 - val_loss: 0.0176\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0054 - val_loss: 0.0171\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0060 - val_loss: 0.0161\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0048 - val_loss: 0.0161\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0043 - val_loss: 0.0160\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0055 - val_loss: 0.0161\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0039 - val_loss: 0.0184\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0041 - val_loss: 0.0189\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb240a1c4c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5073 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.2942 - val_loss: 0.0344\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0342 - val_loss: 0.0323\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0271 - val_loss: 0.0308\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0248 - val_loss: 0.0294\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0200 - val_loss: 0.0265\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0168 - val_loss: 0.0243\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0140 - val_loss: 0.0233\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0128 - val_loss: 0.0227\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0117 - val_loss: 0.0221\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0106 - val_loss: 0.0219\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0104 - val_loss: 0.0217\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0096 - val_loss: 0.0216\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 0.0216\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0083 - val_loss: 0.0216\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0084 - val_loss: 0.0216\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0080 - val_loss: 0.0214\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0077 - val_loss: 0.0212\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0075 - val_loss: 0.0209\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0067 - val_loss: 0.0205\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0092 - val_loss: 0.0202\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0064 - val_loss: 0.0202\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0064 - val_loss: 0.0203\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0066 - val_loss: 0.0204\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2020ec940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5074 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.0814 - val_loss: 0.0484\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0388 - val_loss: 0.0441\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0219 - val_loss: 0.0338\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0127 - val_loss: 0.0290\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0123 - val_loss: 0.0279\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0083 - val_loss: 0.0264\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0090 - val_loss: 0.0261\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0070 - val_loss: 0.0267\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0067 - val_loss: 0.0275\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0065 - val_loss: 0.0278\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb20bba1e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5075 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.1126 - val_loss: 0.0402\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0239 - val_loss: 0.0479\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0187 - val_loss: 0.0511\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0155 - val_loss: 0.0530\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb22601e1f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5076 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 0.0287 - val_loss: 0.0411\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0187 - val_loss: 0.0424\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0170 - val_loss: 0.0411\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0131 - val_loss: 0.0386\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0121 - val_loss: 0.0373\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0105 - val_loss: 0.0378\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0103 - val_loss: 0.0395\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0106 - val_loss: 0.0406\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1fbfc1280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5077 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.0621 - val_loss: 0.0489\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0278 - val_loss: 0.0511\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0223 - val_loss: 0.0546\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0190 - val_loss: 0.0612\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb209ffda60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5078 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.4036 - val_loss: 0.1371\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0605 - val_loss: 0.1203\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0270 - val_loss: 0.0876\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0150 - val_loss: 0.0680\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0155 - val_loss: 0.0587\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0106 - val_loss: 0.0553\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0090 - val_loss: 0.0531\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0084 - val_loss: 0.0542\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0090 - val_loss: 0.0555\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0087 - val_loss: 0.0569\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1ea3ad430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5079 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.1073 - val_loss: 0.0754\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0774 - val_loss: 0.0832\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0331 - val_loss: 0.0715\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0156 - val_loss: 0.0601\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0116 - val_loss: 0.0519\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0111 - val_loss: 0.0492\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0094 - val_loss: 0.0487\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0098 - val_loss: 0.0492\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0083 - val_loss: 0.0501\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0072 - val_loss: 0.0510\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1ec830310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5080 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.0818 - val_loss: 0.0334\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0225 - val_loss: 0.0296\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0142 - val_loss: 0.0271\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0121 - val_loss: 0.0257\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0111 - val_loss: 0.0246\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0102 - val_loss: 0.0234\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0082 - val_loss: 0.0228\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0087 - val_loss: 0.0226\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0080 - val_loss: 0.0221\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0072 - val_loss: 0.0221\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0071 - val_loss: 0.0218\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0063 - val_loss: 0.0220\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0062 - val_loss: 0.0222\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0062 - val_loss: 0.0223\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1ecb3e940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5081 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.1712 - val_loss: 0.0389\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0299 - val_loss: 0.0731\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0169 - val_loss: 0.1037\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0112 - val_loss: 0.1165\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1ecf08940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5082 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 203ms/step - loss: 0.1565 - val_loss: 0.0375\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0342 - val_loss: 0.0305\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0194 - val_loss: 0.0317\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0156 - val_loss: 0.0340\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0118 - val_loss: 0.0349\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1ed325820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5083 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.0407 - val_loss: 0.0454\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0231 - val_loss: 0.0415\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0109 - val_loss: 0.0330\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0106 - val_loss: 0.0337\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0096 - val_loss: 0.0361\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0072 - val_loss: 0.0375\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1ed6cd430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5084 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.0591 - val_loss: 0.0744\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0318 - val_loss: 0.0584\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0286 - val_loss: 0.0354\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0147 - val_loss: 0.0299\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0124 - val_loss: 0.0279\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0115 - val_loss: 0.0266\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0094 - val_loss: 0.0256\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0076 - val_loss: 0.0255\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0067 - val_loss: 0.0255\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0066 - val_loss: 0.0260\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0059 - val_loss: 0.0264\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1eeb3f280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5085 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.0433 - val_loss: 0.0518\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0160 - val_loss: 0.0364\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0107 - val_loss: 0.0308\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0098 - val_loss: 0.0296\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0092 - val_loss: 0.0268\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0083 - val_loss: 0.0261\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0069 - val_loss: 0.0263\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0075 - val_loss: 0.0266\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0073 - val_loss: 0.0263\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1eee77dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5086 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.2173 - val_loss: 0.0454\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0196 - val_loss: 0.0480\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0138 - val_loss: 0.0395\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0103 - val_loss: 0.0307\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0098 - val_loss: 0.0287\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0088 - val_loss: 0.0289\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0078 - val_loss: 0.0308\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0091 - val_loss: 0.0318\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1ef2ee310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5087 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.1312 - val_loss: 0.0681\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0332 - val_loss: 0.0420\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0173 - val_loss: 0.0275\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0188 - val_loss: 0.0249\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0146 - val_loss: 0.0254\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0100 - val_loss: 0.0260\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0095 - val_loss: 0.0264\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1ef6165e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5088 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.0814 - val_loss: 0.0478\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0726 - val_loss: 0.0459\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0185 - val_loss: 0.0344\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0172 - val_loss: 0.0352\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0118 - val_loss: 0.0343\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0087 - val_loss: 0.0326\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0079 - val_loss: 0.0310\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0101 - val_loss: 0.0294\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0086 - val_loss: 0.0275\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0071 - val_loss: 0.0250\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0066 - val_loss: 0.0232\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0067 - val_loss: 0.0225\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0054 - val_loss: 0.0222\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0061 - val_loss: 0.0218\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0056 - val_loss: 0.0215\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0046 - val_loss: 0.0218\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0054 - val_loss: 0.0217\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0046 - val_loss: 0.0218\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1f0a52940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5089 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 179ms/step - loss: 0.1306 - val_loss: 0.0258\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0578 - val_loss: 0.0253\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0225 - val_loss: 0.0261\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0176 - val_loss: 0.0251\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0156 - val_loss: 0.0274\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0136 - val_loss: 0.0327\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0123 - val_loss: 0.0421\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1f0e19b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5090 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.0452 - val_loss: 0.0341\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0147 - val_loss: 0.0535\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0123 - val_loss: 0.0602\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0126 - val_loss: 0.0545\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1f126f040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5091 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 0.0708 - val_loss: 0.0427\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0188 - val_loss: 0.0710\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0225 - val_loss: 0.0723\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0157 - val_loss: 0.0555\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1f159c3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5092 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.1069 - val_loss: 0.0307\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0235 - val_loss: 0.0357\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0161 - val_loss: 0.0355\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0131 - val_loss: 0.0359\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1f3094310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5093 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.0589 - val_loss: 0.0323\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0482 - val_loss: 0.0228\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0159 - val_loss: 0.0266\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0111 - val_loss: 0.0305\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0081 - val_loss: 0.0316\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1f4087790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5094 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.0685 - val_loss: 0.0410\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0249 - val_loss: 0.0297\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0145 - val_loss: 0.0265\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0130 - val_loss: 0.0279\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0097 - val_loss: 0.0314\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0076 - val_loss: 0.0336\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1f6d16310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5095 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.0475 - val_loss: 0.0644\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0200 - val_loss: 0.0519\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0131 - val_loss: 0.0393\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0110 - val_loss: 0.0343\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0111 - val_loss: 0.0332\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0107 - val_loss: 0.0331\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0092 - val_loss: 0.0331\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0083 - val_loss: 0.0327\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0080 - val_loss: 0.0329\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0074 - val_loss: 0.0326\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0071 - val_loss: 0.0322\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0062 - val_loss: 0.0314\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0060 - val_loss: 0.0302\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0060 - val_loss: 0.0291\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0050 - val_loss: 0.0284\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0050 - val_loss: 0.0281\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0049 - val_loss: 0.0282\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0057 - val_loss: 0.0279\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0041 - val_loss: 0.0275\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0045 - val_loss: 0.0274\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0049 - val_loss: 0.0274\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0046 - val_loss: 0.0276\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0041 - val_loss: 0.0278\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1f7b375e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5096 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.2824 - val_loss: 0.0444\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0418 - val_loss: 0.0303\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0224 - val_loss: 0.0679\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0238 - val_loss: 0.0805\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0193 - val_loss: 0.0776\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb220960790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5097 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 0.1952 - val_loss: 0.0350\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0369 - val_loss: 0.0436\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0211 - val_loss: 0.0448\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0159 - val_loss: 0.0506\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb22396fdc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5098 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.0561 - val_loss: 0.0453\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0183 - val_loss: 0.0409\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0139 - val_loss: 0.0392\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0103 - val_loss: 0.0397\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0094 - val_loss: 0.0416\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0090 - val_loss: 0.0411\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1d8ed3040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5099 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 0.2167 - val_loss: 0.0907\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0635 - val_loss: 0.0303\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0273 - val_loss: 0.0242\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0173 - val_loss: 0.0291\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0183 - val_loss: 0.0421\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0130 - val_loss: 0.0473\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1da938700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5100 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.1644 - val_loss: 0.0249\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0717 - val_loss: 0.0259\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0302 - val_loss: 0.0231\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0188 - val_loss: 0.0214\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0126 - val_loss: 0.0238\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0121 - val_loss: 0.0216\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0116 - val_loss: 0.0204\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0089 - val_loss: 0.0205\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0072 - val_loss: 0.0207\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0067 - val_loss: 0.0209\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1db933940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5101 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.3172 - val_loss: 0.0403\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0776 - val_loss: 0.0328\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0224 - val_loss: 0.0311\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0134 - val_loss: 0.0299\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0168 - val_loss: 0.0293\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0144 - val_loss: 0.0292\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0122 - val_loss: 0.0292\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0119 - val_loss: 0.0292\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0105 - val_loss: 0.0291\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0105 - val_loss: 0.0289\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0095 - val_loss: 0.0286\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0086 - val_loss: 0.0280\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0090 - val_loss: 0.0274\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0089 - val_loss: 0.0271\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0071 - val_loss: 0.0269\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0063 - val_loss: 0.0269\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0065 - val_loss: 0.0269\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0065 - val_loss: 0.0268\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0068 - val_loss: 0.0267\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0057 - val_loss: 0.0264\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0050 - val_loss: 0.0261\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0048 - val_loss: 0.0259\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0056 - val_loss: 0.0259\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0046 - val_loss: 0.0260\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0048 - val_loss: 0.0260\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1dcc12c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5102 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.9518 - val_loss: 0.0773\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.1415 - val_loss: 0.0407\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0320 - val_loss: 0.0250\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0245 - val_loss: 0.0380\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0280 - val_loss: 0.0461\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0279 - val_loss: 0.0492\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1df0ab040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5103 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.4717 - val_loss: 0.0557\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0636 - val_loss: 0.0327\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0169 - val_loss: 0.0253\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0196 - val_loss: 0.0258\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0230 - val_loss: 0.0301\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0218 - val_loss: 0.0365\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1e030b3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5104 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.0456 - val_loss: 0.0289\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0166 - val_loss: 0.0269\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0104 - val_loss: 0.0253\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0101 - val_loss: 0.0259\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0086 - val_loss: 0.0255\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0072 - val_loss: 0.0253\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1e10fb9d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5105 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.0966 - val_loss: 0.0321\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0264 - val_loss: 0.0256\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0171 - val_loss: 0.0275\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0128 - val_loss: 0.0269\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0092 - val_loss: 0.0268\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1e23d9d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5106 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.4846 - val_loss: 0.1147\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.1011 - val_loss: 0.0815\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0368 - val_loss: 0.0769\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0322 - val_loss: 0.0661\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0291 - val_loss: 0.0546\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0250 - val_loss: 0.0472\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0218 - val_loss: 0.0423\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0204 - val_loss: 0.0380\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0187 - val_loss: 0.0355\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0174 - val_loss: 0.0344\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0172 - val_loss: 0.0335\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0155 - val_loss: 0.0328\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0145 - val_loss: 0.0321\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0150 - val_loss: 0.0313\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0140 - val_loss: 0.0304\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0137 - val_loss: 0.0296\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0122 - val_loss: 0.0288\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0121 - val_loss: 0.0281\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0119 - val_loss: 0.0277\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0116 - val_loss: 0.0274\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0130 - val_loss: 0.0273\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0107 - val_loss: 0.0271\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0102 - val_loss: 0.0270\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0099 - val_loss: 0.0268\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0095 - val_loss: 0.0267\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0090 - val_loss: 0.0265\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0083 - val_loss: 0.0263\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0092 - val_loss: 0.0261\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0095 - val_loss: 0.0260\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0089 - val_loss: 0.0259\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0076 - val_loss: 0.0258\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0083 - val_loss: 0.0256\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0072 - val_loss: 0.0255\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0070 - val_loss: 0.0255\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0067 - val_loss: 0.0254\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0086 - val_loss: 0.0253\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0063 - val_loss: 0.0253\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0075 - val_loss: 0.0253\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0070 - val_loss: 0.0252\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0066 - val_loss: 0.0251\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0059 - val_loss: 0.0250\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0056 - val_loss: 0.0249\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0054 - val_loss: 0.0248\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0060 - val_loss: 0.0246\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0053 - val_loss: 0.0246\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0071 - val_loss: 0.0248\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0055 - val_loss: 0.0250\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb44df11430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5107 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 211ms/step - loss: 0.1128 - val_loss: 0.0415\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0190 - val_loss: 0.0321\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0135 - val_loss: 0.0299\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0094 - val_loss: 0.0298\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0088 - val_loss: 0.0301\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0083 - val_loss: 0.0307\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0064 - val_loss: 0.0312\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb23f560700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5108 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 0.0605 - val_loss: 0.0582\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0270 - val_loss: 0.0607\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0124 - val_loss: 0.0495\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0138 - val_loss: 0.0396\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0081 - val_loss: 0.0379\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0078 - val_loss: 0.0357\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0065 - val_loss: 0.0336\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0056 - val_loss: 0.0355\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0067 - val_loss: 0.0371\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0050 - val_loss: 0.0378\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb33dd683a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5109 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 0.4115 - val_loss: 0.0872\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0332 - val_loss: 0.0556\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0331 - val_loss: 0.0390\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0141 - val_loss: 0.0306\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0086 - val_loss: 0.0265\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0085 - val_loss: 0.0256\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0090 - val_loss: 0.0259\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0073 - val_loss: 0.0262\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0068 - val_loss: 0.0265\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb25c6e5ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5110 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 0.0574 - val_loss: 0.0512\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0246 - val_loss: 0.0497\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0248 - val_loss: 0.0464\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0138 - val_loss: 0.0412\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0101 - val_loss: 0.0383\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0090 - val_loss: 0.0373\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0085 - val_loss: 0.0380\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0081 - val_loss: 0.0384\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0060 - val_loss: 0.0391\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb4319a5940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5111 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.0343 - val_loss: 0.0394\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0166 - val_loss: 0.0322\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0079 - val_loss: 0.0282\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0076 - val_loss: 0.0278\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0077 - val_loss: 0.0281\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0076 - val_loss: 0.0272\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0062 - val_loss: 0.0278\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0065 - val_loss: 0.0283\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0056 - val_loss: 0.0277\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb28c359940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5112 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.0270 - val_loss: 0.0462\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0174 - val_loss: 0.0437\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0125 - val_loss: 0.0406\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0113 - val_loss: 0.0420\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0084 - val_loss: 0.0422\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0069 - val_loss: 0.0416\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3c5b4c3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5113 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.2163 - val_loss: 0.1097\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0661 - val_loss: 0.0528\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0227 - val_loss: 0.0414\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0166 - val_loss: 0.0333\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0147 - val_loss: 0.0316\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0134 - val_loss: 0.0329\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0104 - val_loss: 0.0334\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0093 - val_loss: 0.0339\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2a20d64c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5114 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.1059 - val_loss: 0.0469\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0194 - val_loss: 0.0445\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0113 - val_loss: 0.0404\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0092 - val_loss: 0.0401\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0084 - val_loss: 0.0411\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0078 - val_loss: 0.0439\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0075 - val_loss: 0.0445\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb363fc4310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5115 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.1477 - val_loss: 0.0381\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0190 - val_loss: 0.0537\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0374 - val_loss: 0.0567\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0205 - val_loss: 0.0561\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb326fa2550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5116 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 0.1232 - val_loss: 0.0421\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0383 - val_loss: 0.0497\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0241 - val_loss: 0.0492\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0147 - val_loss: 0.0401\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0128 - val_loss: 0.0355\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0118 - val_loss: 0.0364\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0100 - val_loss: 0.0366\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0087 - val_loss: 0.0358\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2eef7f790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5117 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.0500 - val_loss: 0.0322\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0233 - val_loss: 0.0266\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0164 - val_loss: 0.0258\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0146 - val_loss: 0.0260\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0137 - val_loss: 0.0254\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0116 - val_loss: 0.0251\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0116 - val_loss: 0.0248\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0098 - val_loss: 0.0243\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0097 - val_loss: 0.0237\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0074 - val_loss: 0.0235\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0076 - val_loss: 0.0235\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0065 - val_loss: 0.0237\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0062 - val_loss: 0.0238\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb45f7ff790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5118 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.1397 - val_loss: 0.0561\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0265 - val_loss: 0.0370\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0226 - val_loss: 0.0227\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0168 - val_loss: 0.0319\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0153 - val_loss: 0.0529\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0135 - val_loss: 0.0700\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb400222700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5119 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3114 - val_loss: 0.1021\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0459 - val_loss: 0.0352\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0354 - val_loss: 0.0277\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0174 - val_loss: 0.0250\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0139 - val_loss: 0.0237\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0123 - val_loss: 0.0237\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0115 - val_loss: 0.0227\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0096 - val_loss: 0.0226\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0089 - val_loss: 0.0228\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0081 - val_loss: 0.0232\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0079 - val_loss: 0.0238\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb382851160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5120 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.0717 - val_loss: 0.0475\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0285 - val_loss: 0.0415\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0224 - val_loss: 0.0412\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0121 - val_loss: 0.0382\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 0.0385\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0088 - val_loss: 0.0382\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0089 - val_loss: 0.0376\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0079 - val_loss: 0.0363\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0078 - val_loss: 0.0362\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0065 - val_loss: 0.0359\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0071 - val_loss: 0.0366\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0070 - val_loss: 0.0365\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0061 - val_loss: 0.0386\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1e0b6df70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5121 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 122ms/step - loss: 0.0929 - val_loss: 0.0620\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0286 - val_loss: 0.0487\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0183 - val_loss: 0.0425\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0139 - val_loss: 0.0352\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0124 - val_loss: 0.0300\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0137 - val_loss: 0.0270\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0102 - val_loss: 0.0250\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0110 - val_loss: 0.0238\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0096 - val_loss: 0.0232\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0090 - val_loss: 0.0233\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0090 - val_loss: 0.0242\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0081 - val_loss: 0.0257\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1deaaf700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5122 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 0.8612 - val_loss: 0.0815\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1087 - val_loss: 0.0330\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0439 - val_loss: 0.0247\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0356 - val_loss: 0.0245\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0254 - val_loss: 0.0309\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0213 - val_loss: 0.0422\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0150 - val_loss: 0.0455\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1dca0f310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5123 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.1668 - val_loss: 0.0218\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0302 - val_loss: 0.0502\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0272 - val_loss: 0.0697\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0255 - val_loss: 0.0709\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1d9558940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5124 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 0.0761 - val_loss: 0.0670\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0313 - val_loss: 0.0747\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0159 - val_loss: 0.0701\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0126 - val_loss: 0.0651\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0106 - val_loss: 0.0610\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0094 - val_loss: 0.0602\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0107 - val_loss: 0.0606\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0093 - val_loss: 0.0594\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0080 - val_loss: 0.0567\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0071 - val_loss: 0.0539\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0066 - val_loss: 0.0517\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0061 - val_loss: 0.0502\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0058 - val_loss: 0.0492\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0055 - val_loss: 0.0480\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0057 - val_loss: 0.0464\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0054 - val_loss: 0.0450\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0051 - val_loss: 0.0438\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0053 - val_loss: 0.0417\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0043 - val_loss: 0.0401\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0041 - val_loss: 0.0406\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0052 - val_loss: 0.0411\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0039 - val_loss: 0.0403\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2213420d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5125 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.5286 - val_loss: 0.1153\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1065 - val_loss: 0.0641\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0418 - val_loss: 0.0563\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0292 - val_loss: 0.0515\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0226 - val_loss: 0.0477\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0193 - val_loss: 0.0450\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0179 - val_loss: 0.0421\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0184 - val_loss: 0.0395\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0165 - val_loss: 0.0373\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0161 - val_loss: 0.0357\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0147 - val_loss: 0.0346\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0142 - val_loss: 0.0337\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0130 - val_loss: 0.0327\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0118 - val_loss: 0.0319\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0111 - val_loss: 0.0317\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0107 - val_loss: 0.0314\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0094 - val_loss: 0.0306\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0089 - val_loss: 0.0293\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0086 - val_loss: 0.0277\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0088 - val_loss: 0.0264\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0076 - val_loss: 0.0253\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0079 - val_loss: 0.0246\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0084 - val_loss: 0.0235\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0079 - val_loss: 0.0220\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0066 - val_loss: 0.0211\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0069 - val_loss: 0.0207\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0065 - val_loss: 0.0212\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0067 - val_loss: 0.0225\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0058 - val_loss: 0.0234\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1f5c9adc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5126 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.1581 - val_loss: 0.0845\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0345 - val_loss: 0.0543\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0212 - val_loss: 0.0380\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0167 - val_loss: 0.0307\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0145 - val_loss: 0.0253\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0129 - val_loss: 0.0201\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0118 - val_loss: 0.0168\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0107 - val_loss: 0.0170\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0099 - val_loss: 0.0178\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0099 - val_loss: 0.0176\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1f0f0f9d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5127 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.0736 - val_loss: 0.0700\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0232 - val_loss: 0.0755\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0182 - val_loss: 0.0746\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0173 - val_loss: 0.0730\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1ef797dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5128 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.3835 - val_loss: 0.2845\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0326 - val_loss: 0.0713\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0130 - val_loss: 0.0179\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0127 - val_loss: 0.0184\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0108 - val_loss: 0.0200\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0108 - val_loss: 0.0218\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1eebc9ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5129 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.0762 - val_loss: 0.0963\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0237 - val_loss: 0.0591\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0157 - val_loss: 0.0445\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0099 - val_loss: 0.0399\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0094 - val_loss: 0.0402\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0104 - val_loss: 0.0432\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0069 - val_loss: 0.0460\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1ecfdd550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5130 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.1355 - val_loss: 0.0667\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0270 - val_loss: 0.0537\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0219 - val_loss: 0.0483\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0161 - val_loss: 0.0475\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0135 - val_loss: 0.0467\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0123 - val_loss: 0.0481\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0115 - val_loss: 0.0512\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0100 - val_loss: 0.0534\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1ea53e940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5131 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.0571 - val_loss: 0.0192\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0263 - val_loss: 0.0209\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0273 - val_loss: 0.0246\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0194 - val_loss: 0.0260\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb212c639d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5132 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.0733 - val_loss: 0.0436\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0292 - val_loss: 0.0407\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0189 - val_loss: 0.0387\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0147 - val_loss: 0.0367\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0129 - val_loss: 0.0347\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0124 - val_loss: 0.0349\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0083 - val_loss: 0.0356\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0076 - val_loss: 0.0356\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb20b33f430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5133 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.0772 - val_loss: 0.0744\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0553 - val_loss: 0.0706\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0218 - val_loss: 0.0592\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0167 - val_loss: 0.0479\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0149 - val_loss: 0.0406\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0113 - val_loss: 0.0357\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0119 - val_loss: 0.0329\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0111 - val_loss: 0.0309\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0083 - val_loss: 0.0304\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0080 - val_loss: 0.0287\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0066 - val_loss: 0.0271\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0073 - val_loss: 0.0245\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0067 - val_loss: 0.0237\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0055 - val_loss: 0.0231\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0057 - val_loss: 0.0229\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0057 - val_loss: 0.0230\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0053 - val_loss: 0.0237\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0052 - val_loss: 0.0241\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1ff843160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5134 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.0516 - val_loss: 0.0316\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0320 - val_loss: 0.0327\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0179 - val_loss: 0.0337\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0152 - val_loss: 0.0320\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb240a1c670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5135 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.0786 - val_loss: 0.0458\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0318 - val_loss: 0.0528\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0197 - val_loss: 0.0554\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0169 - val_loss: 0.0536\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb20e29e790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5136 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 172ms/step - loss: 0.0461 - val_loss: 0.0504\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0163 - val_loss: 0.0448\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.0109 - val_loss: 0.0417\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0088 - val_loss: 0.0394\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0100 - val_loss: 0.0379\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0101 - val_loss: 0.0364\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0076 - val_loss: 0.0365\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0096 - val_loss: 0.0369\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0088 - val_loss: 0.0377\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb235976310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5137 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.0413 - val_loss: 0.0521\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0245 - val_loss: 0.0403\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0129 - val_loss: 0.0316\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0087 - val_loss: 0.0331\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0078 - val_loss: 0.0429\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 0.0447\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2073e3b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5138 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.1414 - val_loss: 0.0291\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0332 - val_loss: 0.0277\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0236 - val_loss: 0.0280\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0189 - val_loss: 0.0274\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0169 - val_loss: 0.0260\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0153 - val_loss: 0.0246\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0137 - val_loss: 0.0250\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0132 - val_loss: 0.0257\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0135 - val_loss: 0.0265\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb21428ec10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5139 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.0473 - val_loss: 0.0322\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0233 - val_loss: 0.0344\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0221 - val_loss: 0.0290\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0156 - val_loss: 0.0213\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0121 - val_loss: 0.0188\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0126 - val_loss: 0.0181\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0108 - val_loss: 0.0182\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0100 - val_loss: 0.0181\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0106 - val_loss: 0.0178\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0095 - val_loss: 0.0178\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0071 - val_loss: 0.0181\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0077 - val_loss: 0.0180\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2491fd040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5140 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.1678 - val_loss: 0.0384\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0429 - val_loss: 0.0275\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0262 - val_loss: 0.0181\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0170 - val_loss: 0.0223\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0111 - val_loss: 0.0305\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0133 - val_loss: 0.0325\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb225f11ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5141 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 0.0831 - val_loss: 0.0403\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0391 - val_loss: 0.0554\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0161 - val_loss: 0.0479\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0109 - val_loss: 0.0462\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb25a492670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5142 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.3142 - val_loss: 0.2361\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0628 - val_loss: 0.1658\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0315 - val_loss: 0.1244\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0233 - val_loss: 0.0826\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0184 - val_loss: 0.0567\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0160 - val_loss: 0.0472\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0158 - val_loss: 0.0396\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0141 - val_loss: 0.0322\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0144 - val_loss: 0.0271\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0126 - val_loss: 0.0245\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0119 - val_loss: 0.0234\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0112 - val_loss: 0.0225\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0108 - val_loss: 0.0214\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0109 - val_loss: 0.0203\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0105 - val_loss: 0.0195\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0106 - val_loss: 0.0186\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 0.0183\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0102 - val_loss: 0.0184\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0090 - val_loss: 0.0182\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0085 - val_loss: 0.0181\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 0.0182\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0114 - val_loss: 0.0185\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0081 - val_loss: 0.0190\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2d5996430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5143 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 0.1197 - val_loss: 0.0529\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0567 - val_loss: 0.0445\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0422 - val_loss: 0.0403\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0349 - val_loss: 0.0364\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0310 - val_loss: 0.0321\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0293 - val_loss: 0.0287\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0279 - val_loss: 0.0270\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0252 - val_loss: 0.0254\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0245 - val_loss: 0.0245\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0216 - val_loss: 0.0253\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0208 - val_loss: 0.0255\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0192 - val_loss: 0.0252\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3828ea9d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5144 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.1641 - val_loss: 0.0558\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0640 - val_loss: 0.0451\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0370 - val_loss: 0.0345\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0264 - val_loss: 0.0226\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0208 - val_loss: 0.0193\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0156 - val_loss: 0.0176\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0118 - val_loss: 0.0178\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0120 - val_loss: 0.0178\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0114 - val_loss: 0.0178\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb399693430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5145 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 0.0917 - val_loss: 0.0457\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0300 - val_loss: 0.0350\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0218 - val_loss: 0.0307\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0149 - val_loss: 0.0237\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0149 - val_loss: 0.0198\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0122 - val_loss: 0.0202\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0113 - val_loss: 0.0232\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0100 - val_loss: 0.0264\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2461d7dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5146 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.0437 - val_loss: 0.0180\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0220 - val_loss: 0.0255\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0160 - val_loss: 0.0295\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0102 - val_loss: 0.0209\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb224435310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5147 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.0458 - val_loss: 0.0577\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0246 - val_loss: 0.0497\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0190 - val_loss: 0.0480\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0136 - val_loss: 0.0433\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0126 - val_loss: 0.0393\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0101 - val_loss: 0.0367\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0082 - val_loss: 0.0367\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0062 - val_loss: 0.0386\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0051 - val_loss: 0.0402\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.004 - 0s 14ms/step - loss: 0.0040 - val_loss: 0.0406\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb224435d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5148 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 164ms/step - loss: 0.0693 - val_loss: 0.0455\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0289 - val_loss: 0.0413\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0230 - val_loss: 0.0408\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0212 - val_loss: 0.0441\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0132 - val_loss: 0.0443\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0146 - val_loss: 0.0444\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb21d24c3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5149 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 179ms/step - loss: 0.8908 - val_loss: 0.7051\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1639 - val_loss: 0.5842\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0595 - val_loss: 0.3953\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0356 - val_loss: 0.3101\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0282 - val_loss: 0.2194\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0285 - val_loss: 0.1612\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0259 - val_loss: 0.1331\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0251 - val_loss: 0.1100\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0233 - val_loss: 0.0905\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0215 - val_loss: 0.0756\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0253 - val_loss: 0.0679\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0209 - val_loss: 0.0602\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0266 - val_loss: 0.0546\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0177 - val_loss: 0.0495\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0192 - val_loss: 0.0468\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0185 - val_loss: 0.0439\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0162 - val_loss: 0.0424\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0155 - val_loss: 0.0428\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0156 - val_loss: 0.0430\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0142 - val_loss: 0.0418\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0139 - val_loss: 0.0384\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0120 - val_loss: 0.0351\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0115 - val_loss: 0.0317\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0111 - val_loss: 0.0291\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0103 - val_loss: 0.0278\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0096 - val_loss: 0.0285\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0092 - val_loss: 0.0300\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0091 - val_loss: 0.0324\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2378ee8b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5150 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 159ms/step - loss: 0.2085 - val_loss: 0.0187\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0639 - val_loss: 0.0192\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0265 - val_loss: 0.0202\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0176 - val_loss: 0.0263\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb23701f040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5151 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.0540 - val_loss: 0.0506\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0327 - val_loss: 0.0422\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0197 - val_loss: 0.0270\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0150 - val_loss: 0.0271\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0101 - val_loss: 0.0342\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0128 - val_loss: 0.0318\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2367b6ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5152 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.0479 - val_loss: 0.0464\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0175 - val_loss: 0.0340\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0128 - val_loss: 0.0284\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0137 - val_loss: 0.0293\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0080 - val_loss: 0.0373\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0083 - val_loss: 0.0460\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb235fe7790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5153 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.0369 - val_loss: 0.0401\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0295 - val_loss: 0.0372\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0124 - val_loss: 0.0339\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0110 - val_loss: 0.0328\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0095 - val_loss: 0.0326\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0079 - val_loss: 0.0318\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0095 - val_loss: 0.0302\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0066 - val_loss: 0.0310\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0058 - val_loss: 0.0340\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0056 - val_loss: 0.0381\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb23575cd30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5154 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.0477 - val_loss: 0.1126\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0415 - val_loss: 0.0621\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0207 - val_loss: 0.0487\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0142 - val_loss: 0.0433\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0109 - val_loss: 0.0378\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0089 - val_loss: 0.0333\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0066 - val_loss: 0.0310\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0055 - val_loss: 0.0302\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0061 - val_loss: 0.0289\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0053 - val_loss: 0.0244\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0052 - val_loss: 0.0215\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0052 - val_loss: 0.0210\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0049 - val_loss: 0.0215\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0037 - val_loss: 0.0209\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0067 - val_loss: 0.0199\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0062 - val_loss: 0.0194\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0046 - val_loss: 0.0202\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0046 - val_loss: 0.0223\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0041 - val_loss: 0.0243\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb234b17550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5155 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.1150 - val_loss: 0.0740\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0195 - val_loss: 0.1086\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0199 - val_loss: 0.1291\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0169 - val_loss: 0.1237\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb257813ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5156 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.0361 - val_loss: 0.0353\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0141 - val_loss: 0.0368\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0097 - val_loss: 0.0334\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0111 - val_loss: 0.0307\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0088 - val_loss: 0.0296\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0079 - val_loss: 0.0279\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0069 - val_loss: 0.0281\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0057 - val_loss: 0.0281\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0055 - val_loss: 0.0272\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0047 - val_loss: 0.0269\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0052 - val_loss: 0.0276\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0047 - val_loss: 0.0279\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0043 - val_loss: 0.0276\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb24c943f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5157 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.1250 - val_loss: 0.0369\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0436 - val_loss: 0.0190\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0185 - val_loss: 0.0158\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0193 - val_loss: 0.0167\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0158 - val_loss: 0.0173\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0098 - val_loss: 0.0169\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb23e90f8b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5158 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.0643 - val_loss: 0.0651\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0355 - val_loss: 0.0298\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0216 - val_loss: 0.0248\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0151 - val_loss: 0.0231\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0121 - val_loss: 0.0223\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 0.0213\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0083 - val_loss: 0.0212\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0086 - val_loss: 0.0214\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0087 - val_loss: 0.0220\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0073 - val_loss: 0.0228\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2aceecdc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5159 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.1618 - val_loss: 0.0357\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0264 - val_loss: 0.0469\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0170 - val_loss: 0.0551\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0159 - val_loss: 0.0597\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb22e62d3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5160 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.0291 - val_loss: 0.0191\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0132 - val_loss: 0.0167\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0104 - val_loss: 0.0165\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0101 - val_loss: 0.0170\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0090 - val_loss: 0.0179\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0073 - val_loss: 0.0195\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb357413b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5161 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 0.2279 - val_loss: 0.0596\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 184ms/step - loss: 0.0398 - val_loss: 0.0286\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0177 - val_loss: 0.0248\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 0.0179 - val_loss: 0.0219\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 212ms/step - loss: 0.0147 - val_loss: 0.0204\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0122 - val_loss: 0.0193\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0107 - val_loss: 0.0189\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.0099 - val_loss: 0.0187\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0088 - val_loss: 0.0186\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0087 - val_loss: 0.0183\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.0081 - val_loss: 0.0182\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0083 - val_loss: 0.0183\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.0074 - val_loss: 0.0187\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0070 - val_loss: 0.0194\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb282bbe160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5162 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 0.0570 - val_loss: 0.0186\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0277 - val_loss: 0.0191\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0123 - val_loss: 0.0193\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0083 - val_loss: 0.0200\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb266ca6700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5163 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 647ms/step - loss: 0.0418 - val_loss: 0.0332\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0234 - val_loss: 0.0296\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0097 - val_loss: 0.0331\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0082 - val_loss: 0.0344\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0067 - val_loss: 0.0328\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb25e97ef70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5164 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 0.0295 - val_loss: 0.0230\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0093 - val_loss: 0.0220\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0134 - val_loss: 0.0225\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0080 - val_loss: 0.0229\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0075 - val_loss: 0.0202\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0063 - val_loss: 0.0193\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0067 - val_loss: 0.0190\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0058 - val_loss: 0.0189\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0058 - val_loss: 0.0190\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0067 - val_loss: 0.0187\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0051 - val_loss: 0.0191\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0046 - val_loss: 0.0196\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0049 - val_loss: 0.0197\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb25b831280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5165 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.0334 - val_loss: 0.0345\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0122 - val_loss: 0.0284\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0122 - val_loss: 0.0295\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0083 - val_loss: 0.0310\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0067 - val_loss: 0.0316\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb258dc1550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5166 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.2184 - val_loss: 0.0527\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0161 - val_loss: 0.0225\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0167 - val_loss: 0.0203\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0131 - val_loss: 0.0195\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0112 - val_loss: 0.0191\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0081 - val_loss: 0.0184\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0074 - val_loss: 0.0188\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0081 - val_loss: 0.0199\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0057 - val_loss: 0.0212\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb282d5c8b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5167 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.2357 - val_loss: 0.0327\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0364 - val_loss: 0.0413\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0184 - val_loss: 0.0589\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0126 - val_loss: 0.0533\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb27b64d820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5168 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.0538 - val_loss: 0.0731\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0265 - val_loss: 0.1193\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0124 - val_loss: 0.1134\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0124 - val_loss: 0.0674\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0124 - val_loss: 0.0396\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0093 - val_loss: 0.0273\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0085 - val_loss: 0.0223\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0079 - val_loss: 0.0199\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0071 - val_loss: 0.0250\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0075 - val_loss: 0.0354\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0070 - val_loss: 0.0415\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb270d2d040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5169 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 196ms/step - loss: 0.0515 - val_loss: 0.0350\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.0231 - val_loss: 0.0304\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0109 - val_loss: 0.0303\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0115 - val_loss: 0.0315\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0095 - val_loss: 0.0332\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0103 - val_loss: 0.0317\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb29a5fd8b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5170 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 0.0731 - val_loss: 0.0220\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0410 - val_loss: 0.0174\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0158 - val_loss: 0.0172\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0121 - val_loss: 0.0178\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0074 - val_loss: 0.0205\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0070 - val_loss: 0.0266\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2828e2c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5171 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 0.1899 - val_loss: 0.0956\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0344 - val_loss: 0.0376\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0182 - val_loss: 0.0235\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0171 - val_loss: 0.0251\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0128 - val_loss: 0.0224\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0149 - val_loss: 0.0227\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0129 - val_loss: 0.0285\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 0.0292\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb297d1d8b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5172 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.0380 - val_loss: 0.0196\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0141 - val_loss: 0.0174\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0088 - val_loss: 0.0182\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0106 - val_loss: 0.0189\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0092 - val_loss: 0.0191\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3c5f3a550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5173 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 0.1856 - val_loss: 0.0201\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0242 - val_loss: 0.0195\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0169 - val_loss: 0.0284\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0123 - val_loss: 0.0351\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0118 - val_loss: 0.0345\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb285e398b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5174 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 174ms/step - loss: 0.0420 - val_loss: 0.0324\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0159 - val_loss: 0.0308\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0100 - val_loss: 0.0278\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0083 - val_loss: 0.0262\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0079 - val_loss: 0.0253\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0079 - val_loss: 0.0254\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0069 - val_loss: 0.0256\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0062 - val_loss: 0.0257\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb27f358550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5175 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 0.1903 - val_loss: 0.0247\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0201 - val_loss: 0.0274\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0155 - val_loss: 0.0315\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0127 - val_loss: 0.0300\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb27cb6c790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5176 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.0429 - val_loss: 0.0231\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0130 - val_loss: 0.0203\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0112 - val_loss: 0.0174\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0084 - val_loss: 0.0173\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0075 - val_loss: 0.0176\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0064 - val_loss: 0.0176\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0071 - val_loss: 0.0179\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2c20e18b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5177 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 165ms/step - loss: 0.1970 - val_loss: 0.0469\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0484 - val_loss: 0.0369\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0300 - val_loss: 0.0274\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0216 - val_loss: 0.0206\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0161 - val_loss: 0.0177\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0140 - val_loss: 0.0170\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.0105 - val_loss: 0.0181\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0098 - val_loss: 0.0201\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0110 - val_loss: 0.0220\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2e9cd84c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5178 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.0624 - val_loss: 0.0233\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0209 - val_loss: 0.0324\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0132 - val_loss: 0.0430\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0097 - val_loss: 0.0488\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb28c33e280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5179 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 156ms/step - loss: 0.0417 - val_loss: 0.0165\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0209 - val_loss: 0.0199\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0110 - val_loss: 0.0226\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0074 - val_loss: 0.0239\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2c6643d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5180 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 0.0990 - val_loss: 0.0159\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0210 - val_loss: 0.0172\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0098 - val_loss: 0.0195\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0113 - val_loss: 0.0196\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb35bbd1820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5181 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 1.0499 - val_loss: 0.3172\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.1662 - val_loss: 0.1227\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0645 - val_loss: 0.1012\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0505 - val_loss: 0.0726\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0407 - val_loss: 0.0591\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0315 - val_loss: 0.0487\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0290 - val_loss: 0.0447\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0251 - val_loss: 0.0386\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0199 - val_loss: 0.0305\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0155 - val_loss: 0.0232\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0129 - val_loss: 0.0191\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0111 - val_loss: 0.0181\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0112 - val_loss: 0.0172\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0104 - val_loss: 0.0165\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0100 - val_loss: 0.0167\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0102 - val_loss: 0.0170\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0093 - val_loss: 0.0174\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2f4310550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5182 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.4697 - val_loss: 0.0407\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0342 - val_loss: 0.0160\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0301 - val_loss: 0.0170\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0307 - val_loss: 0.0179\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0198 - val_loss: 0.0171\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3138c4c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5183 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.0448 - val_loss: 0.0183\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0211 - val_loss: 0.0155\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0113 - val_loss: 0.0154\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0087 - val_loss: 0.0156\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0075 - val_loss: 0.0155\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0055 - val_loss: 0.0155\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb31d60f940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5184 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.0595 - val_loss: 0.0258\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0261 - val_loss: 0.0203\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0148 - val_loss: 0.0162\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0158 - val_loss: 0.0149\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0157 - val_loss: 0.0149\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0136 - val_loss: 0.0154\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0148 - val_loss: 0.0158\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3a4b9f040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5185 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 169ms/step - loss: 0.2108 - val_loss: 0.0299\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0731 - val_loss: 0.0278\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0450 - val_loss: 0.0242\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0345 - val_loss: 0.0214\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0304 - val_loss: 0.0199\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0270 - val_loss: 0.0185\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.0240 - val_loss: 0.0174\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0205 - val_loss: 0.0164\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0182 - val_loss: 0.0155\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0153 - val_loss: 0.0149\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0133 - val_loss: 0.0144\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0121 - val_loss: 0.0141\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0103 - val_loss: 0.0143\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0085 - val_loss: 0.0146\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0078 - val_loss: 0.0149\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb36e65dee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5186 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.1931 - val_loss: 0.0506\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0462 - val_loss: 0.1225\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0155 - val_loss: 0.1257\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0102 - val_loss: 0.0999\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3140773a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5187 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.0515 - val_loss: 0.0186\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0164 - val_loss: 0.0172\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0126 - val_loss: 0.0165\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0086 - val_loss: 0.0159\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0075 - val_loss: 0.0157\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0055 - val_loss: 0.0151\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0055 - val_loss: 0.0144\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0055 - val_loss: 0.0142\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0054 - val_loss: 0.0139\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0047 - val_loss: 0.0135\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0041 - val_loss: 0.0135\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0046 - val_loss: 0.0133\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0043 - val_loss: 0.0133\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0057 - val_loss: 0.0134\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0039 - val_loss: 0.0135\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0042 - val_loss: 0.0134\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3054ffc10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5188 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 0.0879 - val_loss: 0.0165\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0286 - val_loss: 0.0135\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0170 - val_loss: 0.0128\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0133 - val_loss: 0.0127\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0100 - val_loss: 0.0132\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0081 - val_loss: 0.0152\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 0.0158\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2e8f04af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5189 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.0318 - val_loss: 0.0167\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0149 - val_loss: 0.0139\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0118 - val_loss: 0.0132\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0093 - val_loss: 0.0129\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0121 - val_loss: 0.0126\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0118 - val_loss: 0.0127\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0073 - val_loss: 0.0134\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0075 - val_loss: 0.0135\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2c5560a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5190 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.0510 - val_loss: 0.0191\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0253 - val_loss: 0.0147\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0161 - val_loss: 0.0130\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0124 - val_loss: 0.0134\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0093 - val_loss: 0.0134\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0097 - val_loss: 0.0137\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2d1227430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5191 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.0595 - val_loss: 0.0339\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0234 - val_loss: 0.0130\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 0.0129\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0112 - val_loss: 0.0128\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0062 - val_loss: 0.0125\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0054 - val_loss: 0.0127\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0060 - val_loss: 0.0127\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0051 - val_loss: 0.0128\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2c2ef5700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5192 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.0624 - val_loss: 0.0205\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0236 - val_loss: 0.0124\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0139 - val_loss: 0.0125\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0097 - val_loss: 0.0125\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0098 - val_loss: 0.0129\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2a2754040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5193 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.2454 - val_loss: 0.0440\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0326 - val_loss: 0.0379\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0377 - val_loss: 0.0164\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0163 - val_loss: 0.0124\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0111 - val_loss: 0.0113\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 0.0120\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0086 - val_loss: 0.0117\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0072 - val_loss: 0.0119\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb288b1c940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5194 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.0405 - val_loss: 0.0259\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0209 - val_loss: 0.0315\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0114 - val_loss: 0.0292\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0107 - val_loss: 0.0288\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb35a921af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5195 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.1605 - val_loss: 0.0645\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0473 - val_loss: 0.0546\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0135 - val_loss: 0.0353\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0149 - val_loss: 0.0308\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0076 - val_loss: 0.0347\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0072 - val_loss: 0.0393\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0065 - val_loss: 0.0406\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb27e42edc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5196 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.7068 - val_loss: 0.0103\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0808 - val_loss: 0.0132\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0275 - val_loss: 0.0150\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0215 - val_loss: 0.0182\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb28f8a5550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5197 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 181ms/step - loss: 0.0581 - val_loss: 0.0203\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0186 - val_loss: 0.0269\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0138 - val_loss: 0.0217\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0099 - val_loss: 0.0132\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 0.0098\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0091 - val_loss: 0.0102\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0076 - val_loss: 0.0143\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0062 - val_loss: 0.0265\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2a99865e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5198 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.0435 - val_loss: 0.0198\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0240 - val_loss: 0.0180\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0107 - val_loss: 0.0143\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0085 - val_loss: 0.0145\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0088 - val_loss: 0.0150\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0071 - val_loss: 0.0160\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2b79981f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5199 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 0.3555 - val_loss: 0.0788\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1170 - val_loss: 0.0514\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0699 - val_loss: 0.0385\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0434 - val_loss: 0.0220\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0346 - val_loss: 0.0152\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0309 - val_loss: 0.0134\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0278 - val_loss: 0.0118\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0260 - val_loss: 0.0104\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0246 - val_loss: 0.0094\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0226 - val_loss: 0.0086\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0228 - val_loss: 0.0081\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0201 - val_loss: 0.0078\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0184 - val_loss: 0.0078\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0172 - val_loss: 0.0079\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0155 - val_loss: 0.0081\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0138 - val_loss: 0.0084\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2bd57e3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5200 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.0697 - val_loss: 0.0184\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0372 - val_loss: 0.0214\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0225 - val_loss: 0.0175\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0142 - val_loss: 0.0163\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0102 - val_loss: 0.0161\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0098 - val_loss: 0.0158\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.009 - 0s 16ms/step - loss: 0.0097 - val_loss: 0.0150\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0073 - val_loss: 0.0145\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0067 - val_loss: 0.0144\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0055 - val_loss: 0.0142\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0052 - val_loss: 0.0141\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0044 - val_loss: 0.0141\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0040 - val_loss: 0.0144\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0073 - val_loss: 0.0149\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0040 - val_loss: 0.0153\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb26d2be160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5201 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.0808 - val_loss: 0.0136\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0369 - val_loss: 0.0084\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0187 - val_loss: 0.0076\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0142 - val_loss: 0.0077\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0100 - val_loss: 0.0085\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0110 - val_loss: 0.0084\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3c651ed30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5202 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.2841 - val_loss: 0.0461\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0457 - val_loss: 0.0227\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0299 - val_loss: 0.0108\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0144 - val_loss: 0.0084\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0147 - val_loss: 0.0080\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0204 - val_loss: 0.0078\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0126 - val_loss: 0.0080\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0087 - val_loss: 0.0095\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0073 - val_loss: 0.0102\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb320912820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5203 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 0.0670 - val_loss: 0.0080\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0400 - val_loss: 0.0087\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0244 - val_loss: 0.0090\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0148 - val_loss: 0.0083\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb263ed10d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5204 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 195ms/step - loss: 0.6820 - val_loss: 0.0315\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0685 - val_loss: 0.0093\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0329 - val_loss: 0.0377\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0305 - val_loss: 0.0686\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0222 - val_loss: 0.0628\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb249520040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5205 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 187ms/step - loss: 0.0211 - val_loss: 0.0173\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0126 - val_loss: 0.0135\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0080 - val_loss: 0.0120\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0078 - val_loss: 0.0127\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0071 - val_loss: 0.0130\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0063 - val_loss: 0.0127\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb29a763310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5206 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.1215 - val_loss: 0.0086\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0504 - val_loss: 0.0185\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0188 - val_loss: 0.0291\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0121 - val_loss: 0.0314\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb262865e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5207 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.0350 - val_loss: 0.0109\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0124 - val_loss: 0.0086\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0084 - val_loss: 0.0097\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0093 - val_loss: 0.0085\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0068 - val_loss: 0.0083\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0074 - val_loss: 0.0083\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0067 - val_loss: 0.0084\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0052 - val_loss: 0.0084\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb27aec25e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5208 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.1084 - val_loss: 0.0198\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0239 - val_loss: 0.0124\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0167 - val_loss: 0.0128\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0113 - val_loss: 0.0143\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0095 - val_loss: 0.0152\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb25a53d4c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5209 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.1243 - val_loss: 0.0249\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0417 - val_loss: 0.0277\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0336 - val_loss: 0.0262\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0294 - val_loss: 0.0233\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0248 - val_loss: 0.0207\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0177 - val_loss: 0.0178\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0134 - val_loss: 0.0153\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0112 - val_loss: 0.0136\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0098 - val_loss: 0.0128\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0095 - val_loss: 0.0127\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0087 - val_loss: 0.0131\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0090 - val_loss: 0.0134\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0081 - val_loss: 0.0135\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb23af2f940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5210 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 177ms/step - loss: 0.1501 - val_loss: 0.0156\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0346 - val_loss: 0.0072\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0195 - val_loss: 0.0113\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0138 - val_loss: 0.0132\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0140 - val_loss: 0.0138\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb23dd17040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5211 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.0589 - val_loss: 0.0119\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0274 - val_loss: 0.0069\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0163 - val_loss: 0.0109\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0151 - val_loss: 0.0137\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0118 - val_loss: 0.0100\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb24248b040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5212 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.0475 - val_loss: 0.0225\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0161 - val_loss: 0.0121\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0109 - val_loss: 0.0073\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0089 - val_loss: 0.0061\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0079 - val_loss: 0.0067\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0078 - val_loss: 0.0085\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0066 - val_loss: 0.0102\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb228d53c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5213 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.1689 - val_loss: 0.0312\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0424 - val_loss: 0.0365\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0358 - val_loss: 0.0325\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0266 - val_loss: 0.0192\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0162 - val_loss: 0.0095\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0153 - val_loss: 0.0062\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0094 - val_loss: 0.0063\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0091 - val_loss: 0.0074\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0089 - val_loss: 0.0094\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb35008f0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5214 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.0428 - val_loss: 0.0123\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0215 - val_loss: 0.0064\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0127 - val_loss: 0.0064\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0120 - val_loss: 0.0066\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0094 - val_loss: 0.0068\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb35c190e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5215 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 312ms/step - loss: 0.1261 - val_loss: 0.0056\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0470 - val_loss: 0.0060\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0283 - val_loss: 0.0073\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0179 - val_loss: 0.0069\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb323e3edc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5216 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.0566 - val_loss: 0.0063\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0219 - val_loss: 0.0155\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0198 - val_loss: 0.0104\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0139 - val_loss: 0.0060\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0097 - val_loss: 0.0060\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0083 - val_loss: 0.0062\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0062 - val_loss: 0.0063\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0080 - val_loss: 0.0064\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3a57ae1f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5217 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 0.2386 - val_loss: 0.0069\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0351 - val_loss: 0.0090\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0159 - val_loss: 0.0096\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0127 - val_loss: 0.0094\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb26535d280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5218 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 0.0451 - val_loss: 0.0125\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0207 - val_loss: 0.0070\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0127 - val_loss: 0.0069\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0108 - val_loss: 0.0067\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0090 - val_loss: 0.0073\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0081 - val_loss: 0.0103\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb21e650700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5219 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 0.0966 - val_loss: 0.1282\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0176 - val_loss: 0.0215\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0134 - val_loss: 0.0173\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0125 - val_loss: 0.0233\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0129 - val_loss: 0.0229\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0107 - val_loss: 0.0204\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2296bd160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5220 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.0691 - val_loss: 0.0161\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0386 - val_loss: 0.0138\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0237 - val_loss: 0.0100\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0184 - val_loss: 0.0076\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0151 - val_loss: 0.0067\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0144 - val_loss: 0.0065\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0102 - val_loss: 0.0065\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0095 - val_loss: 0.0073\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0079 - val_loss: 0.0074\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0075 - val_loss: 0.0074\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb23a9054c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5221 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.2327 - val_loss: 0.0805\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0377 - val_loss: 0.0792\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0293 - val_loss: 0.0692\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0181 - val_loss: 0.0674\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0129 - val_loss: 0.0683\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0093 - val_loss: 0.0644\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0077 - val_loss: 0.0592\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0073 - val_loss: 0.0549\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0072 - val_loss: 0.0542\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0070 - val_loss: 0.0559\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0056 - val_loss: 0.0580\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0063 - val_loss: 0.0577\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb237b41d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5222 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.2028 - val_loss: 0.0373\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0523 - val_loss: 0.0397\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0275 - val_loss: 0.0332\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0214 - val_loss: 0.0264\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0134 - val_loss: 0.0189\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0134 - val_loss: 0.0138\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0109 - val_loss: 0.0116\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0121 - val_loss: 0.0099\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0114 - val_loss: 0.0082\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0109 - val_loss: 0.0071\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0087 - val_loss: 0.0069\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0083 - val_loss: 0.0069\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0079 - val_loss: 0.0069\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0059 - val_loss: 0.0068\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0053 - val_loss: 0.0069\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0075 - val_loss: 0.0069\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0055 - val_loss: 0.0070\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2351dcd30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5223 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 0.0372 - val_loss: 0.0068\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0159 - val_loss: 0.0064\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0184 - val_loss: 0.0065\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0105 - val_loss: 0.0066\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0095 - val_loss: 0.0070\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb20a27d670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5224 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.7571 - val_loss: 0.5393\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0606 - val_loss: 0.1678\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0336 - val_loss: 0.0387\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0299 - val_loss: 0.0080\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0239 - val_loss: 0.0088\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0253 - val_loss: 0.0138\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0173 - val_loss: 0.0190\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb20a2f0ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5225 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.2117 - val_loss: 0.0085\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0262 - val_loss: 0.0137\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0154 - val_loss: 0.0163\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0135 - val_loss: 0.0166\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb20aab5310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5226 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 122ms/step - loss: 0.1007 - val_loss: 0.0231\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0704 - val_loss: 0.0105\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0244 - val_loss: 0.0093\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0198 - val_loss: 0.0084\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0164 - val_loss: 0.0157\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0135 - val_loss: 0.0171\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0115 - val_loss: 0.0165\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb20b010160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5227 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.1222 - val_loss: 0.0390\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0292 - val_loss: 0.0605\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0269 - val_loss: 0.0700\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0187 - val_loss: 0.0766\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb20b9f68b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5228 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.0697 - val_loss: 0.0489\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0236 - val_loss: 0.0213\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0181 - val_loss: 0.0094\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0104 - val_loss: 0.0085\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0098 - val_loss: 0.0103\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0072 - val_loss: 0.0103\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb20e7fed30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5229 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 0.1496 - val_loss: 0.0233\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0303 - val_loss: 0.0358\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0221 - val_loss: 0.0563\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0126 - val_loss: 0.0532\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2141daaf0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5230 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.0424 - val_loss: 0.0135\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0276 - val_loss: 0.0106\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0200 - val_loss: 0.0081\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0086 - val_loss: 0.0102\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0086 - val_loss: 0.0107\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0064 - val_loss: 0.0091\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1fda9a160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5231 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.1415 - val_loss: 0.0096\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0362 - val_loss: 0.0179\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0273 - val_loss: 0.0191\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0218 - val_loss: 0.0184\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2032870d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5232 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.0477 - val_loss: 0.0132\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0255 - val_loss: 0.0143\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0132 - val_loss: 0.0177\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0106 - val_loss: 0.0184\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb206f2b5e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5233 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.1723 - val_loss: 0.0238\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0448 - val_loss: 0.0232\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0300 - val_loss: 0.0222\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0248 - val_loss: 0.0145\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0155 - val_loss: 0.0092\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0129 - val_loss: 0.0080\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0116 - val_loss: 0.0079\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0117 - val_loss: 0.0079\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0101 - val_loss: 0.0079\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0087 - val_loss: 0.0081\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb37b8a9040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5234 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 1.8739 - val_loss: 0.3831\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.3822 - val_loss: 0.0730\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1241 - val_loss: 0.0213\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0691 - val_loss: 0.0183\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0387 - val_loss: 0.0166\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0301 - val_loss: 0.0143\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0247 - val_loss: 0.0121\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0218 - val_loss: 0.0104\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0209 - val_loss: 0.0093\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0194 - val_loss: 0.0087\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0188 - val_loss: 0.0083\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0176 - val_loss: 0.0081\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0167 - val_loss: 0.0080\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0155 - val_loss: 0.0079\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0141 - val_loss: 0.0078\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0137 - val_loss: 0.0078\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0125 - val_loss: 0.0077\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0126 - val_loss: 0.0077\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0110 - val_loss: 0.0076\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0108 - val_loss: 0.0076\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0112 - val_loss: 0.0076\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0103 - val_loss: 0.0075\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0089 - val_loss: 0.0075\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0092 - val_loss: 0.0075\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0087 - val_loss: 0.0075\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0084 - val_loss: 0.0075\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0091 - val_loss: 0.0075\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0077 - val_loss: 0.0075\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb4c2111820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5235 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 192ms/step - loss: 0.0401 - val_loss: 0.0076\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0149 - val_loss: 0.0137\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0140 - val_loss: 0.0091\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0105 - val_loss: 0.0087\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2b6e86e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5236 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.2546 - val_loss: 0.0093\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0519 - val_loss: 0.0123\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0282 - val_loss: 0.0157\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0260 - val_loss: 0.0187\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2c7ee7ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5237 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.1999 - val_loss: 0.0183\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0599 - val_loss: 0.0070\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0301 - val_loss: 0.0064\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0211 - val_loss: 0.0069\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0205 - val_loss: 0.0075\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0140 - val_loss: 0.0090\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2d01911f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5238 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 157ms/step - loss: 0.0468 - val_loss: 0.0183\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0153 - val_loss: 0.0150\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0086 - val_loss: 0.0109\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0095 - val_loss: 0.0097\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0111 - val_loss: 0.0089\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0102 - val_loss: 0.0101\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0065 - val_loss: 0.0102\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0068 - val_loss: 0.0086\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0061 - val_loss: 0.0097\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0051 - val_loss: 0.0152\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0050 - val_loss: 0.0224\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb268db6160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5239 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.0642 - val_loss: 0.0062\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0520 - val_loss: 0.0114\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0283 - val_loss: 0.0195\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0271 - val_loss: 0.0187\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb217982dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5240 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.3668 - val_loss: 0.0344\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0677 - val_loss: 0.0138\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0210 - val_loss: 0.0094\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0179 - val_loss: 0.0087\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0168 - val_loss: 0.0091\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0112 - val_loss: 0.0106\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0110 - val_loss: 0.0131\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb216ecae50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5241 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 1.1705 - val_loss: 0.0083\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.1903 - val_loss: 0.0175\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0274 - val_loss: 0.0338\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0183 - val_loss: 0.0413\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb252fba940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5242 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.0376 - val_loss: 0.0085\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0212 - val_loss: 0.0098\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0149 - val_loss: 0.0096\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0109 - val_loss: 0.0079\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0082 - val_loss: 0.0092\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0068 - val_loss: 0.0100\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0068 - val_loss: 0.0125\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1dfb09160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5243 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 0.0498 - val_loss: 0.0137\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0172 - val_loss: 0.0136\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0151 - val_loss: 0.0143\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0097 - val_loss: 0.0161\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0107 - val_loss: 0.0177\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1db1a24c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5244 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.0463 - val_loss: 0.0431\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0295 - val_loss: 0.0163\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0263 - val_loss: 0.0090\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0174 - val_loss: 0.0089\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0092 - val_loss: 0.0097\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0098 - val_loss: 0.0095\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0069 - val_loss: 0.0092\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2349baaf0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5245 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 0.2432 - val_loss: 0.0095\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0453 - val_loss: 0.0123\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0182 - val_loss: 0.0172\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0160 - val_loss: 0.0169\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1f10c1e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5246 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.0445 - val_loss: 0.0340\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0212 - val_loss: 0.0295\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0169 - val_loss: 0.0242\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0124 - val_loss: 0.0206\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0101 - val_loss: 0.0183\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0093 - val_loss: 0.0172\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0071 - val_loss: 0.0168\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0084 - val_loss: 0.0164\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0053 - val_loss: 0.0161\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0058 - val_loss: 0.0162\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0053 - val_loss: 0.0161\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0068 - val_loss: 0.0163\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1f6030430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5247 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 0.2182 - val_loss: 0.0255\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0473 - val_loss: 0.0435\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0329 - val_loss: 0.0360\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0187 - val_loss: 0.0415\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1ea321670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5248 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 0.0720 - val_loss: 0.0114\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0397 - val_loss: 0.0201\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0189 - val_loss: 0.0242\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0124 - val_loss: 0.0301\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1ed5288b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5249 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 0.0283 - val_loss: 0.0250\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0176 - val_loss: 0.0190\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0095 - val_loss: 0.0209\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0084 - val_loss: 0.0226\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0057 - val_loss: 0.0233\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1f0ff71f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5250 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.1028 - val_loss: 0.0332\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0208 - val_loss: 0.0286\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0161 - val_loss: 0.0233\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0124 - val_loss: 0.0187\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0107 - val_loss: 0.0168\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0078 - val_loss: 0.0168\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0074 - val_loss: 0.0165\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0071 - val_loss: 0.0174\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0058 - val_loss: 0.0186\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0055 - val_loss: 0.0194\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb20f4370d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5251 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 0.1018 - val_loss: 0.0169\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0318 - val_loss: 0.0161\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0173 - val_loss: 0.0182\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0135 - val_loss: 0.0171\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0148 - val_loss: 0.0168\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1dca6a160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5252 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.2000 - val_loss: 0.0712\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0572 - val_loss: 0.0487\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0254 - val_loss: 0.0372\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0256 - val_loss: 0.0327\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0197 - val_loss: 0.0312\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0180 - val_loss: 0.0293\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0155 - val_loss: 0.0271\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0131 - val_loss: 0.0248\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0084 - val_loss: 0.0236\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0080 - val_loss: 0.0227\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0080 - val_loss: 0.0220\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0072 - val_loss: 0.0216\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0055 - val_loss: 0.0209\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0074 - val_loss: 0.0203\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0057 - val_loss: 0.0197\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0047 - val_loss: 0.0193\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0059 - val_loss: 0.0192\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0046 - val_loss: 0.0193\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0055 - val_loss: 0.0194\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0043 - val_loss: 0.0196\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1eca715e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5253 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 0.0880 - val_loss: 0.0396\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0808 - val_loss: 0.0233\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0263 - val_loss: 0.0238\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0162 - val_loss: 0.0305\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0114 - val_loss: 0.0291\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1df951790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5254 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.0296 - val_loss: 0.0349\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0159 - val_loss: 0.0294\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0131 - val_loss: 0.0306\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0076 - val_loss: 0.0323\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0077 - val_loss: 0.0317\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1f13cb700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5255 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 157ms/step - loss: 0.7408 - val_loss: 0.0326\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1403 - val_loss: 0.0184\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0672 - val_loss: 0.0381\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0217 - val_loss: 0.0317\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0149 - val_loss: 0.0253\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1ea6ce160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5256 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.0252 - val_loss: 0.0466\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0144 - val_loss: 0.0411\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0164 - val_loss: 0.0379\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.0081 - val_loss: 0.0318\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0070 - val_loss: 0.0343\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0052 - val_loss: 0.0343\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0055 - val_loss: 0.0360\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1e773be50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5257 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 210ms/step - loss: 0.3066 - val_loss: 0.0567\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0986 - val_loss: 0.0420\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0475 - val_loss: 0.0390\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0308 - val_loss: 0.0359\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0262 - val_loss: 0.0325\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.0234 - val_loss: 0.0289\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0206 - val_loss: 0.0254\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0186 - val_loss: 0.0221\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0168 - val_loss: 0.0193\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0148 - val_loss: 0.0170\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0135 - val_loss: 0.0153\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0129 - val_loss: 0.0142\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0126 - val_loss: 0.0134\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0122 - val_loss: 0.0131\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0117 - val_loss: 0.0130\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0112 - val_loss: 0.0131\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0102 - val_loss: 0.0132\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0093 - val_loss: 0.0134\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1e7bc21f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5258 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 209ms/step - loss: 0.4999 - val_loss: 0.1420\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1437 - val_loss: 0.0668\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0489 - val_loss: 0.0428\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0255 - val_loss: 0.0299\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0144 - val_loss: 0.0206\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0108 - val_loss: 0.0167\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0123 - val_loss: 0.0168\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0118 - val_loss: 0.0181\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0097 - val_loss: 0.0192\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1ea071700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5259 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.0752 - val_loss: 0.0660\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0250 - val_loss: 0.0438\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0143 - val_loss: 0.0218\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0120 - val_loss: 0.0169\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0086 - val_loss: 0.0151\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0078 - val_loss: 0.0142\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0061 - val_loss: 0.0149\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0056 - val_loss: 0.0153\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0046 - val_loss: 0.0155\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1f09a1ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5260 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.0315 - val_loss: 0.0349\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0127 - val_loss: 0.0328\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0114 - val_loss: 0.0312\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0074 - val_loss: 0.0369\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0055 - val_loss: 0.0387\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0052 - val_loss: 0.0354\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1f394de50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5261 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.0776 - val_loss: 0.0426\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0211 - val_loss: 0.0399\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0143 - val_loss: 0.0361\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0129 - val_loss: 0.0332\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0077 - val_loss: 0.0312\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0076 - val_loss: 0.0306\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0074 - val_loss: 0.0288\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0055 - val_loss: 0.0299\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0047 - val_loss: 0.0329\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0050 - val_loss: 0.0367\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1f3d5c310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5262 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.0839 - val_loss: 0.0153\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0322 - val_loss: 0.0145\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0180 - val_loss: 0.0130\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0179 - val_loss: 0.0123\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0100 - val_loss: 0.0132\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0091 - val_loss: 0.0126\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0077 - val_loss: 0.0121\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0079 - val_loss: 0.0120\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0067 - val_loss: 0.0119\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0091 - val_loss: 0.0121\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0061 - val_loss: 0.0121\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0053 - val_loss: 0.0121\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1f4537160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5263 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.0938 - val_loss: 0.0511\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0181 - val_loss: 0.0586\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0128 - val_loss: 0.0601\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0104 - val_loss: 0.0595\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1f78e4ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5264 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.0493 - val_loss: 0.0175\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0245 - val_loss: 0.0183\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0124 - val_loss: 0.0201\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0104 - val_loss: 0.0207\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1fe813e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5265 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.0289 - val_loss: 0.0461\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0139 - val_loss: 0.0455\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 0.0425\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0072 - val_loss: 0.0407\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0099 - val_loss: 0.0381\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0070 - val_loss: 0.0348\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0068 - val_loss: 0.0321\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0064 - val_loss: 0.0305\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0046 - val_loss: 0.0289\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0042 - val_loss: 0.0278\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0040 - val_loss: 0.0280\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0037 - val_loss: 0.0289\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0040 - val_loss: 0.0299\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb20021d4c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5266 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 0.2444 - val_loss: 0.0599\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0604 - val_loss: 0.0369\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0357 - val_loss: 0.0252\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0282 - val_loss: 0.0202\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0154 - val_loss: 0.0181\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0115 - val_loss: 0.0175\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0095 - val_loss: 0.0177\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0092 - val_loss: 0.0181\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0086 - val_loss: 0.0187\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb20369b1f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5267 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 122ms/step - loss: 0.0246 - val_loss: 0.0304\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0156 - val_loss: 0.0459\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0080 - val_loss: 0.0497\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0070 - val_loss: 0.0525\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb208bc85e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5268 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 185ms/step - loss: 0.0389 - val_loss: 0.0363\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0180 - val_loss: 0.0476\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0074 - val_loss: 0.0661\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0059 - val_loss: 0.0719\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2095acdc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5269 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.1472 - val_loss: 0.0294\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0382 - val_loss: 0.0226\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0148 - val_loss: 0.0226\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0123 - val_loss: 0.0243\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0097 - val_loss: 0.0247\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0089 - val_loss: 0.0236\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb20e28c1f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5270 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.0325 - val_loss: 0.0256\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0118 - val_loss: 0.0347\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0128 - val_loss: 0.0432\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0114 - val_loss: 0.0495\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2111c4700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5271 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 0.5866 - val_loss: 0.0882\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.1415 - val_loss: 0.0426\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0458 - val_loss: 0.0331\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0290 - val_loss: 0.0284\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0227 - val_loss: 0.0257\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0177 - val_loss: 0.0241\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0158 - val_loss: 0.0229\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0143 - val_loss: 0.0220\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0133 - val_loss: 0.0212\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0124 - val_loss: 0.0205\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0117 - val_loss: 0.0199\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0110 - val_loss: 0.0195\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0104 - val_loss: 0.0191\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0096 - val_loss: 0.0189\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0093 - val_loss: 0.0188\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0093 - val_loss: 0.0188\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0082 - val_loss: 0.0189\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0077 - val_loss: 0.0190\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0074 - val_loss: 0.0192\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2145f9280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5272 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 0.1350 - val_loss: 0.0594\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0307 - val_loss: 0.0377\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0237 - val_loss: 0.0302\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0210 - val_loss: 0.0264\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0142 - val_loss: 0.0240\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0092 - val_loss: 0.0218\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0079 - val_loss: 0.0201\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0070 - val_loss: 0.0195\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0063 - val_loss: 0.0193\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0063 - val_loss: 0.0194\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0051 - val_loss: 0.0190\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0049 - val_loss: 0.0189\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.005 - 0s 15ms/step - loss: 0.0047 - val_loss: 0.0189\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0049 - val_loss: 0.0188\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0045 - val_loss: 0.0184\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0049 - val_loss: 0.0177\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0035 - val_loss: 0.0168\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0039 - val_loss: 0.0138\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0034 - val_loss: 0.0111\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0035 - val_loss: 0.0097\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0030 - val_loss: 0.0094\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0038 - val_loss: 0.0094\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.002 - 0s 18ms/step - loss: 0.0027 - val_loss: 0.0095\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0028 - val_loss: 0.0090\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0033 - val_loss: 0.0082\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0026 - val_loss: 0.0076\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0026 - val_loss: 0.0074\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 0.0074\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0025 - val_loss: 0.0075\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 0.0075\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb219f6adc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5273 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.3873 - val_loss: 0.4060\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0462 - val_loss: 0.1925\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0294 - val_loss: 0.1015\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0203 - val_loss: 0.0662\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0153 - val_loss: 0.0367\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0117 - val_loss: 0.0200\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0099 - val_loss: 0.0126\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0091 - val_loss: 0.0104\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0080 - val_loss: 0.0093\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0079 - val_loss: 0.0087\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0073 - val_loss: 0.0084\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0066 - val_loss: 0.0085\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0059 - val_loss: 0.0088\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0054 - val_loss: 0.0093\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb221a444c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5274 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 0.0287 - val_loss: 0.0364\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0146 - val_loss: 0.0444\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0091 - val_loss: 0.0279\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0080 - val_loss: 0.0252\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0071 - val_loss: 0.0264\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0060 - val_loss: 0.0274\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0049 - val_loss: 0.0281\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb227975790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5275 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 0.0947 - val_loss: 0.0507\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0197 - val_loss: 0.0262\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0113 - val_loss: 0.0149\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0109 - val_loss: 0.0107\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0092 - val_loss: 0.0100\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0072 - val_loss: 0.0096\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0063 - val_loss: 0.0093\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0057 - val_loss: 0.0089\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0046 - val_loss: 0.0086\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0040 - val_loss: 0.0086\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0042 - val_loss: 0.0094\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0041 - val_loss: 0.0104\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0040 - val_loss: 0.0118\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb22b303430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5276 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 0.3994 - val_loss: 0.0217\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0429 - val_loss: 0.0486\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0322 - val_loss: 0.0835\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0183 - val_loss: 0.0780\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1c8aade50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5277 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.5839 - val_loss: 0.1667\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1122 - val_loss: 0.0952\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0205 - val_loss: 0.0483\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0162 - val_loss: 0.0436\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0110 - val_loss: 0.0411\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0085 - val_loss: 0.0400\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0073 - val_loss: 0.0389\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0069 - val_loss: 0.0378\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0069 - val_loss: 0.0372\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0067 - val_loss: 0.0371\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0062 - val_loss: 0.0372\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0065 - val_loss: 0.0373\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0058 - val_loss: 0.0368\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0053 - val_loss: 0.0362\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0050 - val_loss: 0.0354\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0047 - val_loss: 0.0343\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0048 - val_loss: 0.0335\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0050 - val_loss: 0.0329\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0042 - val_loss: 0.0329\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0046 - val_loss: 0.0327\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0044 - val_loss: 0.0320\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0048 - val_loss: 0.0303\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0048 - val_loss: 0.0280\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0042 - val_loss: 0.0268\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0042 - val_loss: 0.0265\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0045 - val_loss: 0.0266\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0038 - val_loss: 0.0274\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0039 - val_loss: 0.0286\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1cadbeca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5278 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 165ms/step - loss: 0.1706 - val_loss: 0.0130\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0145 - val_loss: 0.0239\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0160 - val_loss: 0.0299\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0180 - val_loss: 0.0251\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1cc0a1670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5279 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 0.0377 - val_loss: 0.0668\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0217 - val_loss: 0.0548\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0115 - val_loss: 0.0488\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0105 - val_loss: 0.0446\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0081 - val_loss: 0.0391\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0059 - val_loss: 0.0367\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0071 - val_loss: 0.0346\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0064 - val_loss: 0.0305\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0055 - val_loss: 0.0269\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0046 - val_loss: 0.0230\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0052 - val_loss: 0.0222\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0050 - val_loss: 0.0224\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0039 - val_loss: 0.0237\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0037 - val_loss: 0.0248\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1cd17d1f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5280 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 0.1107 - val_loss: 0.0899\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0281 - val_loss: 0.0795\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0148 - val_loss: 0.0724\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0126 - val_loss: 0.0660\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0096 - val_loss: 0.0561\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0069 - val_loss: 0.0491\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0058 - val_loss: 0.0438\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0082 - val_loss: 0.0368\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0058 - val_loss: 0.0329\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0046 - val_loss: 0.0296\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0042 - val_loss: 0.0290\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0042 - val_loss: 0.0318\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0036 - val_loss: 0.0354\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0045 - val_loss: 0.0384\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1cefb7310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5281 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 0.1409 - val_loss: 0.0084\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0251 - val_loss: 0.0054\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0270 - val_loss: 0.0061\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0127 - val_loss: 0.0107\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0064 - val_loss: 0.0199\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1d0b1ae50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5282 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.2190 - val_loss: 0.1145\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0366 - val_loss: 0.0536\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0187 - val_loss: 0.0390\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0176 - val_loss: 0.0319\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0125 - val_loss: 0.0318\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0112 - val_loss: 0.0309\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0077 - val_loss: 0.0291\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0061 - val_loss: 0.0263\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0058 - val_loss: 0.0251\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0051 - val_loss: 0.0243\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0052 - val_loss: 0.0256\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0047 - val_loss: 0.0273\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0039 - val_loss: 0.0287\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1d15b0a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5283 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.1219 - val_loss: 0.0090\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0185 - val_loss: 0.0387\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0196 - val_loss: 0.0587\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0149 - val_loss: 0.0632\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1d31c0550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5284 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.2547 - val_loss: 0.1166\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0411 - val_loss: 0.0882\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0219 - val_loss: 0.0531\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0139 - val_loss: 0.0329\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0121 - val_loss: 0.0238\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0141 - val_loss: 0.0188\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0091 - val_loss: 0.0159\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0068 - val_loss: 0.0137\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0061 - val_loss: 0.0129\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0066 - val_loss: 0.0124\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0062 - val_loss: 0.0121\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0050 - val_loss: 0.0121\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0044 - val_loss: 0.0125\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0046 - val_loss: 0.0129\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1d5e32280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5285 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.0920 - val_loss: 0.0678\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0296 - val_loss: 0.0400\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0159 - val_loss: 0.0353\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0099 - val_loss: 0.0270\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0079 - val_loss: 0.0204\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0078 - val_loss: 0.0194\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0083 - val_loss: 0.0197\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0064 - val_loss: 0.0206\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0062 - val_loss: 0.0213\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1d6dc5670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5286 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 0.0439 - val_loss: 0.0132\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0203 - val_loss: 0.0135\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0104 - val_loss: 0.0141\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0077 - val_loss: 0.0141\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb22dc52670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5287 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 229ms/step - loss: 0.0864 - val_loss: 0.0648\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0195 - val_loss: 0.0269\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0105 - val_loss: 0.0216\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.007 - 0s 67ms/step - loss: 0.0069 - val_loss: 0.0198\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0076 - val_loss: 0.0191\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0064 - val_loss: 0.0184\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0054 - val_loss: 0.0179\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0056 - val_loss: 0.0172\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0050 - val_loss: 0.0162\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0047 - val_loss: 0.0163\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0050 - val_loss: 0.0171\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0040 - val_loss: 0.0178\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1ff8daa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5288 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 243ms/step - loss: 0.1560 - val_loss: 0.0406\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0208 - val_loss: 0.0330\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0152 - val_loss: 0.0278\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0100 - val_loss: 0.0267\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0076 - val_loss: 0.0264\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0072 - val_loss: 0.0253\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0066 - val_loss: 0.0233\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0082 - val_loss: 0.0225\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0060 - val_loss: 0.0230\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0057 - val_loss: 0.0245\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0046 - val_loss: 0.0254\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb285e0d4c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5289 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 191ms/step - loss: 0.0549 - val_loss: 0.0441\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0186 - val_loss: 0.0356\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0149 - val_loss: 0.0343\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0079 - val_loss: 0.0350\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0071 - val_loss: 0.0378\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0067 - val_loss: 0.0388\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2495201f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5290 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 181ms/step - loss: 0.3096 - val_loss: 0.0665\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0663 - val_loss: 0.0465\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0271 - val_loss: 0.0326\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0212 - val_loss: 0.0262\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0218 - val_loss: 0.0233\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0161 - val_loss: 0.0217\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0153 - val_loss: 0.0212\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0120 - val_loss: 0.0210\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0104 - val_loss: 0.0205\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0094 - val_loss: 0.0197\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0091 - val_loss: 0.0192\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0097 - val_loss: 0.0191\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0087 - val_loss: 0.0192\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0084 - val_loss: 0.0192\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0077 - val_loss: 0.0190\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0076 - val_loss: 0.0186\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0077 - val_loss: 0.0180\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0074 - val_loss: 0.0174\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0079 - val_loss: 0.0171\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0071 - val_loss: 0.0169\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0079 - val_loss: 0.0169\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0075 - val_loss: 0.0169\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0070 - val_loss: 0.0171\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0076 - val_loss: 0.0177\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2e9c6ce50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5291 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 537ms/step - loss: 0.0753 - val_loss: 0.0341\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0530 - val_loss: 0.0387\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0106 - val_loss: 0.0470\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0088 - val_loss: 0.0482\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb334b061f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5292 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 237ms/step - loss: 0.1008 - val_loss: 0.0882\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0347 - val_loss: 0.0327\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0180 - val_loss: 0.0313\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0090 - val_loss: 0.0316\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0095 - val_loss: 0.0306\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0094 - val_loss: 0.0298\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0079 - val_loss: 0.0294\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0062 - val_loss: 0.0296\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0058 - val_loss: 0.0304\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0057 - val_loss: 0.0318\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2dc6da040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5293 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 0.0760 - val_loss: 0.0331\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0178 - val_loss: 0.0306\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0103 - val_loss: 0.0352\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0117 - val_loss: 0.0423\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0076 - val_loss: 0.0387\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb26d21f5e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5294 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 0.2045 - val_loss: 0.0597\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0454 - val_loss: 0.0415\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0198 - val_loss: 0.0391\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0124 - val_loss: 0.0357\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0091 - val_loss: 0.0340\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0093 - val_loss: 0.0323\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0063 - val_loss: 0.0331\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0078 - val_loss: 0.0338\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0074 - val_loss: 0.0346\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2aceec0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5295 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 0.0471 - val_loss: 0.0454\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0201 - val_loss: 0.0421\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0157 - val_loss: 0.0411\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0099 - val_loss: 0.0411\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0089 - val_loss: 0.0409\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0070 - val_loss: 0.0391\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0068 - val_loss: 0.0376\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0069 - val_loss: 0.0369\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0059 - val_loss: 0.0357\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0052 - val_loss: 0.0343\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0041 - val_loss: 0.0333\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0042 - val_loss: 0.0326\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0044 - val_loss: 0.0320\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0043 - val_loss: 0.0314\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0038 - val_loss: 0.0313\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0047 - val_loss: 0.0306\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0038 - val_loss: 0.0298\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0033 - val_loss: 0.0294\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0032 - val_loss: 0.0295\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0031 - val_loss: 0.0294\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0043 - val_loss: 0.0292\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0030 - val_loss: 0.0293\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0027 - val_loss: 0.0294\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0026 - val_loss: 0.0298\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2a35c9550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5296 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 171ms/step - loss: 0.1678 - val_loss: 0.0440\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0223 - val_loss: 0.0374\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0228 - val_loss: 0.0355\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0118 - val_loss: 0.0352\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0098 - val_loss: 0.0342\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0077 - val_loss: 0.0342\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0067 - val_loss: 0.0337\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0065 - val_loss: 0.0335\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0055 - val_loss: 0.0325\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0071 - val_loss: 0.0325\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0059 - val_loss: 0.0327\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0047 - val_loss: 0.0325\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0052 - val_loss: 0.0322\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0043 - val_loss: 0.0322\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0046 - val_loss: 0.0323\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0043 - val_loss: 0.0324\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb21e4c6af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5297 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 156ms/step - loss: 0.0173 - val_loss: 0.0676\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0165 - val_loss: 0.0594\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0091 - val_loss: 0.0491\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0096 - val_loss: 0.0479\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0062 - val_loss: 0.0541\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0063 - val_loss: 0.0590\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0068 - val_loss: 0.0685\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb432f57160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5298 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 228ms/step - loss: 0.2285 - val_loss: 0.0482\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0211 - val_loss: 0.0404\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0153 - val_loss: 0.0350\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0091 - val_loss: 0.0340\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0081 - val_loss: 0.0342\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0080 - val_loss: 0.0371\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0058 - val_loss: 0.0375\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb28f772b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5299 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.1322 - val_loss: 0.0651\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0184 - val_loss: 0.0370\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0148 - val_loss: 0.0335\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0114 - val_loss: 0.0337\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.0086 - val_loss: 0.0351\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0082 - val_loss: 0.0353\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1d6dc5d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5300 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 217ms/step - loss: 0.3551 - val_loss: 0.1694\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1276 - val_loss: 0.1304\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0436 - val_loss: 0.0971\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0268 - val_loss: 0.0764\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0169 - val_loss: 0.0610\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0123 - val_loss: 0.0520\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0110 - val_loss: 0.0464\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0090 - val_loss: 0.0434\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0062 - val_loss: 0.0415\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0078 - val_loss: 0.0404\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0061 - val_loss: 0.0402\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0053 - val_loss: 0.0403\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0065 - val_loss: 0.0395\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0054 - val_loss: 0.0382\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0053 - val_loss: 0.0370\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0051 - val_loss: 0.0363\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0062 - val_loss: 0.0367\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0042 - val_loss: 0.0364\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0065 - val_loss: 0.0355\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0053 - val_loss: 0.0352\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0038 - val_loss: 0.0350\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0046 - val_loss: 0.0349\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0040 - val_loss: 0.0350\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0040 - val_loss: 0.0348\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0034 - val_loss: 0.0345\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0040 - val_loss: 0.0345\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0034 - val_loss: 0.0348\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0036 - val_loss: 0.0351\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1cfd51790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5301 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 2s 825ms/step - loss: 0.1147 - val_loss: 0.0397\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0222 - val_loss: 0.0374\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0234 - val_loss: 0.0382\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0163 - val_loss: 0.0359\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0084 - val_loss: 0.0347\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0059 - val_loss: 0.0342\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0077 - val_loss: 0.0329\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0072 - val_loss: 0.0331\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0070 - val_loss: 0.0343\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0064 - val_loss: 0.0343\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1cbaefca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5302 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 205ms/step - loss: 0.1742 - val_loss: 0.0395\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0435 - val_loss: 0.0369\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0247 - val_loss: 0.0412\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0182 - val_loss: 0.0411\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0122 - val_loss: 0.0418\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1c970a9d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5303 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.1257 - val_loss: 0.0410\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0353 - val_loss: 0.0422\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0161 - val_loss: 0.0439\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0092 - val_loss: 0.0440\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb22b303040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5304 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.8292 - val_loss: 0.0795\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0502 - val_loss: 0.0413\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0244 - val_loss: 0.0330\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0328 - val_loss: 0.0348\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0286 - val_loss: 0.0351\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0210 - val_loss: 0.0354\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2260bb1f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5305 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.0564 - val_loss: 0.0385\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0151 - val_loss: 0.0414\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0091 - val_loss: 0.0434\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0066 - val_loss: 0.0423\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb219f6a430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5306 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 122ms/step - loss: 0.2026 - val_loss: 0.0364\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0298 - val_loss: 0.0365\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0224 - val_loss: 0.0372\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0164 - val_loss: 0.0369\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb213b67ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5307 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.0816 - val_loss: 0.0680\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0396 - val_loss: 0.0775\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0191 - val_loss: 0.0656\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0206 - val_loss: 0.0686\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0116 - val_loss: 0.0642\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0098 - val_loss: 0.0578\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0084 - val_loss: 0.0526\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0066 - val_loss: 0.0499\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0064 - val_loss: 0.0478\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0062 - val_loss: 0.0452\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0054 - val_loss: 0.0417\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0050 - val_loss: 0.0405\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0051 - val_loss: 0.0402\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0056 - val_loss: 0.0391\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0061 - val_loss: 0.0385\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0045 - val_loss: 0.0381\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0041 - val_loss: 0.0381\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0040 - val_loss: 0.0383\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0045 - val_loss: 0.0385\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb20f5261f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5308 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 188ms/step - loss: 0.1432 - val_loss: 0.0412\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0228 - val_loss: 0.0383\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0153 - val_loss: 0.0393\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0113 - val_loss: 0.0384\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0065 - val_loss: 0.0386\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb209ba8ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5309 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.0463 - val_loss: 0.0385\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0194 - val_loss: 0.0419\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0127 - val_loss: 0.0391\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0103 - val_loss: 0.0345\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0083 - val_loss: 0.0342\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0059 - val_loss: 0.0368\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0049 - val_loss: 0.0390\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0063 - val_loss: 0.0397\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb206854790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5310 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 184ms/step - loss: 0.3855 - val_loss: 0.0949\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0549 - val_loss: 0.0478\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0171 - val_loss: 0.0387\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0123 - val_loss: 0.0394\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0109 - val_loss: 0.0408\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0097 - val_loss: 0.0411\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb20021da60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5311 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 0.0507 - val_loss: 0.0420\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0155 - val_loss: 0.0476\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0098 - val_loss: 0.0463\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0078 - val_loss: 0.0466\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1f60fbd30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5312 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.1293 - val_loss: 0.0388\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0229 - val_loss: 0.0381\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0202 - val_loss: 0.0425\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0164 - val_loss: 0.0416\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0120 - val_loss: 0.0386\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1f09a1820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5313 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.0436 - val_loss: 0.0430\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0452 - val_loss: 0.0440\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0152 - val_loss: 0.0464\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0078 - val_loss: 0.0477\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1e75cd5e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5314 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.1219 - val_loss: 0.0387\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0174 - val_loss: 0.0394\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0159 - val_loss: 0.0347\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0121 - val_loss: 0.0345\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0098 - val_loss: 0.0352\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0079 - val_loss: 0.0365\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0065 - val_loss: 0.0372\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1df951430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5315 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.0292 - val_loss: 0.0372\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0178 - val_loss: 0.0363\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0170 - val_loss: 0.0368\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0094 - val_loss: 0.0380\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0074 - val_loss: 0.0380\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1dea5d3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5316 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.2943 - val_loss: 0.0536\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0309 - val_loss: 0.1246\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0197 - val_loss: 0.1774\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0122 - val_loss: 0.1902\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1ef070af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5317 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.4057 - val_loss: 0.0652\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0399 - val_loss: 0.0368\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0430 - val_loss: 0.0344\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0402 - val_loss: 0.0363\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0237 - val_loss: 0.0366\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0190 - val_loss: 0.0378\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1ed5281f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5318 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.0504 - val_loss: 0.0521\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0139 - val_loss: 0.0688\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0103 - val_loss: 0.0685\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0069 - val_loss: 0.0691\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1f6030790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5319 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.0197 - val_loss: 0.0344\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0122 - val_loss: 0.0351\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0073 - val_loss: 0.0353\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0047 - val_loss: 0.0360\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb220806f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5320 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 0.0442 - val_loss: 0.0337\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0119 - val_loss: 0.0361\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0071 - val_loss: 0.0394\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0059 - val_loss: 0.0415\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb20f703f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5321 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.4176 - val_loss: 0.0650\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1339 - val_loss: 0.0476\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0677 - val_loss: 0.0387\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0395 - val_loss: 0.0344\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0233 - val_loss: 0.0361\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0134 - val_loss: 0.0450\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0107 - val_loss: 0.0495\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb252fba430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5322 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 165ms/step - loss: 0.0551 - val_loss: 0.0345\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0299 - val_loss: 0.0340\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0145 - val_loss: 0.0362\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 0.0406\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0064 - val_loss: 0.0438\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2467ea3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5323 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.1927 - val_loss: 0.0365\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0251 - val_loss: 0.0352\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0148 - val_loss: 0.0453\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0124 - val_loss: 0.0565\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0065 - val_loss: 0.0624\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2c3059af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5324 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 122ms/step - loss: 0.0988 - val_loss: 0.0425\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0234 - val_loss: 0.0352\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0142 - val_loss: 0.0347\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0104 - val_loss: 0.0347\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0088 - val_loss: 0.0353\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0084 - val_loss: 0.0366\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0080 - val_loss: 0.0386\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3c3d1a550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5325 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 240ms/step - loss: 0.0494 - val_loss: 0.0468\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 0.0196 - val_loss: 0.0387\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0145 - val_loss: 0.0390\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0131 - val_loss: 0.0401\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0077 - val_loss: 0.0399\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb327f023a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5326 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 330ms/step - loss: 0.0729 - val_loss: 0.0342\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0347 - val_loss: 0.0395\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0152 - val_loss: 0.0545\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0074 - val_loss: 0.0580\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2a49abf70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5327 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 265ms/step - loss: 0.2018 - val_loss: 0.0337\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0301 - val_loss: 0.0349\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0140 - val_loss: 0.0368\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0101 - val_loss: 0.0397\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2eed300d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5328 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 289ms/step - loss: 0.0733 - val_loss: 0.0354\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0146 - val_loss: 0.0413\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0135 - val_loss: 0.0487\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0090 - val_loss: 0.0541\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2054f93a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5329 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 285ms/step - loss: 0.0695 - val_loss: 0.0501\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.0114 - val_loss: 0.0488\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0075 - val_loss: 0.0489\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0063 - val_loss: 0.0498\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.0053 - val_loss: 0.0510\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb200734c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5330 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 0.0240 - val_loss: 0.0298\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0116 - val_loss: 0.0390\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0068 - val_loss: 0.0427\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0053 - val_loss: 0.0397\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2141da3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5331 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 0.0853 - val_loss: 0.0358\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0147 - val_loss: 0.0300\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0121 - val_loss: 0.0312\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0061 - val_loss: 0.0349\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0053 - val_loss: 0.0393\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2112b7a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5332 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 223ms/step - loss: 0.1052 - val_loss: 0.0545\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0237 - val_loss: 0.0599\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0143 - val_loss: 0.0538\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0084 - val_loss: 0.0498\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0061 - val_loss: 0.0503\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0054 - val_loss: 0.0511\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0052 - val_loss: 0.0509\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb20b2c19d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5333 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 122ms/step - loss: 0.0759 - val_loss: 0.0584\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0258 - val_loss: 0.0723\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0171 - val_loss: 0.0768\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0087 - val_loss: 0.0734\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb20ac299d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5334 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 170ms/step - loss: 0.1881 - val_loss: 0.0289\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0309 - val_loss: 0.0387\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0202 - val_loss: 0.0410\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0109 - val_loss: 0.0403\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb20a2f0040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5335 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 207ms/step - loss: 0.1915 - val_loss: 0.0384\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0238 - val_loss: 0.0354\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0146 - val_loss: 0.0408\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0097 - val_loss: 0.0471\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0075 - val_loss: 0.0505\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb209d9b5e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5336 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.0603 - val_loss: 0.0317\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0155 - val_loss: 0.0371\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0121 - val_loss: 0.0461\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0082 - val_loss: 0.0561\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb20955ad30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5337 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.1165 - val_loss: 0.0589\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0305 - val_loss: 0.0656\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0200 - val_loss: 0.0660\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0087 - val_loss: 0.0649\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb237b7eb80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5338 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.0644 - val_loss: 0.0286\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0422 - val_loss: 0.0292\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0123 - val_loss: 0.0298\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0100 - val_loss: 0.0307\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2219dfd30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5339 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 0.1208 - val_loss: 0.0511\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0255 - val_loss: 0.0480\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0208 - val_loss: 0.0434\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0086 - val_loss: 0.0429\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0079 - val_loss: 0.0451\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0068 - val_loss: 0.0477\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0063 - val_loss: 0.0483\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb23b8b7820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5340 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.1247 - val_loss: 0.0290\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0176 - val_loss: 0.0287\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0106 - val_loss: 0.0294\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0099 - val_loss: 0.0307\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0065 - val_loss: 0.0304\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb234a088b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5341 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.1232 - val_loss: 0.0279\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0199 - val_loss: 0.0333\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0102 - val_loss: 0.0415\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0081 - val_loss: 0.0433\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb29083e670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5342 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 0.0351 - val_loss: 0.0390\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0084 - val_loss: 0.0447\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0064 - val_loss: 0.0499\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0056 - val_loss: 0.0524\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3456a65e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5343 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.0501 - val_loss: 0.0341\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0248 - val_loss: 0.0364\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0125 - val_loss: 0.0406\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0085 - val_loss: 0.0493\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb22d614c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5344 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 122ms/step - loss: 0.2492 - val_loss: 0.0299\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0509 - val_loss: 0.0367\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0418 - val_loss: 0.0542\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0246 - val_loss: 0.0795\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb24677a940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5345 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 0.3229 - val_loss: 0.1532\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0622 - val_loss: 0.0984\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0276 - val_loss: 0.0652\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0141 - val_loss: 0.0460\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0111 - val_loss: 0.0358\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0085 - val_loss: 0.0316\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0080 - val_loss: 0.0282\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0065 - val_loss: 0.0274\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0056 - val_loss: 0.0282\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0046 - val_loss: 0.0289\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0041 - val_loss: 0.0294\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2423c9940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5346 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 1.2999 - val_loss: 0.0463\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2569 - val_loss: 0.0419\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0544 - val_loss: 0.0862\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0289 - val_loss: 0.1306\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0221 - val_loss: 0.1591\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb23cab6940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5347 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 0.4196 - val_loss: 0.0385\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0232 - val_loss: 0.0323\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0128 - val_loss: 0.0300\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0138 - val_loss: 0.0285\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0105 - val_loss: 0.0282\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0075 - val_loss: 0.0282\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0060 - val_loss: 0.0281\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0059 - val_loss: 0.0279\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0055 - val_loss: 0.0283\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.005 - 0s 16ms/step - loss: 0.0056 - val_loss: 0.0292\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0037 - val_loss: 0.0287\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb23a9b1af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5348 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.1598 - val_loss: 0.0375\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0268 - val_loss: 0.0349\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0136 - val_loss: 0.0353\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0136 - val_loss: 0.0319\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0106 - val_loss: 0.0300\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0072 - val_loss: 0.0298\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0084 - val_loss: 0.0307\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0057 - val_loss: 0.0328\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0045 - val_loss: 0.0337\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb257b729d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5349 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.0675 - val_loss: 0.0292\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0131 - val_loss: 0.0301\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0094 - val_loss: 0.0303\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0074 - val_loss: 0.0303\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb26a0deee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5350 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.8284 - val_loss: 0.0278\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0536 - val_loss: 0.0289\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0413 - val_loss: 0.0295\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0306 - val_loss: 0.0292\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb27795c280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5351 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.0317 - val_loss: 0.0302\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0187 - val_loss: 0.0319\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0086 - val_loss: 0.0323\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0073 - val_loss: 0.0306\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb27473b160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5352 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 0.1193 - val_loss: 0.0267\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0276 - val_loss: 0.0257\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0151 - val_loss: 0.0254\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0117 - val_loss: 0.0262\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0087 - val_loss: 0.0267\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0051 - val_loss: 0.0268\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb31d0e43a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5353 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 0.0675 - val_loss: 0.0355\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0294 - val_loss: 0.0293\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0160 - val_loss: 0.0295\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0097 - val_loss: 0.0285\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0087 - val_loss: 0.0280\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0085 - val_loss: 0.0277\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0057 - val_loss: 0.0288\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0066 - val_loss: 0.0305\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0043 - val_loss: 0.0307\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb26e878e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5354 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.2248 - val_loss: 0.0255\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0649 - val_loss: 0.0242\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0384 - val_loss: 0.0242\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0239 - val_loss: 0.0281\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0178 - val_loss: 0.0334\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2bcbb63a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5355 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 0.1864 - val_loss: 0.0219\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0303 - val_loss: 0.0247\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0285 - val_loss: 0.0237\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0121 - val_loss: 0.0230\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2b6faf8b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5356 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 0.0345 - val_loss: 0.0229\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0252 - val_loss: 0.0228\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0123 - val_loss: 0.0237\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0093 - val_loss: 0.0224\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0081 - val_loss: 0.0223\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0057 - val_loss: 0.0222\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0094 - val_loss: 0.0222\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0056 - val_loss: 0.0222\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0039 - val_loss: 0.0223\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0045 - val_loss: 0.0224\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2a27beaf0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5357 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 0.4071 - val_loss: 0.0314\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0933 - val_loss: 0.0237\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0393 - val_loss: 0.0218\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0256 - val_loss: 0.0217\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0185 - val_loss: 0.0224\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0174 - val_loss: 0.0236\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0164 - val_loss: 0.0236\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2c52faca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5358 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.1851 - val_loss: 0.0220\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0435 - val_loss: 0.0215\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0264 - val_loss: 0.0229\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0092 - val_loss: 0.0236\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0072 - val_loss: 0.0244\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3056383a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5359 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.1948 - val_loss: 0.0226\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0636 - val_loss: 0.0205\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0240 - val_loss: 0.0216\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0201 - val_loss: 0.0220\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0095 - val_loss: 0.0218\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2a14d8310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5360 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 204ms/step - loss: 0.0469 - val_loss: 0.0230\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0212 - val_loss: 0.0232\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0103 - val_loss: 0.0238\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0080 - val_loss: 0.0236\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb29f5bc5e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5361 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.6414 - val_loss: 0.0729\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1264 - val_loss: 0.0356\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0571 - val_loss: 0.0234\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0321 - val_loss: 0.0204\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0248 - val_loss: 0.0206\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0229 - val_loss: 0.0221\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0184 - val_loss: 0.0245\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2cafea310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5362 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 0.0800 - val_loss: 0.0283\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0287 - val_loss: 0.0801\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0225 - val_loss: 0.0852\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0134 - val_loss: 0.0712\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3c4e59ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5363 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 0.1298 - val_loss: 0.0219\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0205 - val_loss: 0.0219\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0155 - val_loss: 0.0214\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0103 - val_loss: 0.0206\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0093 - val_loss: 0.0206\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0068 - val_loss: 0.0207\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.006 - 0s 11ms/step - loss: 0.0061 - val_loss: 0.0207\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0053 - val_loss: 0.0205\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0046 - val_loss: 0.0204\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0039 - val_loss: 0.0201\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0035 - val_loss: 0.0198\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0034 - val_loss: 0.0196\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0031 - val_loss: 0.0195\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0047 - val_loss: 0.0194\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0037 - val_loss: 0.0195\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0029 - val_loss: 0.0194\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0030 - val_loss: 0.0194\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0038 - val_loss: 0.0195\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0054 - val_loss: 0.0194\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0033 - val_loss: 0.0193\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0036 - val_loss: 0.0193\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0029 - val_loss: 0.0194\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0051 - val_loss: 0.0196\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2eee1f670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5364 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.2083 - val_loss: 0.0277\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0555 - val_loss: 0.0264\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0436 - val_loss: 0.0238\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0361 - val_loss: 0.0219\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0330 - val_loss: 0.0205\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0291 - val_loss: 0.0195\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0239 - val_loss: 0.0189\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0165 - val_loss: 0.0186\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0117 - val_loss: 0.0187\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0111 - val_loss: 0.0190\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0107 - val_loss: 0.0194\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb323e84af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5365 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.0259 - val_loss: 0.0168\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0120 - val_loss: 0.0178\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0100 - val_loss: 0.0191\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 0.0202\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3943a4700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5366 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.2395 - val_loss: 0.1532\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0400 - val_loss: 0.0727\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0304 - val_loss: 0.0255\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0219 - val_loss: 0.0141\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0157 - val_loss: 0.0160\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0137 - val_loss: 0.0187\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0142 - val_loss: 0.0179\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb345266040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5367 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 0.0650 - val_loss: 0.0408\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0250 - val_loss: 0.0163\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0229 - val_loss: 0.0191\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0178 - val_loss: 0.0204\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0122 - val_loss: 0.0257\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2ed839e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5368 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.0415 - val_loss: 0.0175\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0197 - val_loss: 0.0170\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0128 - val_loss: 0.0200\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0087 - val_loss: 0.0251\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0059 - val_loss: 0.0313\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb35bbd1790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5369 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.1130 - val_loss: 0.0253\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0217 - val_loss: 0.0305\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0179 - val_loss: 0.0316\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0156 - val_loss: 0.0301\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2c28b7c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5370 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 156ms/step - loss: 0.0392 - val_loss: 0.0106\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0175 - val_loss: 0.0136\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0091 - val_loss: 0.0102\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0072 - val_loss: 0.0105\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0056 - val_loss: 0.0104\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0054 - val_loss: 0.0103\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2c21f5b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5371 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 165ms/step - loss: 0.0790 - val_loss: 0.0171\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0375 - val_loss: 0.0120\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0104 - val_loss: 0.0087\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0109 - val_loss: 0.0113\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0104 - val_loss: 0.0138\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0060 - val_loss: 0.0143\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2e9cd8820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5372 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 0.0757 - val_loss: 0.0192\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0181 - val_loss: 0.0170\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0114 - val_loss: 0.0175\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0094 - val_loss: 0.0156\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0051 - val_loss: 0.0175\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0051 - val_loss: 0.0141\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0063 - val_loss: 0.0102\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0043 - val_loss: 0.0081\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0067 - val_loss: 0.0091\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0045 - val_loss: 0.0087\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0036 - val_loss: 0.0085\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2a23ca9d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5373 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.0611 - val_loss: 0.0155\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0351 - val_loss: 0.0148\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0249 - val_loss: 0.0124\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0196 - val_loss: 0.0103\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0140 - val_loss: 0.0100\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0104 - val_loss: 0.0110\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0089 - val_loss: 0.0126\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0080 - val_loss: 0.0129\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb285fbb1f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5374 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.1853 - val_loss: 0.0092\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0308 - val_loss: 0.0158\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0225 - val_loss: 0.0150\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0179 - val_loss: 0.0142\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb356e0c040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5375 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.0888 - val_loss: 0.0081\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0183 - val_loss: 0.0099\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0172 - val_loss: 0.0110\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0137 - val_loss: 0.0104\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2f1ebd0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5376 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.0810 - val_loss: 0.0443\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0272 - val_loss: 0.0307\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0161 - val_loss: 0.0273\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0110 - val_loss: 0.0222\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0113 - val_loss: 0.0195\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0073 - val_loss: 0.0179\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0068 - val_loss: 0.0170\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0052 - val_loss: 0.0159\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0077 - val_loss: 0.0155\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0048 - val_loss: 0.0154\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0050 - val_loss: 0.0151\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0040 - val_loss: 0.0147\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0039 - val_loss: 0.0143\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0033 - val_loss: 0.0140\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0041 - val_loss: 0.0136\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0031 - val_loss: 0.0130\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0031 - val_loss: 0.0127\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0032 - val_loss: 0.0125\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0035 - val_loss: 0.0121\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0030 - val_loss: 0.0115\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0033 - val_loss: 0.0107\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0025 - val_loss: 0.0102\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0028 - val_loss: 0.0098\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0030 - val_loss: 0.0095\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0024 - val_loss: 0.0092\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0022 - val_loss: 0.0090\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0022 - val_loss: 0.0089\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0022 - val_loss: 0.0088\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0023 - val_loss: 0.0087\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0030 - val_loss: 0.0087\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0019 - val_loss: 0.0089\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0024 - val_loss: 0.0090\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2a9b19ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5377 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 166ms/step - loss: 0.1306 - val_loss: 0.0143\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0146 - val_loss: 0.0117\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0140 - val_loss: 0.0125\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0109 - val_loss: 0.0159\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0104 - val_loss: 0.0214\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb26e9c2280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5378 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 233ms/step - loss: 0.1403 - val_loss: 0.0160\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0376 - val_loss: 0.0188\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0215 - val_loss: 0.0418\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0234 - val_loss: 0.0194\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb27a4b6ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5379 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 268ms/step - loss: 0.2437 - val_loss: 0.0208\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0530 - val_loss: 0.0194\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0222 - val_loss: 0.0187\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0220 - val_loss: 0.0187\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0207 - val_loss: 0.0191\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0188 - val_loss: 0.0195\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb257c22ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5380 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 0.1258 - val_loss: 0.0214\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0219 - val_loss: 0.0304\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0195 - val_loss: 0.0325\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0120 - val_loss: 0.0335\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb258cb4700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5381 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 167ms/step - loss: 0.0564 - val_loss: 0.0255\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0288 - val_loss: 0.0280\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0203 - val_loss: 0.0286\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0151 - val_loss: 0.0298\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb25e93d790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5382 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 158ms/step - loss: 0.0564 - val_loss: 0.0331\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0265 - val_loss: 0.0329\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0190 - val_loss: 0.0326\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0160 - val_loss: 0.0325\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0147 - val_loss: 0.0326\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0133 - val_loss: 0.0327\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0101 - val_loss: 0.0329\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb247cee820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5383 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 181ms/step - loss: 0.0712 - val_loss: 0.0332\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0419 - val_loss: 0.0329\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0382 - val_loss: 0.0326\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0336 - val_loss: 0.0324\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0265 - val_loss: 0.0340\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0201 - val_loss: 0.0362\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0121 - val_loss: 0.0376\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3f6706ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5384 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 194ms/step - loss: 0.0944 - val_loss: 0.0343\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0422 - val_loss: 0.0348\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0353 - val_loss: 0.0361\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0304 - val_loss: 0.0379\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb22e62da60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5385 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 165ms/step - loss: 0.1388 - val_loss: 0.0599\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0736 - val_loss: 0.0441\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0259 - val_loss: 0.0358\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0183 - val_loss: 0.0324\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0167 - val_loss: 0.0338\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0141 - val_loss: 0.0357\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0113 - val_loss: 0.0375\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb244324940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5386 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 214ms/step - loss: 0.0632 - val_loss: 0.0421\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0181 - val_loss: 0.0397\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0160 - val_loss: 0.0408\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0117 - val_loss: 0.0397\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0108 - val_loss: 0.0395\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0106 - val_loss: 0.0393\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0074 - val_loss: 0.0389\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0065 - val_loss: 0.0402\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0067 - val_loss: 0.0420\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0051 - val_loss: 0.0422\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb24e500d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5387 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 0.0492 - val_loss: 0.0355\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0358 - val_loss: 0.0395\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0210 - val_loss: 0.0470\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0107 - val_loss: 0.0542\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb23cbb8ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5388 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 0.0579 - val_loss: 0.0484\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0212 - val_loss: 0.0403\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0153 - val_loss: 0.0360\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0154 - val_loss: 0.0361\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0140 - val_loss: 0.0360\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0109 - val_loss: 0.0359\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0096 - val_loss: 0.0358\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0073 - val_loss: 0.0361\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0094 - val_loss: 0.0366\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0065 - val_loss: 0.0371\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb23438d040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5389 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 172ms/step - loss: 0.0426 - val_loss: 0.0386\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0305 - val_loss: 0.0382\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0250 - val_loss: 0.0380\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0208 - val_loss: 0.0376\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0180 - val_loss: 0.0364\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0162 - val_loss: 0.0363\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0133 - val_loss: 0.0362\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0114 - val_loss: 0.0363\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0114 - val_loss: 0.0366\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0092 - val_loss: 0.0384\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2357d3a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5390 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 184ms/step - loss: 0.1009 - val_loss: 0.0375\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0362 - val_loss: 0.0379\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0303 - val_loss: 0.0402\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0217 - val_loss: 0.0434\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb235fa9820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5391 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.0544 - val_loss: 0.0715\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0278 - val_loss: 0.0591\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0201 - val_loss: 0.0492\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0208 - val_loss: 0.0449\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0128 - val_loss: 0.0399\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0100 - val_loss: 0.0405\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0088 - val_loss: 0.0434\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0062 - val_loss: 0.0446\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb236716ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5392 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 714ms/step - loss: 0.0311 - val_loss: 0.0429\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0225 - val_loss: 0.0403\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0133 - val_loss: 0.0403\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.0095 - val_loss: 0.0423\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0074 - val_loss: 0.0442\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2370d89d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5393 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 175ms/step - loss: 0.0982 - val_loss: 0.0418\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0272 - val_loss: 0.0427\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0224 - val_loss: 0.0414\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.0144 - val_loss: 0.0411\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.013 - 0s 98ms/step - loss: 0.0148 - val_loss: 0.0400\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0096 - val_loss: 0.0376\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.0092 - val_loss: 0.0384\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0076 - val_loss: 0.0401\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0089 - val_loss: 0.0423\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2378a24c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5394 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 258ms/step - loss: 0.1170 - val_loss: 0.0437\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.0309 - val_loss: 0.0450\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0229 - val_loss: 0.0475\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0161 - val_loss: 0.0474\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb21db64ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5395 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 506ms/step - loss: 0.1138 - val_loss: 0.0456\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0603 - val_loss: 0.0459\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0397 - val_loss: 0.0482\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0345 - val_loss: 0.0503\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb22347aee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5396 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 317ms/step - loss: 0.1350 - val_loss: 0.0536\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0464 - val_loss: 0.0530\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0280 - val_loss: 0.0641\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0166 - val_loss: 0.0715\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0141 - val_loss: 0.0763\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb387d42670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5397 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 165ms/step - loss: 0.7934 - val_loss: 0.4607\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0592 - val_loss: 0.1757\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0496 - val_loss: 0.0769\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0409 - val_loss: 0.0636\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0315 - val_loss: 0.0571\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0225 - val_loss: 0.0556\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0157 - val_loss: 0.0541\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0164 - val_loss: 0.0531\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0117 - val_loss: 0.0534\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0110 - val_loss: 0.0541\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0106 - val_loss: 0.0540\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb30564e670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5398 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 0.0515 - val_loss: 0.0498\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0282 - val_loss: 0.0474\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0195 - val_loss: 0.0506\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0152 - val_loss: 0.0510\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0123 - val_loss: 0.0513\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb31b0b1f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5399 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.3828 - val_loss: 0.0861\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0791 - val_loss: 0.0515\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0408 - val_loss: 0.0491\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0326 - val_loss: 0.0568\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0291 - val_loss: 0.0617\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0253 - val_loss: 0.0637\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb371a331f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5400 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 0.0908 - val_loss: 0.0422\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0143 - val_loss: 0.0414\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0113 - val_loss: 0.0412\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0085 - val_loss: 0.0419\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0081 - val_loss: 0.0424\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0063 - val_loss: 0.0417\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb20293fdc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5401 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.1151 - val_loss: 0.0482\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0295 - val_loss: 0.0473\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0174 - val_loss: 0.0475\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0115 - val_loss: 0.0479\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0085 - val_loss: 0.0482\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1fde42550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5402 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.2766 - val_loss: 0.0544\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0675 - val_loss: 0.0464\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0393 - val_loss: 0.0471\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0279 - val_loss: 0.0502\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0210 - val_loss: 0.0543\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb20e39a940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5403 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 0.0681 - val_loss: 0.0479\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0285 - val_loss: 0.0517\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0208 - val_loss: 0.0545\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0185 - val_loss: 0.0533\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1fda481f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5404 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 0.0482 - val_loss: 0.0525\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0254 - val_loss: 0.0515\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0196 - val_loss: 0.0519\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0129 - val_loss: 0.0526\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0110 - val_loss: 0.0538\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb240a1c9d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5405 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.0408 - val_loss: 0.0506\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0182 - val_loss: 0.0499\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0108 - val_loss: 0.0472\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0068 - val_loss: 0.0472\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0047 - val_loss: 0.0477\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0051 - val_loss: 0.0476\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0056 - val_loss: 0.0473\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1fbf04c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5406 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 0.0483 - val_loss: 0.0509\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0231 - val_loss: 0.0521\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0174 - val_loss: 0.0528\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0117 - val_loss: 0.0538\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb20134db80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5407 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.0619 - val_loss: 0.0472\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0212 - val_loss: 0.0491\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0179 - val_loss: 0.0507\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0129 - val_loss: 0.0506\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2094983a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5408 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.4285 - val_loss: 0.1283\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0779 - val_loss: 0.0876\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0279 - val_loss: 0.0679\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0131 - val_loss: 0.0593\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0143 - val_loss: 0.0572\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0156 - val_loss: 0.0564\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0117 - val_loss: 0.0571\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0111 - val_loss: 0.0586\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0081 - val_loss: 0.0634\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1ec8b79d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5409 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.1446 - val_loss: 0.0483\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0271 - val_loss: 0.0504\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0215 - val_loss: 0.0546\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0129 - val_loss: 0.0592\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1eeb3f550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5410 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 0.5325 - val_loss: 0.2222\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0561 - val_loss: 0.1112\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0362 - val_loss: 0.0658\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0357 - val_loss: 0.0541\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0350 - val_loss: 0.0497\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0343 - val_loss: 0.0511\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0330 - val_loss: 0.0508\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0325 - val_loss: 0.0509\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1ef7975e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5411 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 0.0402 - val_loss: 0.0525\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0232 - val_loss: 0.0513\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0124 - val_loss: 0.0487\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0086 - val_loss: 0.0470\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0109 - val_loss: 0.0455\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0082 - val_loss: 0.0455\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0063 - val_loss: 0.0457\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0060 - val_loss: 0.0467\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0050 - val_loss: 0.0475\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1f272f9d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5412 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 156ms/step - loss: 0.2759 - val_loss: 0.0467\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0508 - val_loss: 0.0546\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0281 - val_loss: 0.0561\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0192 - val_loss: 0.0565\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1f6d16280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5413 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 170ms/step - loss: 0.0906 - val_loss: 0.0494\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0173 - val_loss: 0.0470\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0176 - val_loss: 0.0481\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0127 - val_loss: 0.0477\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0093 - val_loss: 0.0494\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2246c6c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5414 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 219ms/step - loss: 0.0319 - val_loss: 0.0549\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0215 - val_loss: 0.0509\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0169 - val_loss: 0.0502\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0129 - val_loss: 0.0500\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0100 - val_loss: 0.0492\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0079 - val_loss: 0.0496\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0064 - val_loss: 0.0507\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0060 - val_loss: 0.0486\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0052 - val_loss: 0.0487\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0043 - val_loss: 0.0477\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0045 - val_loss: 0.0472\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0045 - val_loss: 0.0464\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0040 - val_loss: 0.0459\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0043 - val_loss: 0.0457\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0036 - val_loss: 0.0459\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0045 - val_loss: 0.0458\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0039 - val_loss: 0.0442\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0040 - val_loss: 0.0428\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0058 - val_loss: 0.0416\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0036 - val_loss: 0.0403\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0039 - val_loss: 0.0403\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0037 - val_loss: 0.0409\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0035 - val_loss: 0.0413\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0032 - val_loss: 0.0435\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1db0eb310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5415 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 174ms/step - loss: 0.0593 - val_loss: 0.0569\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0499 - val_loss: 0.0689\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0180 - val_loss: 0.1134\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0205 - val_loss: 0.1214\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1dca0f040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5416 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 196ms/step - loss: 0.0651 - val_loss: 0.0573\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0234 - val_loss: 0.0519\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0169 - val_loss: 0.0486\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0120 - val_loss: 0.0479\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0083 - val_loss: 0.0474\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0056 - val_loss: 0.0497\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.005 - 0s 15ms/step - loss: 0.0048 - val_loss: 0.0519\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0056 - val_loss: 0.0513\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1df97f9d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5417 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 280ms/step - loss: 0.1587 - val_loss: 0.0532\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0413 - val_loss: 0.0513\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0176 - val_loss: 0.0580\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0111 - val_loss: 0.0591\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0111 - val_loss: 0.0578\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1e0ded430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5418 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 217ms/step - loss: 0.0556 - val_loss: 0.0512\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0191 - val_loss: 0.0509\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0147 - val_loss: 0.0521\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0124 - val_loss: 0.0535\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0096 - val_loss: 0.0549\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2ef405040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5419 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 311ms/step - loss: 0.0696 - val_loss: 0.0505\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0273 - val_loss: 0.0655\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0176 - val_loss: 0.0826\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0127 - val_loss: 0.0911\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2b18779d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5420 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 336ms/step - loss: 0.0456 - val_loss: 0.0591\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0220 - val_loss: 0.0561\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0143 - val_loss: 0.0579\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0144 - val_loss: 0.0568\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0090 - val_loss: 0.0552\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0087 - val_loss: 0.0551\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0068 - val_loss: 0.0547\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0062 - val_loss: 0.0533\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0062 - val_loss: 0.0538\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0042 - val_loss: 0.0552\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0046 - val_loss: 0.0561\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb23aeef700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5421 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 216ms/step - loss: 1.0548 - val_loss: 0.0878\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0756 - val_loss: 0.0630\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0353 - val_loss: 0.0544\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0315 - val_loss: 0.0503\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0296 - val_loss: 0.0506\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0278 - val_loss: 0.0515\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0264 - val_loss: 0.0521\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb29f2ccee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5422 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 249ms/step - loss: 0.0873 - val_loss: 0.0512\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0135 - val_loss: 0.0558\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0177 - val_loss: 0.0571\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0096 - val_loss: 0.0575\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb31978a9d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5423 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 248ms/step - loss: 0.0358 - val_loss: 0.0520\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0179 - val_loss: 0.0526\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0116 - val_loss: 0.0534\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0087 - val_loss: 0.0522\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2d11ac3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5424 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 228ms/step - loss: 0.0954 - val_loss: 0.0486\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 0.0198 - val_loss: 0.0459\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0180 - val_loss: 0.0454\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0140 - val_loss: 0.0469\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0113 - val_loss: 0.0482\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0089 - val_loss: 0.0492\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb27da1c280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5425 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 372ms/step - loss: 0.1125 - val_loss: 0.0538\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0179 - val_loss: 0.0617\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0178 - val_loss: 0.0607\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0122 - val_loss: 0.0580\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2ca130310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5426 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 189ms/step - loss: 0.1085 - val_loss: 0.0647\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.0302 - val_loss: 0.0535\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0169 - val_loss: 0.0623\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0145 - val_loss: 0.0655\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0102 - val_loss: 0.0628\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3d25bfee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5427 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 242ms/step - loss: 0.0468 - val_loss: 0.0552\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0238 - val_loss: 0.0531\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0145 - val_loss: 0.0530\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0137 - val_loss: 0.0534\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0135 - val_loss: 0.0537\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0122 - val_loss: 0.0539\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1e27bfc10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5428 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 192ms/step - loss: 0.1790 - val_loss: 0.0495\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0242 - val_loss: 0.0467\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0211 - val_loss: 0.0507\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0179 - val_loss: 0.0508\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0146 - val_loss: 0.0511\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb209c22b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5429 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.0847 - val_loss: 0.0524\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0334 - val_loss: 0.0519\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0234 - val_loss: 0.0530\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0169 - val_loss: 0.0548\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0133 - val_loss: 0.0551\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1fde24dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5430 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 166ms/step - loss: 0.0749 - val_loss: 0.0531\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0251 - val_loss: 0.0569\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0193 - val_loss: 0.0596\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0150 - val_loss: 0.0589\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2365f30d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5431 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.2785 - val_loss: 0.0480\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0359 - val_loss: 0.0558\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0118 - val_loss: 0.0587\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0191 - val_loss: 0.0552\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2276dc5e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5432 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 210ms/step - loss: 0.0260 - val_loss: 0.0533\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0199 - val_loss: 0.0530\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.0133 - val_loss: 0.0529\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0135 - val_loss: 0.0525\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0119 - val_loss: 0.0535\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0096 - val_loss: 0.0520\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0096 - val_loss: 0.0521\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0070 - val_loss: 0.0522\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0059 - val_loss: 0.0527\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1d4810160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5433 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 188ms/step - loss: 0.0504 - val_loss: 0.0620\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0188 - val_loss: 0.0596\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.0167 - val_loss: 0.0710\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0111 - val_loss: 0.0767\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0073 - val_loss: 0.0741\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1f6f74e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5434 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 226ms/step - loss: 0.0630 - val_loss: 0.0659\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0206 - val_loss: 0.0660\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0125 - val_loss: 0.0684\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0088 - val_loss: 0.0606\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0074 - val_loss: 0.0566\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0082 - val_loss: 0.0557\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0089 - val_loss: 0.0553\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0068 - val_loss: 0.0571\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0070 - val_loss: 0.0586\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0055 - val_loss: 0.0580\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb228d8d0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5435 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 212ms/step - loss: 0.0724 - val_loss: 0.0509\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0370 - val_loss: 0.0457\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0174 - val_loss: 0.0465\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0156 - val_loss: 0.0497\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0125 - val_loss: 0.0513\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb20131a550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5436 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 0.2073 - val_loss: 0.0493\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0799 - val_loss: 0.0528\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0229 - val_loss: 0.0695\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0190 - val_loss: 0.0769\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1ca80e9d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5437 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 0.5564 - val_loss: 0.0520\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0469 - val_loss: 0.0516\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0277 - val_loss: 0.0511\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0228 - val_loss: 0.0508\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0215 - val_loss: 0.0506\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0192 - val_loss: 0.0506\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0168 - val_loss: 0.0505\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0134 - val_loss: 0.0505\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0124 - val_loss: 0.0505\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0118 - val_loss: 0.0506\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0115 - val_loss: 0.0507\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0108 - val_loss: 0.0508\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1f46a9c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5438 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 183ms/step - loss: 0.0742 - val_loss: 0.0598\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0229 - val_loss: 0.0548\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0175 - val_loss: 0.0530\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0148 - val_loss: 0.0503\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0119 - val_loss: 0.0495\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0123 - val_loss: 0.0495\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0109 - val_loss: 0.0497\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0069 - val_loss: 0.0500\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1e395f0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5439 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 343ms/step - loss: 0.0455 - val_loss: 0.0369\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0287 - val_loss: 0.0415\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0232 - val_loss: 0.0406\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0144 - val_loss: 0.0394\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1ceaa05e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5440 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 167ms/step - loss: 0.1496 - val_loss: 0.0672\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0372 - val_loss: 0.0404\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0263 - val_loss: 0.0397\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0159 - val_loss: 0.0415\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0120 - val_loss: 0.0434\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0105 - val_loss: 0.0438\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1ff61eb80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5441 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 227ms/step - loss: 0.0859 - val_loss: 0.0388\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0313 - val_loss: 0.0462\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0149 - val_loss: 0.0469\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0146 - val_loss: 0.0412\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1ece5b670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5442 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 172ms/step - loss: 0.2242 - val_loss: 0.0389\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0441 - val_loss: 0.0442\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0324 - val_loss: 0.0465\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0216 - val_loss: 0.0488\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1e71ce160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5443 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 245ms/step - loss: 0.0367 - val_loss: 0.0373\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0239 - val_loss: 0.0293\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0212 - val_loss: 0.0336\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0156 - val_loss: 0.0344\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0142 - val_loss: 0.0335\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1f3f65040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5444 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.0701 - val_loss: 0.0334\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0336 - val_loss: 0.0423\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0319 - val_loss: 0.0426\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0295 - val_loss: 0.0411\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1ffa50a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5445 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.0455 - val_loss: 0.0299\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0181 - val_loss: 0.0544\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0125 - val_loss: 0.0636\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0154 - val_loss: 0.0681\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2103f13a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5446 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.0737 - val_loss: 0.0350\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0330 - val_loss: 0.0220\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0231 - val_loss: 0.0240\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0175 - val_loss: 0.0227\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0135 - val_loss: 0.0217\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0105 - val_loss: 0.0199\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0075 - val_loss: 0.0179\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0094 - val_loss: 0.0166\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0073 - val_loss: 0.0160\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0052 - val_loss: 0.0154\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0064 - val_loss: 0.0152\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0060 - val_loss: 0.0149\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0042 - val_loss: 0.0151\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0048 - val_loss: 0.0155\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0050 - val_loss: 0.0160\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb231075550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5447 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 186ms/step - loss: 0.0600 - val_loss: 0.1156\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0272 - val_loss: 0.0679\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0192 - val_loss: 0.0533\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0143 - val_loss: 0.0405\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0189 - val_loss: 0.0343\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0118 - val_loss: 0.0338\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0103 - val_loss: 0.0341\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0130 - val_loss: 0.0331\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0092 - val_loss: 0.0324\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0087 - val_loss: 0.0311\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0076 - val_loss: 0.0309\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0081 - val_loss: 0.0308\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0056 - val_loss: 0.0311\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0073 - val_loss: 0.0296\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0063 - val_loss: 0.0265\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0059 - val_loss: 0.0244\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0053 - val_loss: 0.0256\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0041 - val_loss: 0.0280\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0049 - val_loss: 0.0276\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb231b1e3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5448 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 2s 788ms/step - loss: 0.0470 - val_loss: 0.0107\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0158 - val_loss: 0.0193\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 170ms/step - loss: 0.0173 - val_loss: 0.0157\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 170ms/step - loss: 0.0178 - val_loss: 0.0137\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb231f4edc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5449 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 418ms/step - loss: 0.1046 - val_loss: 0.1598\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0377 - val_loss: 0.1302\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0180 - val_loss: 0.0955\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.0161 - val_loss: 0.0811\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0121 - val_loss: 0.0841\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0073 - val_loss: 0.0958\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0059 - val_loss: 0.0911\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2324e6160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5450 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 388ms/step - loss: 0.3634 - val_loss: 0.0288\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0559 - val_loss: 0.0484\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0398 - val_loss: 0.0746\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0400 - val_loss: 0.0894\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2329a7820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5451 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0724 - val_loss: 0.0302\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.0490 - val_loss: 0.0340\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0212 - val_loss: 0.0332\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.0187 - val_loss: 0.0325\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb233064b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5452 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 175ms/step - loss: 0.0756 - val_loss: 0.0511\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.0372 - val_loss: 0.0331\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0248 - val_loss: 0.0275\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0208 - val_loss: 0.0271\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0159 - val_loss: 0.0303\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0135 - val_loss: 0.0353\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0085 - val_loss: 0.0392\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1b7c68dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5453 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 196ms/step - loss: 0.0628 - val_loss: 0.0350\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0269 - val_loss: 0.0401\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.0241 - val_loss: 0.0402\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0175 - val_loss: 0.0414\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1b9171160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5454 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 222ms/step - loss: 0.0388 - val_loss: 0.0354\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.0228 - val_loss: 0.0375\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0167 - val_loss: 0.0371\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0138 - val_loss: 0.0382\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1b92e85e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5455 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 438ms/step - loss: 0.1941 - val_loss: 0.0229\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.0528 - val_loss: 0.0362\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0235 - val_loss: 0.0425\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0167 - val_loss: 0.0461\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1b95f24c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5456 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4335WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0055s vs `on_train_batch_end` time: 0.0157s). Check your callbacks.\n",
      "2/2 [==============================] - 1s 436ms/step - loss: 0.3141 - val_loss: 0.0675\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.0399 - val_loss: 0.0229\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0371 - val_loss: 0.0082\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0422 - val_loss: 0.0055\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0229 - val_loss: 0.0057\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0154 - val_loss: 0.0055\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0123 - val_loss: 0.0054\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0148 - val_loss: 0.0052\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0094 - val_loss: 0.0052\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0087 - val_loss: 0.0057\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0075 - val_loss: 0.0062\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1bac6c280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5457 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 2s 761ms/step - loss: 0.1751 - val_loss: 0.0055\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0344 - val_loss: 0.0053\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0241 - val_loss: 0.0128\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0208 - val_loss: 0.0107\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.0167 - val_loss: 0.0075\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1bb427160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5458 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 181ms/step - loss: 0.2220 - val_loss: 0.0517\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0316 - val_loss: 0.0278\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0350 - val_loss: 0.0174\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.0247 - val_loss: 0.0106\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0198 - val_loss: 0.0102\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0207 - val_loss: 0.0108\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0167 - val_loss: 0.0110\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0166 - val_loss: 0.0103\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1bcb914c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5459 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0723 - val_loss: 0.0245\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.0304 - val_loss: 0.0160\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 0.0196 - val_loss: 0.0128\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.0202 - val_loss: 0.0121\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.0160 - val_loss: 0.0109\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.0132 - val_loss: 0.0100\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0108 - val_loss: 0.0097\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.0095 - val_loss: 0.0096\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 0.0088 - val_loss: 0.0097\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 122ms/step - loss: 0.0075 - val_loss: 0.0093\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.0074 - val_loss: 0.0088\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0060 - val_loss: 0.0085\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.0059 - val_loss: 0.0085\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0046 - val_loss: 0.0085\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 0.0075 - val_loss: 0.0085\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1bde7eaf0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5460 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6296WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0055s vs `on_train_batch_end` time: 0.0405s). Check your callbacks.\n",
      "2/2 [==============================] - 1s 742ms/step - loss: 0.6296 - val_loss: 0.0136\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0624 - val_loss: 0.0486\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.0426 - val_loss: 0.0986\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0279 - val_loss: 0.1081\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1bf974e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5461 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 203ms/step - loss: 0.1273 - val_loss: 0.0300\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0399 - val_loss: 0.0161\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0313 - val_loss: 0.0129\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0216 - val_loss: 0.0126\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0149 - val_loss: 0.0133\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.0105 - val_loss: 0.0138\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0103 - val_loss: 0.0143\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1c16123a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5462 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 194ms/step - loss: 0.1594 - val_loss: 0.0497\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0318 - val_loss: 0.0322\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0240 - val_loss: 0.0133\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0184 - val_loss: 0.0076\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0173 - val_loss: 0.0054\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0127 - val_loss: 0.0058\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0109 - val_loss: 0.0084\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0116 - val_loss: 0.0100\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1c2566310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5463 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 203ms/step - loss: 0.5323 - val_loss: 0.0513\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.0807 - val_loss: 0.0346\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.0408 - val_loss: 0.0367\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0213 - val_loss: 0.0338\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0165 - val_loss: 0.0298\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0191 - val_loss: 0.0271\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0136 - val_loss: 0.0247\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0098 - val_loss: 0.0227\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0093 - val_loss: 0.0225\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0078 - val_loss: 0.0240\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0110 - val_loss: 0.0262\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0086 - val_loss: 0.0278\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1c488f1f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5464 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 218ms/step - loss: 0.1402 - val_loss: 0.0499\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0166 - val_loss: 0.0325\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0157 - val_loss: 0.0199\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0130 - val_loss: 0.0158\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0108 - val_loss: 0.0148\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0099 - val_loss: 0.0138\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0092 - val_loss: 0.0124\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0077 - val_loss: 0.0130\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0057 - val_loss: 0.0143\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0076 - val_loss: 0.0148\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1c5a7edc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5465 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 184ms/step - loss: 0.0806 - val_loss: 0.0183\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0636 - val_loss: 0.0172\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0187 - val_loss: 0.0226\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0181 - val_loss: 0.0263\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0171 - val_loss: 0.0291\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2336470d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5466 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 162ms/step - loss: 0.1277 - val_loss: 0.0064\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0511 - val_loss: 0.0094\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0239 - val_loss: 0.0151\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0169 - val_loss: 0.0163\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb233b004c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5467 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 183ms/step - loss: 0.3701 - val_loss: 0.0139\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0668 - val_loss: 0.0280\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0314 - val_loss: 0.0287\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0298 - val_loss: 0.0265\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1a7c1ea60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5468 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 249ms/step - loss: 0.1234 - val_loss: 0.0510\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0345 - val_loss: 0.0516\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0331 - val_loss: 0.0362\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0230 - val_loss: 0.0355\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0252 - val_loss: 0.0367\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0187 - val_loss: 0.0362\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0153 - val_loss: 0.0356\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1a9e4eca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5469 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 213ms/step - loss: 0.1805 - val_loss: 0.0160\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0406 - val_loss: 0.0230\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0254 - val_loss: 0.0298\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0245 - val_loss: 0.0353\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1ab4229d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5470 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 254ms/step - loss: 0.8356 - val_loss: 0.0233\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0979 - val_loss: 0.0484\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0367 - val_loss: 0.0681\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0358 - val_loss: 0.0863\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1acdfe790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5471 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 267ms/step - loss: 0.2884 - val_loss: 0.0166\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0482 - val_loss: 0.0143\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0256 - val_loss: 0.0249\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0170 - val_loss: 0.0321\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.0151 - val_loss: 0.0312\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1ae518280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5472 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 268ms/step - loss: 1.3857 - val_loss: 0.0072\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1485 - val_loss: 0.0236\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0517 - val_loss: 0.0433\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0351 - val_loss: 0.0525\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2ed71f5e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5473 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 217ms/step - loss: 0.0527 - val_loss: 0.0179\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0291 - val_loss: 0.0513\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0193 - val_loss: 0.1132\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0085 - val_loss: 0.1228\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2d4a11430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5474 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 214ms/step - loss: 0.1216 - val_loss: 0.0137\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0421 - val_loss: 0.0259\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0297 - val_loss: 0.0320\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0265 - val_loss: 0.0348\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb20bf17700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5475 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 208ms/step - loss: 0.1955 - val_loss: 0.0167\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0577 - val_loss: 0.0130\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0347 - val_loss: 0.0107\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0220 - val_loss: 0.0094\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0190 - val_loss: 0.0090\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0192 - val_loss: 0.0093\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0141 - val_loss: 0.0102\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0098 - val_loss: 0.0112\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2ee11ce50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5476 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 195ms/step - loss: 0.2545 - val_loss: 0.0189\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0317 - val_loss: 0.0144\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0317 - val_loss: 0.0139\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0129 - val_loss: 0.0135\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0140 - val_loss: 0.0130\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0129 - val_loss: 0.0121\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0097 - val_loss: 0.0108\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0090 - val_loss: 0.0097\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0063 - val_loss: 0.0094\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0062 - val_loss: 0.0095\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0054 - val_loss: 0.0091\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0065 - val_loss: 0.0085\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0072 - val_loss: 0.0079\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0071 - val_loss: 0.0077\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0062 - val_loss: 0.0078\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0041 - val_loss: 0.0079\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0049 - val_loss: 0.0080\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2b1831040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5477 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 241ms/step - loss: 0.2924 - val_loss: 0.0101\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0318 - val_loss: 0.0196\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0295 - val_loss: 0.0284\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0220 - val_loss: 0.0312\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb28640ae50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5478 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 173ms/step - loss: 0.0532 - val_loss: 0.0224\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0212 - val_loss: 0.0107\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0174 - val_loss: 0.0075\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0093 - val_loss: 0.0074\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0080 - val_loss: 0.0079\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0061 - val_loss: 0.0075\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0105 - val_loss: 0.0067\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0065 - val_loss: 0.0069\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0058 - val_loss: 0.0072\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0051 - val_loss: 0.0066\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0036 - val_loss: 0.0069\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0043 - val_loss: 0.0073\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0059 - val_loss: 0.0075\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb35bbd1a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5479 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 270ms/step - loss: 0.0420 - val_loss: 0.0193\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0303 - val_loss: 0.0192\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0203 - val_loss: 0.0189\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0146 - val_loss: 0.0183\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0122 - val_loss: 0.0162\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0081 - val_loss: 0.0116\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0093 - val_loss: 0.0092\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0076 - val_loss: 0.0085\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0059 - val_loss: 0.0083\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0046 - val_loss: 0.0080\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.004 - 0s 15ms/step - loss: 0.0061 - val_loss: 0.0084\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0039 - val_loss: 0.0089\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0045 - val_loss: 0.0086\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb305638dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5480 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 223ms/step - loss: 0.0961 - val_loss: 0.0259\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0451 - val_loss: 0.0180\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0222 - val_loss: 0.0125\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0178 - val_loss: 0.0103\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0125 - val_loss: 0.0087\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0099 - val_loss: 0.0083\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.0079 - val_loss: 0.0088\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0096 - val_loss: 0.0082\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0089 - val_loss: 0.0086\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0083 - val_loss: 0.0102\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0109 - val_loss: 0.0091\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb246155040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5481 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 222ms/step - loss: 0.1687 - val_loss: 0.0108\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0336 - val_loss: 0.0260\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0300 - val_loss: 0.0313\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0266 - val_loss: 0.0324\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb214154b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5482 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 218ms/step - loss: 0.0494 - val_loss: 0.0203\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0275 - val_loss: 0.0181\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0224 - val_loss: 0.0150\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0203 - val_loss: 0.0119\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0146 - val_loss: 0.0091\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0122 - val_loss: 0.0078\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0167 - val_loss: 0.0071\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.0107 - val_loss: 0.0068\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0084 - val_loss: 0.0071\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0079 - val_loss: 0.0076\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0067 - val_loss: 0.0080\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb268db6dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5483 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 462ms/step - loss: 0.5294 - val_loss: 0.0152\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0670 - val_loss: 0.0089\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0306 - val_loss: 0.0060\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0282 - val_loss: 0.0058\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0262 - val_loss: 0.0063\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0194 - val_loss: 0.0069\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.0167 - val_loss: 0.0072\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb363d6b550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5484 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 0.1985 - val_loss: 0.0261\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0398 - val_loss: 0.0384\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0309 - val_loss: 0.0430\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0248 - val_loss: 0.0418\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb23b83e0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5485 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 333ms/step - loss: 0.1212 - val_loss: 0.0105\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0315 - val_loss: 0.0052\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.0252 - val_loss: 0.0054\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0192 - val_loss: 0.0117\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0115 - val_loss: 0.0216\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb292d59f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5486 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0499 - val_loss: 0.0279\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.0323 - val_loss: 0.0204\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.0188 - val_loss: 0.0134\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 0.0150 - val_loss: 0.0090\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 0.0134 - val_loss: 0.0095\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0128 - val_loss: 0.0125\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.0110 - val_loss: 0.0148\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1ac80f280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5487 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 544ms/step - loss: 0.1123 - val_loss: 0.0056\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.0284 - val_loss: 0.0065\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0249 - val_loss: 0.0076\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0187 - val_loss: 0.0232\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1a9e4e790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5488 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 598ms/step - loss: 0.0421 - val_loss: 0.0234\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.0350 - val_loss: 0.0210\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0200 - val_loss: 0.0190\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0135 - val_loss: 0.0177\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0088 - val_loss: 0.0162\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0099 - val_loss: 0.0154\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0075 - val_loss: 0.0146\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0064 - val_loss: 0.0143\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0078 - val_loss: 0.0142\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0037 - val_loss: 0.0139\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.0039 - val_loss: 0.0138\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0045 - val_loss: 0.0137\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0048 - val_loss: 0.0135\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0059 - val_loss: 0.0132\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0039 - val_loss: 0.0132\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0043 - val_loss: 0.0134\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0043 - val_loss: 0.0133\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb233b4e8b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5489 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 290ms/step - loss: 0.0864 - val_loss: 0.0217\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0269 - val_loss: 0.0135\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0155 - val_loss: 0.0086\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0143 - val_loss: 0.0067\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0123 - val_loss: 0.0066\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0102 - val_loss: 0.0071\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0096 - val_loss: 0.0079\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0138 - val_loss: 0.0086\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1c6a58940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5490 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 269ms/step - loss: 0.0906 - val_loss: 0.0205\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0350 - val_loss: 0.0211\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0166 - val_loss: 0.0119\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0120 - val_loss: 0.0092\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0100 - val_loss: 0.0084\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0069 - val_loss: 0.0085\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0082 - val_loss: 0.0079\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0047 - val_loss: 0.0078\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0048 - val_loss: 0.0077\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0043 - val_loss: 0.0075\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0046 - val_loss: 0.0074\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0051 - val_loss: 0.0074\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0054 - val_loss: 0.0074\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0041 - val_loss: 0.0074\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0041 - val_loss: 0.0076\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0038 - val_loss: 0.0078\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1c533d790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5491 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 280ms/step - loss: 0.0523 - val_loss: 0.0076\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0324 - val_loss: 0.0110\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0267 - val_loss: 0.0135\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0232 - val_loss: 0.0118\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1c20cc790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5492 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 328ms/step - loss: 1.2090 - val_loss: 0.1283\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.2514 - val_loss: 0.0573\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0404 - val_loss: 0.0215\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0238 - val_loss: 0.0065\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0336 - val_loss: 0.0089\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0383 - val_loss: 0.0150\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0316 - val_loss: 0.0210\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1be837700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5493 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 424ms/step - loss: 0.0605 - val_loss: 0.0524\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0194 - val_loss: 0.0303\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0135 - val_loss: 0.0220\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0072 - val_loss: 0.0176\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0062 - val_loss: 0.0148\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0055 - val_loss: 0.0147\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0063 - val_loss: 0.0158\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0058 - val_loss: 0.0159\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0070 - val_loss: 0.0155\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1bad35430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5494 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 231ms/step - loss: 0.5772 - val_loss: 0.0097\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0456 - val_loss: 0.0165\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0309 - val_loss: 0.0230\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0295 - val_loss: 0.0322\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb233522f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5495 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 202ms/step - loss: 0.0822 - val_loss: 0.0136\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0232 - val_loss: 0.0171\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0146 - val_loss: 0.0174\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0094 - val_loss: 0.0171\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2324e68b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5496 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 204ms/step - loss: 0.0711 - val_loss: 0.0126\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0368 - val_loss: 0.0161\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0227 - val_loss: 0.0083\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0193 - val_loss: 0.0074\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0099 - val_loss: 0.0077\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0105 - val_loss: 0.0073\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0131 - val_loss: 0.0059\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0069 - val_loss: 0.0065\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0069 - val_loss: 0.0112\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0056 - val_loss: 0.0189\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2103f1820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5497 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 192ms/step - loss: 0.0883 - val_loss: 0.0250\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0246 - val_loss: 0.0389\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0209 - val_loss: 0.0344\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0159 - val_loss: 0.0247\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0137 - val_loss: 0.0187\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0127 - val_loss: 0.0167\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0104 - val_loss: 0.0168\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0086 - val_loss: 0.0175\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0124 - val_loss: 0.0194\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1e72758b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5498 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 228ms/step - loss: 0.1048 - val_loss: 0.0343\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0253 - val_loss: 0.0178\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0133 - val_loss: 0.0107\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0091 - val_loss: 0.0084\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0051 - val_loss: 0.0073\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0076 - val_loss: 0.0071\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0053 - val_loss: 0.0067\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0047 - val_loss: 0.0066\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0042 - val_loss: 0.0069\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0068 - val_loss: 0.0076\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0055 - val_loss: 0.0078\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1f4273670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5499 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 270ms/step - loss: 0.5341 - val_loss: 0.0267\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0704 - val_loss: 0.0207\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0110 - val_loss: 0.0150\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0139 - val_loss: 0.0116\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.014 - 0s 21ms/step - loss: 0.0115 - val_loss: 0.0098\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0081 - val_loss: 0.0086\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0077 - val_loss: 0.0077\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0068 - val_loss: 0.0072\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0061 - val_loss: 0.0067\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0058 - val_loss: 0.0064\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0112 - val_loss: 0.0061\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0057 - val_loss: 0.0060\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0070 - val_loss: 0.0059\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0084 - val_loss: 0.0059\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0045 - val_loss: 0.0059\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0061 - val_loss: 0.0060\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0038 - val_loss: 0.0060\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb21f232e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5500 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 207ms/step - loss: 0.1988 - val_loss: 0.0235\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0603 - val_loss: 0.0457\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.0227 - val_loss: 0.0524\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0177 - val_loss: 0.0525\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb227d685e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5501 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 209ms/step - loss: 0.0410 - val_loss: 0.0143\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0325 - val_loss: 0.0077\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0122 - val_loss: 0.0071\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0113 - val_loss: 0.0051\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0071 - val_loss: 0.0047\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0093 - val_loss: 0.0048\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0066 - val_loss: 0.0056\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0075 - val_loss: 0.0054\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb203605af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5502 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 204ms/step - loss: 0.0445 - val_loss: 0.0061\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0143 - val_loss: 0.0057\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0125 - val_loss: 0.0064\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0106 - val_loss: 0.0096\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0079 - val_loss: 0.0087\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1fc06e280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5503 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 322ms/step - loss: 0.0964 - val_loss: 0.0303\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0322 - val_loss: 0.0316\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0212 - val_loss: 0.0275\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0159 - val_loss: 0.0276\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0101 - val_loss: 0.0291\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 0.0060 - val_loss: 0.0307\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2092afa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5504 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 262ms/step - loss: 0.0474 - val_loss: 0.0049\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0281 - val_loss: 0.0092\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0286 - val_loss: 0.0144\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.0230 - val_loss: 0.0161\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1f6f740d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5505 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 451ms/step - loss: 0.2454 - val_loss: 0.0271\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0544 - val_loss: 0.0369\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0232 - val_loss: 0.0382\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.0095 - val_loss: 0.0367\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1e0d5cca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5506 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 0.4387 - val_loss: 0.0250\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1044 - val_loss: 0.0210\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0451 - val_loss: 0.0167\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0298 - val_loss: 0.0138\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0273 - val_loss: 0.0120\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0213 - val_loss: 0.0108\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0177 - val_loss: 0.0101\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0139 - val_loss: 0.0094\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0121 - val_loss: 0.0086\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0114 - val_loss: 0.0077\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0096 - val_loss: 0.0068\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0092 - val_loss: 0.0061\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0086 - val_loss: 0.0057\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0078 - val_loss: 0.0054\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0079 - val_loss: 0.0052\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0079 - val_loss: 0.0050\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0086 - val_loss: 0.0049\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0066 - val_loss: 0.0049\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0063 - val_loss: 0.0049\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0067 - val_loss: 0.0049\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0051 - val_loss: 0.0049\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0059 - val_loss: 0.0049\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0079 - val_loss: 0.0049\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0042 - val_loss: 0.0051\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1f3fde8b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5507 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 609ms/step - loss: 0.0489 - val_loss: 0.0049\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0152 - val_loss: 0.0052\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0088 - val_loss: 0.0059\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0068 - val_loss: 0.0059\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb209c22dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5508 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 406ms/step - loss: 0.3409 - val_loss: 0.0152\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0875 - val_loss: 0.0125\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0322 - val_loss: 0.0112\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0219 - val_loss: 0.0101\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0187 - val_loss: 0.0093\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0186 - val_loss: 0.0081\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0139 - val_loss: 0.0070\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0111 - val_loss: 0.0062\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0090 - val_loss: 0.0056\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0074 - val_loss: 0.0052\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0067 - val_loss: 0.0050\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0065 - val_loss: 0.0048\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0069 - val_loss: 0.0048\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0049 - val_loss: 0.0048\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0051 - val_loss: 0.0048\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0053 - val_loss: 0.0048\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0064 - val_loss: 0.0049\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1e37a8af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5509 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 303ms/step - loss: 0.4174 - val_loss: 0.0100\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0794 - val_loss: 0.0057\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0291 - val_loss: 0.0049\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0279 - val_loss: 0.0074\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0254 - val_loss: 0.0095\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0236 - val_loss: 0.0107\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb23468ae50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5510 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 310ms/step - loss: 0.0805 - val_loss: 0.0078\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0451 - val_loss: 0.0196\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0257 - val_loss: 0.0223\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.0286 - val_loss: 0.0250\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2828d6d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5511 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0610WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0286s vs `on_train_batch_end` time: 0.0768s). Check your callbacks.\n",
      "2/2 [==============================] - 1s 566ms/step - loss: 0.0610 - val_loss: 0.0052\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0253 - val_loss: 0.0056\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0205 - val_loss: 0.0059\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0154 - val_loss: 0.0066\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3a5fa84c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5512 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 483ms/step - loss: 0.1009 - val_loss: 0.0140\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0362 - val_loss: 0.0063\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0211 - val_loss: 0.0060\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0120 - val_loss: 0.0062\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0162 - val_loss: 0.0054\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0118 - val_loss: 0.0051\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0074 - val_loss: 0.0054\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0071 - val_loss: 0.0062\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0072 - val_loss: 0.0073\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3237c0670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5513 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 470ms/step - loss: 0.5566 - val_loss: 0.0067\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.1084 - val_loss: 0.0210\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0315 - val_loss: 0.0230\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0292 - val_loss: 0.0220\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3396c75e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5514 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 286ms/step - loss: 0.1834 - val_loss: 0.1044\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0389 - val_loss: 0.0453\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0136 - val_loss: 0.0348\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.0146 - val_loss: 0.0168\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0093 - val_loss: 0.0110\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0093 - val_loss: 0.0086\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0076 - val_loss: 0.0055\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 0.0061 - val_loss: 0.0059\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0038 - val_loss: 0.0084\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0035 - val_loss: 0.0106\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1e0bddca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5515 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 443ms/step - loss: 0.1707 - val_loss: 0.0061\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0381 - val_loss: 0.0179\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0213 - val_loss: 0.0235\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0215 - val_loss: 0.0234\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1dd57fd30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5516 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 468ms/step - loss: 1.2001 - val_loss: 0.0704\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.4965 - val_loss: 0.0157\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0643 - val_loss: 0.0054\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0264 - val_loss: 0.0058\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0303 - val_loss: 0.0074\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.0288 - val_loss: 0.0105\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1db0eb820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5517 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 284ms/step - loss: 0.0334 - val_loss: 0.0138\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0346 - val_loss: 0.0134\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0216 - val_loss: 0.0118\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0170 - val_loss: 0.0087\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0120 - val_loss: 0.0069\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0085 - val_loss: 0.0058\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0045 - val_loss: 0.0066\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0051 - val_loss: 0.0104\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0081 - val_loss: 0.0160\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1d8ed3c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5518 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0682 - val_loss: 0.0104\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.0425 - val_loss: 0.0146\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0188 - val_loss: 0.0097\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0106 - val_loss: 0.0068\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0082 - val_loss: 0.0060\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0079 - val_loss: 0.0058\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0060 - val_loss: 0.0058\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0047 - val_loss: 0.0058\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0068 - val_loss: 0.0059\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0054 - val_loss: 0.0059\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1f477f4c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5519 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 232ms/step - loss: 0.2408 - val_loss: 0.0112\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0469 - val_loss: 0.0065\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0215 - val_loss: 0.0056\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0181 - val_loss: 0.0060\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.015 - 0s 48ms/step - loss: 0.0168 - val_loss: 0.0060\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0097 - val_loss: 0.0058\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1f0ae9af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5520 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 385ms/step - loss: 0.0806 - val_loss: 0.0099\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0219 - val_loss: 0.0057\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0139 - val_loss: 0.0067\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0160 - val_loss: 0.0067\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0092 - val_loss: 0.0061\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1eef14160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5521 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 399ms/step - loss: 0.3486 - val_loss: 0.0995\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1140 - val_loss: 0.0253\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0410 - val_loss: 0.0170\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0295 - val_loss: 0.0166\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0205 - val_loss: 0.0191\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0117 - val_loss: 0.0207\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0080 - val_loss: 0.0206\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1ecbf0280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5522 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 447ms/step - loss: 0.0747 - val_loss: 0.0215\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0255 - val_loss: 0.0220\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0229 - val_loss: 0.0161\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0160 - val_loss: 0.0134\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0098 - val_loss: 0.0109\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.0084 - val_loss: 0.0067\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0087 - val_loss: 0.0064\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0076 - val_loss: 0.0071\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.0075 - val_loss: 0.0077\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0060 - val_loss: 0.0075\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb209ffd820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer layer_normalization_5523 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 200ms/step - loss: 0.0773 - val_loss: 0.0179\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0429 - val_loss: 0.0214\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0311 - val_loss: 0.0210\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0275 - val_loss: 0.0192\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb20b7ba940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "loss = []\n",
    "preds = []\n",
    "seed(1)\n",
    "for retrain_idx in range(552):\n",
    "    X = Xl.iloc[t_train_start[retrain_idx]:t_train_end[retrain_idx],:]\n",
    "    X_idx = X.apply(pd.Series.nunique) != 1\n",
    "    X = X.loc[:,X_idx]\n",
    "    X_val = Xl.loc[t_val_start[retrain_idx]:t_val_end[retrain_idx],X_idx]\n",
    "    X_test = Xl.loc[t_test_start[retrain_idx]:t_test_end[retrain_idx],X_idx]\n",
    "    y = y_agg.iloc[t_train_start[retrain_idx]:t_train_end[retrain_idx],:]\n",
    "    y_val = y_agg.loc[t_val_start[retrain_idx]:t_val_end[retrain_idx],:]\n",
    "    y_test = y_agg.loc[t_test_start[retrain_idx]:t_test_end[retrain_idx],:]\n",
    "    model = Sequential()\n",
    "    model.add(LayerNormalization())\n",
    "    model.add(Dense(128,activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(64,activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(32,activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(16,activation='relu'))\n",
    "    model.add(Dense(16,activation='relu'))\n",
    "    model.add(Dense(16,activation='relu'))\n",
    "    model.add(Dense(8,activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    optimizer = Adam(learning_rate=0.005)\n",
    "    model.compile(optimizer=optimizer,loss='mse')\n",
    "    early_stop = EarlyStopping(monitor='val_loss', verbose=0, patience=3)\n",
    "    history = model.fit(x=X,y=y,validation_data=(X_val,y_val), batch_size=64, epochs=100,verbose=1,callbacks=[early_stop])\n",
    "    preds.append(model.predict(X_test))\n",
    "    loss.append(min(history.history['val_loss']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_org = y_agg.loc[t_test_start[0]:t_test_end[551],:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate R^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   -0.489419\n",
       "dtype: float64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-np.sum((np.squeeze(y_org)-np.squeeze(preds))**2)/np.sum((y_org-np.mean(y_org))**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A good R^2 is expected to be between 0 to 0.05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Finance.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
