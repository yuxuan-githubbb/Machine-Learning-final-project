{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "NcDhtxLCV8Tw",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, LayerNormalization, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from numpy.random import seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 426
    },
    "id": "vI12F-E9V8T1",
    "outputId": "869138a1-ef3d-4c37-86c8-e408129de90a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "Xl = pd.read_csv('Xl.csv',header=None)\n",
    "Xs = pd.read_csv('Xs.csv',header=None)\n",
    "R = pd.read_csv('y.csv',header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_agg=R.iloc[::-1].rolling(window=12).sum().iloc[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "Psf8guRAV8T1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "t_train_start = list(range(46*12))\n",
    "t_train_end =[x+120 for x in t_train_start]\n",
    "t_val_start= [x for x in t_train_end]\n",
    "t_val_end = [x+60 for x in t_val_start]\n",
    "t_test_start = [x for x in t_val_end]\n",
    "t_test_end = [x for x in t_test_start]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(552,)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(t_test_end) #model needed to be retrained every month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "731"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_test_end[551]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3316 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.0297 - val_loss: 0.0387\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0206 - val_loss: 0.0321\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0205 - val_loss: 0.0326\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0163 - val_loss: 0.0343\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb35d53b670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3317 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.0511 - val_loss: 0.0320\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0333 - val_loss: 0.0368\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0155 - val_loss: 0.0411\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb36f6e03a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3318 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.3573 - val_loss: 0.0518\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1762 - val_loss: 0.0276\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0711 - val_loss: 0.0255\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0415 - val_loss: 0.0280\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0273 - val_loss: 0.0316\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb356fef670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3319 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.1678 - val_loss: 0.0354\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0353 - val_loss: 0.0312\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0207 - val_loss: 0.0307\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0152 - val_loss: 0.0328\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0210 - val_loss: 0.0335\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb357bde040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3320 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.0724 - val_loss: 0.0315\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0292 - val_loss: 0.0359\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1074 - val_loss: 0.0359\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3577fa700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3321 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.1921 - val_loss: 0.0317\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0990 - val_loss: 0.0344\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0473 - val_loss: 0.0385\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb352c93310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3322 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 0.7940 - val_loss: 0.0521\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3134 - val_loss: 0.0443\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1266 - val_loss: 0.0350\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0522 - val_loss: 0.0312\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0201 - val_loss: 0.0323\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0164 - val_loss: 0.0335\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3cb40a160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3323 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 308ms/step - loss: 0.0582 - val_loss: 0.0402\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0264 - val_loss: 0.0309\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0168 - val_loss: 0.0306\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0163 - val_loss: 0.0311\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0169 - val_loss: 0.0307\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb482486550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3324 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.2889 - val_loss: 0.0295\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1322 - val_loss: 0.0290\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0794 - val_loss: 0.0275\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0273 - val_loss: 0.0281\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0234 - val_loss: 0.0287\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb36e8a5040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3325 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.0365 - val_loss: 0.0367\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0275 - val_loss: 0.0311\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0296 - val_loss: 0.0315\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0255 - val_loss: 0.0299\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0213 - val_loss: 0.0294\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0156 - val_loss: 0.0295\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0135 - val_loss: 0.0287\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0125 - val_loss: 0.0280\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0112 - val_loss: 0.0285\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0101 - val_loss: 0.0289\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb350515f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3326 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.0278 - val_loss: 0.0342\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0257 - val_loss: 0.0319\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0110 - val_loss: 0.0322\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0118 - val_loss: 0.0324\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb34cc348b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3327 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.0764 - val_loss: 0.0337\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0496 - val_loss: 0.0335\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0330 - val_loss: 0.0401\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0258 - val_loss: 0.0491\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb34a64caf0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3328 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.0296 - val_loss: 0.0333\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0230 - val_loss: 0.0382\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0156 - val_loss: 0.0389\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb366925a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3329 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.0693 - val_loss: 0.0392\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1068 - val_loss: 0.0375\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0427 - val_loss: 0.0381\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0218 - val_loss: 0.0384\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3643ef040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3330 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.0565 - val_loss: 0.0429\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0383 - val_loss: 0.0379\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0257 - val_loss: 0.0380\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0145 - val_loss: 0.0377\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0099 - val_loss: 0.0364\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0099 - val_loss: 0.0357\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0095 - val_loss: 0.0352\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0091 - val_loss: 0.0349\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0081 - val_loss: 0.0346\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0075 - val_loss: 0.0342\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0072 - val_loss: 0.0342\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0066 - val_loss: 0.0344\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0066 - val_loss: 0.0343\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb36390b160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3331 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 1.3162 - val_loss: 0.0856\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6908 - val_loss: 0.0324\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1078 - val_loss: 0.0363\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0300 - val_loss: 0.0397\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb36e6cab80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3332 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 0.4579 - val_loss: 0.0617\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1672 - val_loss: 0.0358\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0445 - val_loss: 0.0317\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0622 - val_loss: 0.0293\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0303 - val_loss: 0.0300\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0170 - val_loss: 0.0320\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb37b526d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3333 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.1954 - val_loss: 0.0327\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0647 - val_loss: 0.0429\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0573 - val_loss: 0.0585\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3c592c550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3334 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.1486 - val_loss: 0.0297\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.1401 - val_loss: 0.0303\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0718 - val_loss: 0.0294\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0325 - val_loss: 0.0332\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0205 - val_loss: 0.0358\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3943a43a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3335 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.1478 - val_loss: 0.0399\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2173 - val_loss: 0.0447\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0878 - val_loss: 0.0437\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb37b43d700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3336 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 1s 601ms/step - loss: 0.0362 - val_loss: 0.0323\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0257 - val_loss: 0.0348\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0177 - val_loss: 0.0321\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0177 - val_loss: 0.0283\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0141 - val_loss: 0.0256\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0117 - val_loss: 0.0245\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0114 - val_loss: 0.0243\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0124 - val_loss: 0.0246\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.0102 - val_loss: 0.0251\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb379e87c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3337 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 1s 560ms/step - loss: 0.4303 - val_loss: 0.0551\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.2072 - val_loss: 0.0359\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0764 - val_loss: 0.0334\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0289 - val_loss: 0.0349\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0154 - val_loss: 0.0366\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3a3728b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3338 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 1s 885ms/step - loss: 0.0705 - val_loss: 0.0465\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0567 - val_loss: 0.0391\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0233 - val_loss: 0.0367\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0142 - val_loss: 0.0362\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0118 - val_loss: 0.0362\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0123 - val_loss: 0.0361\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0117 - val_loss: 0.0361\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0113 - val_loss: 0.0358\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0109 - val_loss: 0.0354\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0102 - val_loss: 0.0347\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0092 - val_loss: 0.0340\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0095 - val_loss: 0.0335\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0087 - val_loss: 0.0331\n",
      "Epoch 14/60\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0081 - val_loss: 0.0328\n",
      "Epoch 15/60\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0079 - val_loss: 0.0326\n",
      "Epoch 16/60\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0075 - val_loss: 0.0324\n",
      "Epoch 17/60\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0069 - val_loss: 0.0324\n",
      "Epoch 18/60\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0064 - val_loss: 0.0326\n",
      "Epoch 19/60\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0059 - val_loss: 0.0328\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb399568160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3339 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 1s 596ms/step - loss: 0.5315 - val_loss: 0.0547\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2250 - val_loss: 0.0361\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0731 - val_loss: 0.0346\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0379 - val_loss: 0.0340\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0210 - val_loss: 0.0344\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0186 - val_loss: 0.0353\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3c42a6f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3340 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 1s 553ms/step - loss: 0.5576 - val_loss: 0.0605\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2844 - val_loss: 0.0342\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0574 - val_loss: 0.0370\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0342 - val_loss: 0.0559\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3c3b8f310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3341 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.0950 - val_loss: 0.0360\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0310 - val_loss: 0.0362\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0439 - val_loss: 0.0380\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb40dd4f0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3342 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 0.1755 - val_loss: 0.0341\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0341 - val_loss: 0.0339\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0205 - val_loss: 0.0344\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0218 - val_loss: 0.0348\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3b9b271f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3343 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 0.0298 - val_loss: 0.0359\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0240 - val_loss: 0.0367\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0186 - val_loss: 0.0359\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0146 - val_loss: 0.0377\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0149 - val_loss: 0.0391\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3d126a160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3344 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 480ms/step - loss: 0.1124 - val_loss: 0.0344\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0422 - val_loss: 0.0356\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0205 - val_loss: 0.0361\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3d3766a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3345 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.1061 - val_loss: 0.1124\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0375 - val_loss: 0.0959\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0219 - val_loss: 0.0805\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.0194 - val_loss: 0.0677\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0182 - val_loss: 0.0565\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.0169 - val_loss: 0.0489\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0160 - val_loss: 0.0444\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0152 - val_loss: 0.0420\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.0142 - val_loss: 0.0376\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0134 - val_loss: 0.0344\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0129 - val_loss: 0.0350\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0125 - val_loss: 0.0357\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3e88d6dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3346 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.1775 - val_loss: 0.0382\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0622 - val_loss: 0.0341\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0291 - val_loss: 0.0378\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0149 - val_loss: 0.0389\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb433522550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3347 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.0400 - val_loss: 0.0340\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0211 - val_loss: 0.0346\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0174 - val_loss: 0.0365\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb41d13f820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3348 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.0578 - val_loss: 0.0341\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0258 - val_loss: 0.0361\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0209 - val_loss: 0.0350\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3f1ee0040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3349 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.2309 - val_loss: 0.0384\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0528 - val_loss: 0.0392\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0180 - val_loss: 0.0378\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0188 - val_loss: 0.0372\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0187 - val_loss: 0.0355\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0148 - val_loss: 0.0346\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0128 - val_loss: 0.0342\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0118 - val_loss: 0.0339\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0101 - val_loss: 0.0334\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0090 - val_loss: 0.0330\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0085 - val_loss: 0.0328\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0086 - val_loss: 0.0325\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0085 - val_loss: 0.0321\n",
      "Epoch 14/60\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0083 - val_loss: 0.0316\n",
      "Epoch 15/60\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0079 - val_loss: 0.0311\n",
      "Epoch 16/60\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0076 - val_loss: 0.0307\n",
      "Epoch 17/60\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0075 - val_loss: 0.0305\n",
      "Epoch 18/60\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0068 - val_loss: 0.0304\n",
      "Epoch 19/60\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0066 - val_loss: 0.0302\n",
      "Epoch 20/60\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0065 - val_loss: 0.0302\n",
      "Epoch 21/60\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0062 - val_loss: 0.0303\n",
      "Epoch 22/60\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0060 - val_loss: 0.0303\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3cb679310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3350 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 1s 807ms/step - loss: 0.0522 - val_loss: 0.0348\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0171 - val_loss: 0.0303\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0117 - val_loss: 0.0302\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0153 - val_loss: 0.0311\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0116 - val_loss: 0.0333\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3d48d5040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3351 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 1s 508ms/step - loss: 0.0335 - val_loss: 0.0345\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0289 - val_loss: 0.0338\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0164 - val_loss: 0.0335\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0105 - val_loss: 0.0333\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0119 - val_loss: 0.0332\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0133 - val_loss: 0.0321\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0125 - val_loss: 0.0311\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0103 - val_loss: 0.0314\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0088 - val_loss: 0.0317\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3c5729c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3352 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.0629 - val_loss: 0.0344\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0378 - val_loss: 0.0373\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0190 - val_loss: 0.0404\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3a9997160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3353 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 1.1361 - val_loss: 0.0923\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0886 - val_loss: 0.0534\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0372 - val_loss: 0.0438\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0178 - val_loss: 0.0394\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0109 - val_loss: 0.0393\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0113 - val_loss: 0.0394\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0110 - val_loss: 0.0395\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3cbd29550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3354 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.1915 - val_loss: 0.0340\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0624 - val_loss: 0.0316\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0185 - val_loss: 0.0334\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0173 - val_loss: 0.0365\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3aa95e280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3355 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 0.0394 - val_loss: 0.0434\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0309 - val_loss: 0.0398\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0199 - val_loss: 0.0372\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0140 - val_loss: 0.0345\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0141 - val_loss: 0.0338\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0102 - val_loss: 0.0338\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0069 - val_loss: 0.0340\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3a57ae310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3356 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 1.1845 - val_loss: 0.0339\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5668 - val_loss: 0.0340\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0862 - val_loss: 0.0365\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3a6656310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3357 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 299ms/step - loss: 0.0606 - val_loss: 0.0325\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0364 - val_loss: 0.0310\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0553 - val_loss: 0.0312\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.0421 - val_loss: 0.0337\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3930c01f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3358 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 1s 526ms/step - loss: 0.0699 - val_loss: 0.0324\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0210 - val_loss: 0.0343\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0162 - val_loss: 0.0345\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3d6337550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3359 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.5040 - val_loss: 0.0464\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.1707 - val_loss: 0.0428\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1199 - val_loss: 0.0404\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0354 - val_loss: 0.0414\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0198 - val_loss: 0.0403\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0168 - val_loss: 0.0380\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0133 - val_loss: 0.0361\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0121 - val_loss: 0.0345\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0117 - val_loss: 0.0325\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0090 - val_loss: 0.0316\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0077 - val_loss: 0.0312\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0069 - val_loss: 0.0311\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0063 - val_loss: 0.0310\n",
      "Epoch 14/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0057 - val_loss: 0.0308\n",
      "Epoch 15/60\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0053 - val_loss: 0.0304\n",
      "Epoch 16/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0051 - val_loss: 0.0301\n",
      "Epoch 17/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0049 - val_loss: 0.0298\n",
      "Epoch 18/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0046 - val_loss: 0.0294\n",
      "Epoch 19/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0043 - val_loss: 0.0292\n",
      "Epoch 20/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0040 - val_loss: 0.0290\n",
      "Epoch 21/60\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0037 - val_loss: 0.0288\n",
      "Epoch 22/60\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0035 - val_loss: 0.0286\n",
      "Epoch 23/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0034 - val_loss: 0.0283\n",
      "Epoch 24/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0033 - val_loss: 0.0281\n",
      "Epoch 25/60\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0032 - val_loss: 0.0279\n",
      "Epoch 26/60\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0031 - val_loss: 0.0277\n",
      "Epoch 27/60\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0031 - val_loss: 0.0276\n",
      "Epoch 28/60\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0030 - val_loss: 0.0274\n",
      "Epoch 29/60\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0029 - val_loss: 0.0273\n",
      "Epoch 30/60\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0029 - val_loss: 0.0272\n",
      "Epoch 31/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0028 - val_loss: 0.0271\n",
      "Epoch 32/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0027 - val_loss: 0.0270\n",
      "Epoch 33/60\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0027 - val_loss: 0.0270\n",
      "Epoch 34/60\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0026 - val_loss: 0.0270\n",
      "Epoch 35/60\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0026 - val_loss: 0.0271\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb36de3e430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3360 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 1.0093 - val_loss: 0.0319\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.4641 - val_loss: 0.0314\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0695 - val_loss: 0.0335\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0181 - val_loss: 0.0368\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb36ee2c550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3361 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 478ms/step - loss: 0.3797 - val_loss: 0.2058\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.1040 - val_loss: 0.1029\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0699 - val_loss: 0.0554\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0283 - val_loss: 0.0349\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0174 - val_loss: 0.0311\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0137 - val_loss: 0.0303\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0107 - val_loss: 0.0298\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0106 - val_loss: 0.0301\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0085 - val_loss: 0.0308\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb36f748700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3362 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 1s 502ms/step - loss: 0.0234 - val_loss: 0.0324\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0125 - val_loss: 0.0336\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0089 - val_loss: 0.0339\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3744d2160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3363 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.1225 - val_loss: 0.0330\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0305 - val_loss: 0.0337\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0198 - val_loss: 0.0368\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb37bf679d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3364 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.8610 - val_loss: 0.0570\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4146 - val_loss: 0.0410\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1867 - val_loss: 0.0329\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0522 - val_loss: 0.0315\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0282 - val_loss: 0.0312\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0222 - val_loss: 0.0307\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0190 - val_loss: 0.0306\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0152 - val_loss: 0.0311\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0144 - val_loss: 0.0315\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb417e4ce50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3365 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 475ms/step - loss: 0.1190 - val_loss: 0.0308\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0844 - val_loss: 0.0364\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0198 - val_loss: 0.0371\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3e04d9670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3366 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.0555 - val_loss: 0.0352\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0157 - val_loss: 0.0319\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0162 - val_loss: 0.0327\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0085 - val_loss: 0.0332\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb35c104700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3367 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.0604 - val_loss: 0.0350\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0280 - val_loss: 0.0359\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0294 - val_loss: 0.0366\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb379077670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3368 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.2773 - val_loss: 0.0301\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.0802 - val_loss: 0.0305\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0265 - val_loss: 0.0339\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb356c3f820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3369 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.1431 - val_loss: 0.0333\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0810 - val_loss: 0.0323\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0201 - val_loss: 0.0308\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0098 - val_loss: 0.0321\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0110 - val_loss: 0.0347\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3574c2d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3370 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.1349 - val_loss: 0.0321\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0506 - val_loss: 0.0356\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0215 - val_loss: 0.0375\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb357aad430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3371 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 1s 631ms/step - loss: 0.1936 - val_loss: 0.0394\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1225 - val_loss: 0.0351\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0557 - val_loss: 0.0315\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0357 - val_loss: 0.0290\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0240 - val_loss: 0.0285\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0167 - val_loss: 0.0284\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0123 - val_loss: 0.0282\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0101 - val_loss: 0.0282\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0089 - val_loss: 0.0284\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb35c60f3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3372 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.1446 - val_loss: 0.0326\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0299 - val_loss: 0.0346\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0156 - val_loss: 0.0347\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb35da33670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3373 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.1894 - val_loss: 0.0276\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1507 - val_loss: 0.0322\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0426 - val_loss: 0.0471\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3395294c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3374 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1509 - val_loss: 0.0274\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0675 - val_loss: 0.0226\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0219 - val_loss: 0.0322\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0143 - val_loss: 0.0426\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb33f4afb80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3375 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.0372 - val_loss: 0.0285\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0192 - val_loss: 0.0285\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0223 - val_loss: 0.0279\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0112 - val_loss: 0.0274\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0116 - val_loss: 0.0271\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0105 - val_loss: 0.0265\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0077 - val_loss: 0.0257\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0065 - val_loss: 0.0250\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0058 - val_loss: 0.0243\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0051 - val_loss: 0.0237\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0048 - val_loss: 0.0232\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0045 - val_loss: 0.0228\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0041 - val_loss: 0.0226\n",
      "Epoch 14/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0040 - val_loss: 0.0227\n",
      "Epoch 15/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0037 - val_loss: 0.0228\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb452867ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3376 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.0881 - val_loss: 0.0229\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1074 - val_loss: 0.0343\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0191 - val_loss: 0.0472\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3c5569ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3377 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.0347 - val_loss: 0.0212\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0187 - val_loss: 0.0230\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0150 - val_loss: 0.0241\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb45af79310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3378 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.0725 - val_loss: 0.0237\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0449 - val_loss: 0.0185\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0230 - val_loss: 0.0193\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0132 - val_loss: 0.0227\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3d4a73e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3379 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.4028 - val_loss: 0.0899\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0978 - val_loss: 0.0303\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0298 - val_loss: 0.0123\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0272 - val_loss: 0.0108\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0265 - val_loss: 0.0106\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0252 - val_loss: 0.0107\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0194 - val_loss: 0.0109\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3418ad430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3380 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.1482 - val_loss: 0.0203\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0312 - val_loss: 0.0151\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0209 - val_loss: 0.0131\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0179 - val_loss: 0.0131\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0125 - val_loss: 0.0135\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0111 - val_loss: 0.0138\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3330dfaf0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3381 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 1.4293 - val_loss: 0.0669\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3892 - val_loss: 0.0241\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0593 - val_loss: 0.0130\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0244 - val_loss: 0.0127\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0232 - val_loss: 0.0174\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0246 - val_loss: 0.0243\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb327c39af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3382 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 0.1889 - val_loss: 0.0275\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0781 - val_loss: 0.0336\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0282 - val_loss: 0.0380\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb33308ea60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3383 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.0578 - val_loss: 0.0254\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0230 - val_loss: 0.0182\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0196 - val_loss: 0.0139\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0146 - val_loss: 0.0124\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0156 - val_loss: 0.0152\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0119 - val_loss: 0.0189\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3408ae550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3384 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.0377 - val_loss: 0.0166\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0250 - val_loss: 0.0174\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0171 - val_loss: 0.0193\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb34718c670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3385 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.3091 - val_loss: 0.0377\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0491 - val_loss: 0.0223\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0530 - val_loss: 0.0181\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0256 - val_loss: 0.0170\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0166 - val_loss: 0.0164\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0185 - val_loss: 0.0163\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0116 - val_loss: 0.0163\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0083 - val_loss: 0.0162\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0074 - val_loss: 0.0165\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0065 - val_loss: 0.0173\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb32e07b670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3386 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.1022 - val_loss: 0.0254\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0317 - val_loss: 0.0165\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0192 - val_loss: 0.0145\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0115 - val_loss: 0.0137\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0103 - val_loss: 0.0131\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0097 - val_loss: 0.0128\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0087 - val_loss: 0.0129\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0089 - val_loss: 0.0134\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb345266550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3387 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.4232 - val_loss: 0.0302\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1265 - val_loss: 0.0410\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0514 - val_loss: 0.0392\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb32c9614c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3388 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.7341 - val_loss: 0.0191\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0654 - val_loss: 0.0368\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0702 - val_loss: 0.0559\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb317e651f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3389 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.3805 - val_loss: 0.0421\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1251 - val_loss: 0.0309\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0501 - val_loss: 0.0240\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0289 - val_loss: 0.0207\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0213 - val_loss: 0.0187\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0178 - val_loss: 0.0173\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0172 - val_loss: 0.0163\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0174 - val_loss: 0.0154\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0172 - val_loss: 0.0145\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0169 - val_loss: 0.0139\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0156 - val_loss: 0.0133\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0142 - val_loss: 0.0128\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0128 - val_loss: 0.0124\n",
      "Epoch 14/60\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0117 - val_loss: 0.0121\n",
      "Epoch 15/60\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0107 - val_loss: 0.0117\n",
      "Epoch 16/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0099 - val_loss: 0.0115\n",
      "Epoch 17/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0091 - val_loss: 0.0116\n",
      "Epoch 18/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0086 - val_loss: 0.0117\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb319328160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3390 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.0589 - val_loss: 0.0234\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0302 - val_loss: 0.0180\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0196 - val_loss: 0.0142\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0177 - val_loss: 0.0126\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0143 - val_loss: 0.0120\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0148 - val_loss: 0.0121\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0140 - val_loss: 0.0124\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb31a0431f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3391 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.3117 - val_loss: 0.0440\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0787 - val_loss: 0.0639\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0483 - val_loss: 0.0589\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb31a4ea040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3392 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 1s 668ms/step - loss: 0.0399 - val_loss: 0.0269\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0183 - val_loss: 0.0209\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0157 - val_loss: 0.0200\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0100 - val_loss: 0.0199\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0088 - val_loss: 0.0193\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0079 - val_loss: 0.0185\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0070 - val_loss: 0.0187\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0061 - val_loss: 0.0200\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb31b0b1d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3393 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.2990 - val_loss: 0.0154\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2892 - val_loss: 0.0209\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0476 - val_loss: 0.0260\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb31b58bc10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3394 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 484ms/step - loss: 0.1832 - val_loss: 0.0129\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0499 - val_loss: 0.0189\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0240 - val_loss: 0.0317\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb31c279ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3395 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 490ms/step - loss: 0.1027 - val_loss: 0.0275\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0408 - val_loss: 0.0160\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0277 - val_loss: 0.0139\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0154 - val_loss: 0.0131\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0154 - val_loss: 0.0131\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0158 - val_loss: 0.0137\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb31c7619d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3396 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 0.6351 - val_loss: 0.0157\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1227 - val_loss: 0.0345\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0768 - val_loss: 0.0504\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb31e040a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3397 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.0438 - val_loss: 0.0185\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0565 - val_loss: 0.0125\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0266 - val_loss: 0.0168\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0280 - val_loss: 0.0203\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb31f57c790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3398 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 0.5826 - val_loss: 0.0702\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1276 - val_loss: 0.0478\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0479 - val_loss: 0.0324\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0288 - val_loss: 0.0210\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0222 - val_loss: 0.0183\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0201 - val_loss: 0.0169\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0174 - val_loss: 0.0157\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0135 - val_loss: 0.0145\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0123 - val_loss: 0.0135\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0113 - val_loss: 0.0127\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0104 - val_loss: 0.0120\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0096 - val_loss: 0.0116\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0093 - val_loss: 0.0113\n",
      "Epoch 14/60\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0088 - val_loss: 0.0112\n",
      "Epoch 15/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.008 - 0s 35ms/step - loss: 0.0089 - val_loss: 0.0112\n",
      "Epoch 16/60\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0088 - val_loss: 0.0112\n",
      "Epoch 17/60\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0084 - val_loss: 0.0112\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb320a48670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3399 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 0.0337 - val_loss: 0.0167\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0234 - val_loss: 0.0150\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0156 - val_loss: 0.0133\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0102 - val_loss: 0.0127\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0089 - val_loss: 0.0127\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0081 - val_loss: 0.0126\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0071 - val_loss: 0.0123\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0065 - val_loss: 0.0116\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0058 - val_loss: 0.0114\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0050 - val_loss: 0.0114\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0047 - val_loss: 0.0115\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0044 - val_loss: 0.0117\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb322d43670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3400 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.1523 - val_loss: 0.0159\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0456 - val_loss: 0.0255\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0335 - val_loss: 0.0253\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3252125e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3401 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 1s 628ms/step - loss: 0.0377 - val_loss: 0.0253\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0291 - val_loss: 0.0288\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0156 - val_loss: 0.0311\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb32671e4c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3402 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.2576 - val_loss: 0.0365\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0730 - val_loss: 0.0289\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0302 - val_loss: 0.0234\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0279 - val_loss: 0.0202\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0236 - val_loss: 0.0177\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0171 - val_loss: 0.0157\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0159 - val_loss: 0.0144\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0147 - val_loss: 0.0137\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.0133 - val_loss: 0.0132\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0120 - val_loss: 0.0129\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0112 - val_loss: 0.0127\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0109 - val_loss: 0.0126\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0103 - val_loss: 0.0126\n",
      "Epoch 14/60\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0096 - val_loss: 0.0127\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb30a3bb1f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3403 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.0666 - val_loss: 0.0451\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0247 - val_loss: 0.0819\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0663 - val_loss: 0.0559\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb30b1b70d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3404 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.1484 - val_loss: 0.0244\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0778 - val_loss: 0.0237\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0305 - val_loss: 0.0250\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0220 - val_loss: 0.0257\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb30d4af1f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3405 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 0.4802 - val_loss: 0.0445\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1230 - val_loss: 0.0262\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0416 - val_loss: 0.0168\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0204 - val_loss: 0.0159\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0182 - val_loss: 0.0155\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0154 - val_loss: 0.0149\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0139 - val_loss: 0.0144\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0141 - val_loss: 0.0144\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0122 - val_loss: 0.0144\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0098 - val_loss: 0.0144\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0081 - val_loss: 0.0145\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb30eab8040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3406 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 1.7793 - val_loss: 0.0844\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.7271 - val_loss: 0.0367\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2611 - val_loss: 0.0160\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0862 - val_loss: 0.0155\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0419 - val_loss: 0.0154\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0357 - val_loss: 0.0150\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0335 - val_loss: 0.0150\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0350 - val_loss: 0.0156\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0312 - val_loss: 0.0159\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3259c38b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3407 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.2764 - val_loss: 0.0156\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1809 - val_loss: 0.0212\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0260 - val_loss: 0.0363\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3a88c11f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3408 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 1.1294 - val_loss: 0.0404\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4180 - val_loss: 0.0189\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1520 - val_loss: 0.0159\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0608 - val_loss: 0.0177\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0333 - val_loss: 0.0207\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb363d6bdc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3409 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.0517 - val_loss: 0.0153\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0396 - val_loss: 0.0157\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0213 - val_loss: 0.0181\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb36e0b5700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3410 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 299ms/step - loss: 0.0696 - val_loss: 0.0245\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0422 - val_loss: 0.0177\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0301 - val_loss: 0.0157\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0524 - val_loss: 0.0154\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0318 - val_loss: 0.0155\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0212 - val_loss: 0.0155\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3a9864310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3411 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 0.0464 - val_loss: 0.0533\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0512 - val_loss: 0.0640\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0201 - val_loss: 0.0614\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3e88d6ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3412 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.0570 - val_loss: 0.0262\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0420 - val_loss: 0.0278\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0187 - val_loss: 0.0297\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3a3728820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3413 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 0.5545 - val_loss: 0.0289\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1296 - val_loss: 0.0242\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0444 - val_loss: 0.0220\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0228 - val_loss: 0.0211\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0191 - val_loss: 0.0201\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0173 - val_loss: 0.0191\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0162 - val_loss: 0.0182\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0163 - val_loss: 0.0177\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0165 - val_loss: 0.0170\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0150 - val_loss: 0.0162\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0126 - val_loss: 0.0155\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0111 - val_loss: 0.0151\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0101 - val_loss: 0.0150\n",
      "Epoch 14/60\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0099 - val_loss: 0.0148\n",
      "Epoch 15/60\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0088 - val_loss: 0.0147\n",
      "Epoch 16/60\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0079 - val_loss: 0.0147\n",
      "Epoch 17/60\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0072 - val_loss: 0.0149\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb34a81fe50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3414 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.1123 - val_loss: 0.0153\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0339 - val_loss: 0.0164\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0278 - val_loss: 0.0181\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb352c93c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3415 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 1s 893ms/step - loss: 0.0554 - val_loss: 0.0154\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.0186 - val_loss: 0.0255\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0323 - val_loss: 0.0260\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3cc25d8b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3416 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.1305 - val_loss: 0.0217\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0454 - val_loss: 0.0263\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0279 - val_loss: 0.0309\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb30bb61ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3417 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:5 out of the last 27 calls to <function Model.make_train_function.<locals>.train_function at 0x7fb30ab1daf0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1580WARNING:tensorflow:5 out of the last 27 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb30a3bb670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.1580 - val_loss: 0.0324\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0572 - val_loss: 0.0374\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0378 - val_loss: 0.0411\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb326fa2550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3418 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x7fb307c5a670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0529WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb3237c01f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.0529 - val_loss: 0.0219\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0330 - val_loss: 0.0205\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0397 - val_loss: 0.0214\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0346 - val_loss: 0.0237\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb322201790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3419 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.2762 - val_loss: 0.0429\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0548 - val_loss: 0.0441\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0438 - val_loss: 0.0386\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0272 - val_loss: 0.0340\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0237 - val_loss: 0.0308\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0160 - val_loss: 0.0281\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0159 - val_loss: 0.0268\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0151 - val_loss: 0.0261\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0117 - val_loss: 0.0257\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0097 - val_loss: 0.0258\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0085 - val_loss: 0.0261\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb31ee344c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3420 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.5343 - val_loss: 0.0723\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1999 - val_loss: 0.0396\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0422 - val_loss: 0.0300\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0167 - val_loss: 0.0253\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0155 - val_loss: 0.0234\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0156 - val_loss: 0.0230\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0166 - val_loss: 0.0226\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0175 - val_loss: 0.0222\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0166 - val_loss: 0.0216\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0159 - val_loss: 0.0212\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0158 - val_loss: 0.0210\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0154 - val_loss: 0.0209\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0144 - val_loss: 0.0209\n",
      "Epoch 14/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0132 - val_loss: 0.0209\n",
      "Epoch 15/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0119 - val_loss: 0.0210\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb31c148700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3421 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 1s 956ms/step - loss: 0.2215 - val_loss: 0.0712\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1117 - val_loss: 0.0887\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0788 - val_loss: 0.0862\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb319446ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3422 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.1457 - val_loss: 0.0295\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0472 - val_loss: 0.0318\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0374 - val_loss: 0.0347\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb35c2984c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3423 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 1s 578ms/step - loss: 0.0804 - val_loss: 0.0464\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0326 - val_loss: 0.0397\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0225 - val_loss: 0.0373\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0206 - val_loss: 0.0381\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0153 - val_loss: 0.0360\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0118 - val_loss: 0.0339\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0094 - val_loss: 0.0329\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0085 - val_loss: 0.0331\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0074 - val_loss: 0.0333\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb32e037c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3424 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.2206 - val_loss: 0.0529\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1214 - val_loss: 0.0580\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0522 - val_loss: 0.0523\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0300 - val_loss: 0.0518\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0273 - val_loss: 0.0562\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0258 - val_loss: 0.0629\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb32c4f2670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3425 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.1151 - val_loss: 0.0518\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0337 - val_loss: 0.0482\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0275 - val_loss: 0.0415\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0184 - val_loss: 0.0378\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0189 - val_loss: 0.0363\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0099 - val_loss: 0.0349\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0114 - val_loss: 0.0345\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0103 - val_loss: 0.0351\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0076 - val_loss: 0.0362\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb35b839790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3426 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 1.3715 - val_loss: 0.2461\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6344 - val_loss: 0.1670\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.1875 - val_loss: 0.1111\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0746 - val_loss: 0.0700\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0870 - val_loss: 0.0458\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0934 - val_loss: 0.0352\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0870 - val_loss: 0.0320\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0753 - val_loss: 0.0315\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0598 - val_loss: 0.0318\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0469 - val_loss: 0.0321\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb43315a0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3427 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 0.0748 - val_loss: 0.0340\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0593 - val_loss: 0.0634\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0275 - val_loss: 0.0865\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb34b3d3700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3428 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.0311 - val_loss: 0.0881\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0238 - val_loss: 0.0771\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0147 - val_loss: 0.0783\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0126 - val_loss: 0.0703\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0079 - val_loss: 0.0645\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0065 - val_loss: 0.0614\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0053 - val_loss: 0.0561\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0046 - val_loss: 0.0508\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0045 - val_loss: 0.0471\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0043 - val_loss: 0.0464\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0039 - val_loss: 0.0461\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0037 - val_loss: 0.0451\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0036 - val_loss: 0.0436\n",
      "Epoch 14/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0034 - val_loss: 0.0417\n",
      "Epoch 15/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0032 - val_loss: 0.0396\n",
      "Epoch 16/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0031 - val_loss: 0.0379\n",
      "Epoch 17/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0031 - val_loss: 0.0364\n",
      "Epoch 18/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0028 - val_loss: 0.0352\n",
      "Epoch 19/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0026 - val_loss: 0.0341\n",
      "Epoch 20/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0026 - val_loss: 0.0328\n",
      "Epoch 21/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0025 - val_loss: 0.0318\n",
      "Epoch 22/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0024 - val_loss: 0.0311\n",
      "Epoch 23/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0023 - val_loss: 0.0305\n",
      "Epoch 24/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0023 - val_loss: 0.0303\n",
      "Epoch 25/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0022 - val_loss: 0.0302\n",
      "Epoch 26/60\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0020 - val_loss: 0.0301\n",
      "Epoch 27/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0019 - val_loss: 0.0299\n",
      "Epoch 28/60\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0019 - val_loss: 0.0299\n",
      "Epoch 29/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0018 - val_loss: 0.0301\n",
      "Epoch 30/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0018 - val_loss: 0.0305\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb33dacff70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3429 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.0822 - val_loss: 0.0357\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0426 - val_loss: 0.0421\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0272 - val_loss: 0.0457\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb35df53160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3430 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.1203 - val_loss: 0.0453\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0518 - val_loss: 0.0531\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0280 - val_loss: 0.0488\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb35cb8ba60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3431 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 1.4219 - val_loss: 0.0241\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4547 - val_loss: 0.0260\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.1873 - val_loss: 0.0476\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb357aadca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3432 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:5 out of the last 40 calls to <function Model.make_train_function.<locals>.train_function at 0x7fb357a3baf0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0589WARNING:tensorflow:5 out of the last 40 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb357417dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.0589 - val_loss: 0.0362\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0283 - val_loss: 0.0230\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0306 - val_loss: 0.0236\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0224 - val_loss: 0.0244\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3572e99d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3433 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.1935 - val_loss: 0.0385\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0580 - val_loss: 0.0444\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0311 - val_loss: 0.0480\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb356a50e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3434 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.0532 - val_loss: 0.0387\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0247 - val_loss: 0.0423\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0172 - val_loss: 0.0411\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb36399cc10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3435 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.0717 - val_loss: 0.0688\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0591 - val_loss: 0.0756\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0515 - val_loss: 0.0751\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3d35dd9d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3436 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:5 out of the last 14 calls to <function Model.make_train_function.<locals>.train_function at 0x7fb40c085d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6488WARNING:tensorflow:5 out of the last 14 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb37d5be280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.6488 - val_loss: 0.0566\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.1310 - val_loss: 0.0952\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0965 - val_loss: 0.1042\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb44cfbedc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3437 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x7fb44e4a79d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7302WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb3766563a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.7302 - val_loss: 0.0595\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2564 - val_loss: 0.0531\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1202 - val_loss: 0.0490\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0514 - val_loss: 0.0444\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0304 - val_loss: 0.0415\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0227 - val_loss: 0.0402\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0211 - val_loss: 0.0390\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0191 - val_loss: 0.0381\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0179 - val_loss: 0.0368\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0174 - val_loss: 0.0357\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0160 - val_loss: 0.0346\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0148 - val_loss: 0.0334\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0139 - val_loss: 0.0323\n",
      "Epoch 14/60\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0132 - val_loss: 0.0312\n",
      "Epoch 15/60\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0125 - val_loss: 0.0302\n",
      "Epoch 16/60\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0117 - val_loss: 0.0293\n",
      "Epoch 17/60\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0110 - val_loss: 0.0285\n",
      "Epoch 18/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0104 - val_loss: 0.0279\n",
      "Epoch 19/60\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0099 - val_loss: 0.0274\n",
      "Epoch 20/60\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0097 - val_loss: 0.0269\n",
      "Epoch 21/60\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0093 - val_loss: 0.0265\n",
      "Epoch 22/60\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0088 - val_loss: 0.0261\n",
      "Epoch 23/60\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0083 - val_loss: 0.0258\n",
      "Epoch 24/60\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0080 - val_loss: 0.0255\n",
      "Epoch 25/60\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0078 - val_loss: 0.0254\n",
      "Epoch 26/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0076 - val_loss: 0.0253\n",
      "Epoch 27/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0073 - val_loss: 0.0253\n",
      "Epoch 28/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0071 - val_loss: 0.0253\n",
      "Epoch 29/60\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0069 - val_loss: 0.0253\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb374b9aee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3438 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.0536 - val_loss: 0.0657\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0489 - val_loss: 0.0556\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0402 - val_loss: 0.0347\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0231 - val_loss: 0.0329\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0188 - val_loss: 0.0295\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0145 - val_loss: 0.0243\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0109 - val_loss: 0.0226\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0099 - val_loss: 0.0238\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0099 - val_loss: 0.0251\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb36f359310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3439 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 291ms/step - loss: 0.0796 - val_loss: 0.0400\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0247 - val_loss: 0.0304\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0413 - val_loss: 0.0264\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0212 - val_loss: 0.0285\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0203 - val_loss: 0.0294\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb36e622670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3440 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.1283 - val_loss: 0.1203\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0252 - val_loss: 0.1149\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0208 - val_loss: 0.1047\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0207 - val_loss: 0.0921\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0673 - val_loss: 0.0802\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0158 - val_loss: 0.0627\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0131 - val_loss: 0.0488\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0129 - val_loss: 0.0422\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0119 - val_loss: 0.0412\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0094 - val_loss: 0.0418\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0087 - val_loss: 0.0409\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0080 - val_loss: 0.0381\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0074 - val_loss: 0.0359\n",
      "Epoch 14/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0069 - val_loss: 0.0346\n",
      "Epoch 15/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0066 - val_loss: 0.0340\n",
      "Epoch 16/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0064 - val_loss: 0.0340\n",
      "Epoch 17/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0065 - val_loss: 0.0343\n",
      "Epoch 18/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0057 - val_loss: 0.0347\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb37b1b70d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3441 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.1539 - val_loss: 0.0263\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0613 - val_loss: 0.0306\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0570 - val_loss: 0.0347\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb38fd2c8b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3442 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.1414 - val_loss: 0.1566\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0401 - val_loss: 0.0930\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0168 - val_loss: 0.0537\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0178 - val_loss: 0.0461\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0144 - val_loss: 0.0445\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0130 - val_loss: 0.0438\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0120 - val_loss: 0.0432\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0085 - val_loss: 0.0428\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0070 - val_loss: 0.0424\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0061 - val_loss: 0.0421\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0057 - val_loss: 0.0418\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0056 - val_loss: 0.0415\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0051 - val_loss: 0.0413\n",
      "Epoch 14/60\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0048 - val_loss: 0.0410\n",
      "Epoch 15/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0047 - val_loss: 0.0404\n",
      "Epoch 16/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0044 - val_loss: 0.0396\n",
      "Epoch 17/60\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0042 - val_loss: 0.0388\n",
      "Epoch 18/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0044 - val_loss: 0.0382\n",
      "Epoch 19/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0038 - val_loss: 0.0374\n",
      "Epoch 20/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0037 - val_loss: 0.0362\n",
      "Epoch 21/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0035 - val_loss: 0.0350\n",
      "Epoch 22/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0036 - val_loss: 0.0347\n",
      "Epoch 23/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0033 - val_loss: 0.0349\n",
      "Epoch 24/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0034 - val_loss: 0.0350\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3a6335a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3443 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 1.3848 - val_loss: 0.0680\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1843 - val_loss: 0.0697\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0909 - val_loss: 0.0609\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0316 - val_loss: 0.0487\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0234 - val_loss: 0.0438\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0193 - val_loss: 0.0415\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0203 - val_loss: 0.0394\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0223 - val_loss: 0.0379\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0228 - val_loss: 0.0369\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0232 - val_loss: 0.0359\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0225 - val_loss: 0.0350\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0215 - val_loss: 0.0344\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0211 - val_loss: 0.0342\n",
      "Epoch 14/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0203 - val_loss: 0.0340\n",
      "Epoch 15/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0187 - val_loss: 0.0340\n",
      "Epoch 16/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0181 - val_loss: 0.0341\n",
      "Epoch 17/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0169 - val_loss: 0.0341\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3a89431f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3444 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.4001 - val_loss: 0.0457\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1097 - val_loss: 0.0508\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0286 - val_loss: 0.0515\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3cae7b8b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3445 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.2349 - val_loss: 0.0721\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0707 - val_loss: 0.0787\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0296 - val_loss: 0.0830\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3c637a310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3446 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 301ms/step - loss: 0.0661 - val_loss: 0.0457\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0146 - val_loss: 0.0434\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0111 - val_loss: 0.0409\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0091 - val_loss: 0.0381\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0089 - val_loss: 0.0349\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0096 - val_loss: 0.0318\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0079 - val_loss: 0.0282\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0067 - val_loss: 0.0258\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0057 - val_loss: 0.0248\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0050 - val_loss: 0.0245\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0047 - val_loss: 0.0243\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0042 - val_loss: 0.0244\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0038 - val_loss: 0.0247\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb4642179d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3447 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.3060 - val_loss: 0.0793\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1124 - val_loss: 0.0742\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0637 - val_loss: 0.0656\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0446 - val_loss: 0.0453\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0289 - val_loss: 0.0381\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0142 - val_loss: 0.0300\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0101 - val_loss: 0.0267\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0093 - val_loss: 0.0260\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0112 - val_loss: 0.0261\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0105 - val_loss: 0.0262\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3cba6b160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3448 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 0.0537 - val_loss: 0.0444\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0303 - val_loss: 0.0415\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0170 - val_loss: 0.0385\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0147 - val_loss: 0.0361\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0093 - val_loss: 0.0335\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0083 - val_loss: 0.0316\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0086 - val_loss: 0.0312\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0075 - val_loss: 0.0308\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0068 - val_loss: 0.0305\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0064 - val_loss: 0.0306\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0059 - val_loss: 0.0310\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb41c3351f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3449 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.4767 - val_loss: 0.0479\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.1117 - val_loss: 0.0289\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0600 - val_loss: 0.0262\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0280 - val_loss: 0.0276\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0199 - val_loss: 0.0293\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb427984310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3450 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.1691 - val_loss: 0.0611\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0782 - val_loss: 0.0447\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0365 - val_loss: 0.0372\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0216 - val_loss: 0.0323\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0182 - val_loss: 0.0324\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0140 - val_loss: 0.0317\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0108 - val_loss: 0.0303\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0099 - val_loss: 0.0284\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0088 - val_loss: 0.0265\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0081 - val_loss: 0.0254\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0078 - val_loss: 0.0248\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0078 - val_loss: 0.0244\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0074 - val_loss: 0.0242\n",
      "Epoch 14/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0073 - val_loss: 0.0241\n",
      "Epoch 15/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0068 - val_loss: 0.0241\n",
      "Epoch 16/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0063 - val_loss: 0.0240\n",
      "Epoch 17/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0061 - val_loss: 0.0239\n",
      "Epoch 18/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0059 - val_loss: 0.0239\n",
      "Epoch 19/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0056 - val_loss: 0.0238\n",
      "Epoch 20/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0058 - val_loss: 0.0239\n",
      "Epoch 21/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0053 - val_loss: 0.0240\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb4063aa550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3451 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.1451 - val_loss: 0.0342\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0748 - val_loss: 0.0319\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0622 - val_loss: 0.0307\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0953 - val_loss: 0.0335\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0421 - val_loss: 0.0371\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3d126a820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3452 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.2071 - val_loss: 0.0526\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0961 - val_loss: 0.0543\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0253 - val_loss: 0.0561\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3bab184c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3453 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.1215 - val_loss: 0.0572\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0797 - val_loss: 0.0489\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0486 - val_loss: 0.0467\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0318 - val_loss: 0.0447\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0258 - val_loss: 0.0428\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0241 - val_loss: 0.0413\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0229 - val_loss: 0.0400\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0216 - val_loss: 0.0389\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0204 - val_loss: 0.0378\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0193 - val_loss: 0.0369\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0181 - val_loss: 0.0359\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0173 - val_loss: 0.0351\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0166 - val_loss: 0.0343\n",
      "Epoch 14/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0158 - val_loss: 0.0335\n",
      "Epoch 15/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0153 - val_loss: 0.0328\n",
      "Epoch 16/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0154 - val_loss: 0.0321\n",
      "Epoch 17/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0143 - val_loss: 0.0314\n",
      "Epoch 18/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0141 - val_loss: 0.0309\n",
      "Epoch 19/60\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0131 - val_loss: 0.0306\n",
      "Epoch 20/60\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0130 - val_loss: 0.0300\n",
      "Epoch 21/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0120 - val_loss: 0.0295\n",
      "Epoch 22/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0118 - val_loss: 0.0292\n",
      "Epoch 23/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0115 - val_loss: 0.0291\n",
      "Epoch 24/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0110 - val_loss: 0.0289\n",
      "Epoch 25/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0107 - val_loss: 0.0287\n",
      "Epoch 26/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0104 - val_loss: 0.0283\n",
      "Epoch 27/60\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0101 - val_loss: 0.0280\n",
      "Epoch 28/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0098 - val_loss: 0.0278\n",
      "Epoch 29/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0095 - val_loss: 0.0276\n",
      "Epoch 30/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0092 - val_loss: 0.0275\n",
      "Epoch 31/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0090 - val_loss: 0.0273\n",
      "Epoch 32/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0087 - val_loss: 0.0270\n",
      "Epoch 33/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0083 - val_loss: 0.0268\n",
      "Epoch 34/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0081 - val_loss: 0.0267\n",
      "Epoch 35/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0079 - val_loss: 0.0269\n",
      "Epoch 36/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0078 - val_loss: 0.0271\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3c1fc94c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3454 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.0430 - val_loss: 0.0498\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0484 - val_loss: 0.0421\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0267 - val_loss: 0.0371\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0131 - val_loss: 0.0324\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0130 - val_loss: 0.0297\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0111 - val_loss: 0.0296\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0086 - val_loss: 0.0309\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0072 - val_loss: 0.0322\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb397dfbdc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3455 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 0.0855 - val_loss: 0.0524\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0229 - val_loss: 0.0503\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0235 - val_loss: 0.0485\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0206 - val_loss: 0.0444\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0161 - val_loss: 0.0383\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0154 - val_loss: 0.0338\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0136 - val_loss: 0.0321\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0122 - val_loss: 0.0315\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0111 - val_loss: 0.0311\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0103 - val_loss: 0.0305\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0103 - val_loss: 0.0298\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0100 - val_loss: 0.0292\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0095 - val_loss: 0.0289\n",
      "Epoch 14/60\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0092 - val_loss: 0.0286\n",
      "Epoch 15/60\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0091 - val_loss: 0.0285\n",
      "Epoch 16/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0089 - val_loss: 0.0290\n",
      "Epoch 17/60\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0085 - val_loss: 0.0297\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3a8cfa790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3456 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.0358 - val_loss: 0.0535\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0365 - val_loss: 0.0553\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0240 - val_loss: 0.0483\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0176 - val_loss: 0.0441\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0167 - val_loss: 0.0421\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0101 - val_loss: 0.0406\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0068 - val_loss: 0.0400\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0062 - val_loss: 0.0402\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0056 - val_loss: 0.0413\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3797b8820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3457 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.2425 - val_loss: 0.0529\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2725 - val_loss: 0.0368\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0551 - val_loss: 0.0395\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0179 - val_loss: 0.0378\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb37bb54670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3458 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 0.3927 - val_loss: 0.0305\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3137 - val_loss: 0.0501\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0698 - val_loss: 0.0601\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb397d96040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3459 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.0773 - val_loss: 0.0702\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0562 - val_loss: 0.0412\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0230 - val_loss: 0.0363\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0214 - val_loss: 0.0352\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0221 - val_loss: 0.0351\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0194 - val_loss: 0.0346\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0164 - val_loss: 0.0346\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0141 - val_loss: 0.0352\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb397f18f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3460 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.0616 - val_loss: 0.0411\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0275 - val_loss: 0.0454\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0207 - val_loss: 0.0459\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb37b8cf280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3461 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.0307 - val_loss: 0.0528\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0214 - val_loss: 0.0322\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0196 - val_loss: 0.0309\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0156 - val_loss: 0.0361\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0172 - val_loss: 0.0416\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb363805040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3462 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 1s 794ms/step - loss: 0.0312 - val_loss: 0.0303\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0267 - val_loss: 0.0369\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0228 - val_loss: 0.0407\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3645c0280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3463 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 1s 645ms/step - loss: 0.1449 - val_loss: 0.0361\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.0527 - val_loss: 0.0433\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0352 - val_loss: 0.0461\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb349411040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3464 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 466ms/step - loss: 0.0735 - val_loss: 0.0206\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0535 - val_loss: 0.0216\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0231 - val_loss: 0.0242\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb34b847af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3465 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_train_function.<locals>.train_function at 0x7fb34d61c4c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0744WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb350c20c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 816ms/step - loss: 0.0744 - val_loss: 0.0494\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.0216 - val_loss: 0.0487\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.0197 - val_loss: 0.0477\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0149 - val_loss: 0.0454\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0137 - val_loss: 0.0439\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0125 - val_loss: 0.0423\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.0117 - val_loss: 0.0414\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0109 - val_loss: 0.0409\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0118 - val_loss: 0.0403\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0092 - val_loss: 0.0398\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0086 - val_loss: 0.0389\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0081 - val_loss: 0.0377\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0080 - val_loss: 0.0367\n",
      "Epoch 14/60\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0071 - val_loss: 0.0362\n",
      "Epoch 15/60\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0065 - val_loss: 0.0356\n",
      "Epoch 16/60\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0057 - val_loss: 0.0344\n",
      "Epoch 17/60\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0054 - val_loss: 0.0326\n",
      "Epoch 18/60\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0051 - val_loss: 0.0310\n",
      "Epoch 19/60\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0046 - val_loss: 0.0294\n",
      "Epoch 20/60\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0042 - val_loss: 0.0281\n",
      "Epoch 21/60\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0039 - val_loss: 0.0271\n",
      "Epoch 22/60\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0037 - val_loss: 0.0266\n",
      "Epoch 23/60\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - val_loss: 0.0267\n",
      "Epoch 24/60\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0032 - val_loss: 0.0267\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3520bc550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3466 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 1s 670ms/step - loss: 0.2224 - val_loss: 0.0554\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0518 - val_loss: 0.0640\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0662 - val_loss: 0.0616\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3f9cfb550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3467 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 1s 588ms/step - loss: 0.3532 - val_loss: 0.0944\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2317 - val_loss: 0.0644\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0522 - val_loss: 0.0472\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0208 - val_loss: 0.0342\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0225 - val_loss: 0.0299\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0257 - val_loss: 0.0285\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0264 - val_loss: 0.0281\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0212 - val_loss: 0.0285\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0168 - val_loss: 0.0298\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3c042df70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3468 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 1s 565ms/step - loss: 0.8042 - val_loss: 0.0401\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.1350 - val_loss: 0.0588\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0483 - val_loss: 0.0675\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3578ed5e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3469 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 1s 725ms/step - loss: 0.1565 - val_loss: 0.0456\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0558 - val_loss: 0.0407\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0347 - val_loss: 0.0496\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.0280 - val_loss: 0.0613\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb34f27d700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3470 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 0.1963 - val_loss: 0.0692\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0825 - val_loss: 0.0776\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0470 - val_loss: 0.0800\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb35e257790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3471 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.1588 - val_loss: 0.0581\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0684 - val_loss: 0.0541\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0289 - val_loss: 0.0481\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0219 - val_loss: 0.0435\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0220 - val_loss: 0.0400\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0193 - val_loss: 0.0384\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0178 - val_loss: 0.0373\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0162 - val_loss: 0.0362\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0156 - val_loss: 0.0358\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0146 - val_loss: 0.0359\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0138 - val_loss: 0.0365\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3567e2160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3472 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 0.0288 - val_loss: 0.0392\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0309 - val_loss: 0.0511\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0269 - val_loss: 0.0479\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb344d37940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3473 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.1085 - val_loss: 0.0562\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0202 - val_loss: 0.0456\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0228 - val_loss: 0.0360\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0196 - val_loss: 0.0284\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0158 - val_loss: 0.0233\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0144 - val_loss: 0.0203\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0103 - val_loss: 0.0188\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0082 - val_loss: 0.0184\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0071 - val_loss: 0.0184\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0075 - val_loss: 0.0186\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0068 - val_loss: 0.0190\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb345caf700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3474 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.5904 - val_loss: 0.0713\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2788 - val_loss: 0.0908\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0650 - val_loss: 0.1003\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb32c472e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3475 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 1s 812ms/step - loss: 0.0977 - val_loss: 0.0826\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0312 - val_loss: 0.0671\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0222 - val_loss: 0.0621\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0199 - val_loss: 0.0604\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0171 - val_loss: 0.0588\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0156 - val_loss: 0.0582\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0161 - val_loss: 0.0587\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0154 - val_loss: 0.0597\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb333994dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3476 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 1s 869ms/step - loss: 0.0364 - val_loss: 0.0701\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0208 - val_loss: 0.0596\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0146 - val_loss: 0.0581\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0163 - val_loss: 0.0580\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0136 - val_loss: 0.0561\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0114 - val_loss: 0.0551\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0085 - val_loss: 0.0521\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0080 - val_loss: 0.0485\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0068 - val_loss: 0.0464\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0058 - val_loss: 0.0451\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0056 - val_loss: 0.0442\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0055 - val_loss: 0.0439\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0046 - val_loss: 0.0438\n",
      "Epoch 14/60\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0048 - val_loss: 0.0436\n",
      "Epoch 15/60\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0043 - val_loss: 0.0432\n",
      "Epoch 16/60\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0043 - val_loss: 0.0421\n",
      "Epoch 17/60\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0039 - val_loss: 0.0402\n",
      "Epoch 18/60\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.0033 - val_loss: 0.0390\n",
      "Epoch 19/60\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0037 - val_loss: 0.0384\n",
      "Epoch 20/60\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - val_loss: 0.0379\n",
      "Epoch 21/60\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0031 - val_loss: 0.0372\n",
      "Epoch 22/60\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0026 - val_loss: 0.0367\n",
      "Epoch 23/60\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0029 - val_loss: 0.0362\n",
      "Epoch 24/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0027 - val_loss: 0.0359\n",
      "Epoch 25/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0028 - val_loss: 0.0355\n",
      "Epoch 26/60\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0023 - val_loss: 0.0350\n",
      "Epoch 27/60\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0025 - val_loss: 0.0344\n",
      "Epoch 28/60\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0021 - val_loss: 0.0341\n",
      "Epoch 29/60\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0021 - val_loss: 0.0339\n",
      "Epoch 30/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0020 - val_loss: 0.0339\n",
      "Epoch 31/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0018 - val_loss: 0.0339\n",
      "Epoch 32/60\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0019 - val_loss: 0.0336\n",
      "Epoch 33/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0017 - val_loss: 0.0330\n",
      "Epoch 34/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0016 - val_loss: 0.0322\n",
      "Epoch 35/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0015 - val_loss: 0.0315\n",
      "Epoch 36/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0015 - val_loss: 0.0314\n",
      "Epoch 37/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0014 - val_loss: 0.0315\n",
      "Epoch 38/60\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0013 - val_loss: 0.0318\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb41415ff70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3477 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 0.2321 - val_loss: 0.0570\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.1138 - val_loss: 0.0711\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.0549 - val_loss: 0.0710\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb35bf16670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3478 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 1s 696ms/step - loss: 0.0555 - val_loss: 0.0404\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0570 - val_loss: 0.0393\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0243 - val_loss: 0.0370\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0170 - val_loss: 0.0345\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0143 - val_loss: 0.0330\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0121 - val_loss: 0.0333\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0113 - val_loss: 0.0339\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3a5b193a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3479 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 1s 859ms/step - loss: 0.1395 - val_loss: 0.0474\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.0970 - val_loss: 0.0613\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0325 - val_loss: 0.0653\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3fcf224c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3480 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 0.1854 - val_loss: 0.0554\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.0586 - val_loss: 0.0468\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0351 - val_loss: 0.0402\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0287 - val_loss: 0.0358\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0254 - val_loss: 0.0320\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0221 - val_loss: 0.0297\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0207 - val_loss: 0.0280\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0193 - val_loss: 0.0264\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0172 - val_loss: 0.0246\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0151 - val_loss: 0.0227\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.013 - 0s 44ms/step - loss: 0.0138 - val_loss: 0.0215\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0127 - val_loss: 0.0207\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0120 - val_loss: 0.0208\n",
      "Epoch 14/60\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0109 - val_loss: 0.0208\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb384db7040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3481 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 480ms/step - loss: 0.1261 - val_loss: 0.0210\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0552 - val_loss: 0.0308\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0362 - val_loss: 0.0420\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb40d1c00d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3482 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 1s 517ms/step - loss: 0.0726 - val_loss: 0.0359\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0455 - val_loss: 0.0347\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0209 - val_loss: 0.0316\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0171 - val_loss: 0.0292\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0152 - val_loss: 0.0281\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0130 - val_loss: 0.0278\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0117 - val_loss: 0.0284\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0106 - val_loss: 0.0294\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb33659e670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3483 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.1085 - val_loss: 0.0221\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0786 - val_loss: 0.0191\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0345 - val_loss: 0.0227\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0195 - val_loss: 0.0227\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb32b64fee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3484 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 1s 611ms/step - loss: 0.2045 - val_loss: 0.0409\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.0720 - val_loss: 0.0349\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0453 - val_loss: 0.0220\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.0343 - val_loss: 0.0188\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0325 - val_loss: 0.0183\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0313 - val_loss: 0.0180\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0277 - val_loss: 0.0185\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0226 - val_loss: 0.0189\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3226b5e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3485 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.0819 - val_loss: 0.0252\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0294 - val_loss: 0.0207\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0128 - val_loss: 0.0194\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0131 - val_loss: 0.0193\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0109 - val_loss: 0.0199\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0083 - val_loss: 0.0207\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb31c13d8b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3486 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.4026 - val_loss: 0.0536\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.3009 - val_loss: 0.0426\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1249 - val_loss: 0.0358\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0445 - val_loss: 0.0314\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0364 - val_loss: 0.0294\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0278 - val_loss: 0.0320\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0259 - val_loss: 0.0288\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0224 - val_loss: 0.0244\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0188 - val_loss: 0.0222\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0177 - val_loss: 0.0208\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0145 - val_loss: 0.0198\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0129 - val_loss: 0.0193\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0117 - val_loss: 0.0187\n",
      "Epoch 14/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0114 - val_loss: 0.0183\n",
      "Epoch 15/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0113 - val_loss: 0.0181\n",
      "Epoch 16/60\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0113 - val_loss: 0.0181\n",
      "Epoch 17/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0109 - val_loss: 0.0182\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb323ed49d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3487 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 0.1891 - val_loss: 0.0319\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.1155 - val_loss: 0.0276\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0533 - val_loss: 0.0283\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0241 - val_loss: 0.0296\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb31b43ba60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3488 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.5063 - val_loss: 0.0410\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1279 - val_loss: 0.0324\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0586 - val_loss: 0.0300\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0295 - val_loss: 0.0275\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0270 - val_loss: 0.0261\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0237 - val_loss: 0.0252\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0237 - val_loss: 0.0249\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0221 - val_loss: 0.0248\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0197 - val_loss: 0.0241\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0183 - val_loss: 0.0234\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0148 - val_loss: 0.0229\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0118 - val_loss: 0.0224\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0103 - val_loss: 0.0221\n",
      "Epoch 14/60\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0094 - val_loss: 0.0222\n",
      "Epoch 15/60\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0091 - val_loss: 0.0223\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb325cd88b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3489 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.8005 - val_loss: 0.0706\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2951 - val_loss: 0.0409\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0751 - val_loss: 0.0332\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0266 - val_loss: 0.0214\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0229 - val_loss: 0.0179\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0254 - val_loss: 0.0170\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0288 - val_loss: 0.0165\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0284 - val_loss: 0.0159\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0277 - val_loss: 0.0158\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0249 - val_loss: 0.0156\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0180 - val_loss: 0.0153\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0143 - val_loss: 0.0152\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0118 - val_loss: 0.0152\n",
      "Epoch 14/60\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0099 - val_loss: 0.0156\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb308904790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3490 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.3885 - val_loss: 0.0867\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1246 - val_loss: 0.0523\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0764 - val_loss: 0.0303\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0186 - val_loss: 0.0176\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0217 - val_loss: 0.0190\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0206 - val_loss: 0.0187\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3462aa550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3491 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.1096 - val_loss: 0.0438\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0552 - val_loss: 0.0384\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0338 - val_loss: 0.0335\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0373 - val_loss: 0.0317\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0209 - val_loss: 0.0305\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0112 - val_loss: 0.0281\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0083 - val_loss: 0.0268\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0099 - val_loss: 0.0257\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0085 - val_loss: 0.0252\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0077 - val_loss: 0.0248\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0073 - val_loss: 0.0244\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0068 - val_loss: 0.0243\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0065 - val_loss: 0.0245\n",
      "Epoch 14/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0059 - val_loss: 0.0247\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb31b50c430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3492 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.1656 - val_loss: 0.0323\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0295 - val_loss: 0.0558\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0288 - val_loss: 0.0591\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3089514c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3493 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.0979 - val_loss: 0.0337\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0455 - val_loss: 0.0324\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0229 - val_loss: 0.0361\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0212 - val_loss: 0.0366\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3190721f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3494 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 301ms/step - loss: 0.1812 - val_loss: 0.0271\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0813 - val_loss: 0.0167\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0518 - val_loss: 0.0201\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0316 - val_loss: 0.0233\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb313be30d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3495 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.1385 - val_loss: 0.0507\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0657 - val_loss: 0.0433\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0364 - val_loss: 0.0337\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0252 - val_loss: 0.0242\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0193 - val_loss: 0.0190\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0161 - val_loss: 0.0169\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0146 - val_loss: 0.0165\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0140 - val_loss: 0.0165\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0121 - val_loss: 0.0165\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0104 - val_loss: 0.0165\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3140771f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3496 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.0586 - val_loss: 0.0477\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0288 - val_loss: 0.0465\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0135 - val_loss: 0.0422\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0123 - val_loss: 0.0375\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0100 - val_loss: 0.0350\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0102 - val_loss: 0.0340\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0092 - val_loss: 0.0339\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0082 - val_loss: 0.0343\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0073 - val_loss: 0.0348\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3145a8040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3497 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.0510 - val_loss: 0.0405\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0273 - val_loss: 0.0382\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0207 - val_loss: 0.0384\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0118 - val_loss: 0.0380\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0100 - val_loss: 0.0386\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0100 - val_loss: 0.0397\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb31495fd30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3498 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.2024 - val_loss: 0.0602\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0560 - val_loss: 0.0632\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0325 - val_loss: 0.0605\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb314dfab80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3499 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 1s 545ms/step - loss: 0.1558 - val_loss: 0.0451\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0420 - val_loss: 0.0412\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0249 - val_loss: 0.0389\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0160 - val_loss: 0.0360\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0150 - val_loss: 0.0345\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0131 - val_loss: 0.0334\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0085 - val_loss: 0.0323\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0065 - val_loss: 0.0314\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0060 - val_loss: 0.0299\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0064 - val_loss: 0.0286\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.005 - 0s 49ms/step - loss: 0.0058 - val_loss: 0.0274\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0052 - val_loss: 0.0261\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0045 - val_loss: 0.0249\n",
      "Epoch 14/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0039 - val_loss: 0.0240\n",
      "Epoch 15/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0038 - val_loss: 0.0233\n",
      "Epoch 16/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0037 - val_loss: 0.0228\n",
      "Epoch 17/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0035 - val_loss: 0.0225\n",
      "Epoch 18/60\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0032 - val_loss: 0.0221\n",
      "Epoch 19/60\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0028 - val_loss: 0.0220\n",
      "Epoch 20/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0027 - val_loss: 0.0222\n",
      "Epoch 21/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0026 - val_loss: 0.0225\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb31536cca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3500 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.1135 - val_loss: 0.0271\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0453 - val_loss: 0.0217\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0155 - val_loss: 0.0240\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0173 - val_loss: 0.0221\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb31589eb80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3501 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 0.0782 - val_loss: 0.0432\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0255 - val_loss: 0.0336\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0212 - val_loss: 0.0377\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0235 - val_loss: 0.0396\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb315d2fa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3502 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.0740 - val_loss: 0.0577\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0761 - val_loss: 0.0598\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0404 - val_loss: 0.0380\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0219 - val_loss: 0.0281\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0170 - val_loss: 0.0237\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0138 - val_loss: 0.0220\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0098 - val_loss: 0.0213\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0088 - val_loss: 0.0209\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0086 - val_loss: 0.0205\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0074 - val_loss: 0.0212\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0066 - val_loss: 0.0216\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb316a28040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3503 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 0.0488 - val_loss: 0.0798\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0491 - val_loss: 0.0313\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0212 - val_loss: 0.0170\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0319 - val_loss: 0.0249\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0155 - val_loss: 0.0380\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2f896c820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3504 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.1556 - val_loss: 0.0896\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.1063 - val_loss: 0.1174\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0330 - val_loss: 0.1054\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2f9d6f700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3505 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.0332 - val_loss: 0.0464\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0219 - val_loss: 0.0475\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0122 - val_loss: 0.0465\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2fb5f3430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3506 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.1321 - val_loss: 0.0189\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0384 - val_loss: 0.0257\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0199 - val_loss: 0.0286\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2fc9bb4c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3507 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_train_function.<locals>.train_function at 0x7fb2fe87f4c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2364WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb2fee353a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.2364 - val_loss: 0.0506\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.1453 - val_loss: 0.0404\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0541 - val_loss: 0.0306\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0418 - val_loss: 0.0247\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0250 - val_loss: 0.0220\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0228 - val_loss: 0.0210\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0174 - val_loss: 0.0209\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0150 - val_loss: 0.0211\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0132 - val_loss: 0.0216\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb30060b310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3508 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 0.0595 - val_loss: 0.0397\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0239 - val_loss: 0.0474\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0143 - val_loss: 0.0612\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb30149f0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3509 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 0.0475 - val_loss: 0.0495\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0300 - val_loss: 0.0462\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0139 - val_loss: 0.0407\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0094 - val_loss: 0.0394\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0062 - val_loss: 0.0384\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0067 - val_loss: 0.0369\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0057 - val_loss: 0.0349\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0054 - val_loss: 0.0328\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0047 - val_loss: 0.0314\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0047 - val_loss: 0.0302\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0047 - val_loss: 0.0291\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0043 - val_loss: 0.0284\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0041 - val_loss: 0.0275\n",
      "Epoch 14/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0038 - val_loss: 0.0266\n",
      "Epoch 15/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0035 - val_loss: 0.0258\n",
      "Epoch 16/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0034 - val_loss: 0.0249\n",
      "Epoch 17/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0031 - val_loss: 0.0244\n",
      "Epoch 18/60\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0030 - val_loss: 0.0239\n",
      "Epoch 19/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0028 - val_loss: 0.0235\n",
      "Epoch 20/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0026 - val_loss: 0.0231\n",
      "Epoch 21/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0024 - val_loss: 0.0226\n",
      "Epoch 22/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0022 - val_loss: 0.0223\n",
      "Epoch 23/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0021 - val_loss: 0.0220\n",
      "Epoch 24/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0020 - val_loss: 0.0216\n",
      "Epoch 25/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0020 - val_loss: 0.0213\n",
      "Epoch 26/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0020 - val_loss: 0.0212\n",
      "Epoch 27/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0018 - val_loss: 0.0211\n",
      "Epoch 28/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0018 - val_loss: 0.0210\n",
      "Epoch 29/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0018 - val_loss: 0.0211\n",
      "Epoch 30/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0017 - val_loss: 0.0212\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3033a31f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3510 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.2765 - val_loss: 0.0427\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0958 - val_loss: 0.0348\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0719 - val_loss: 0.0315\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0431 - val_loss: 0.0252\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0217 - val_loss: 0.0210\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0128 - val_loss: 0.0200\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0115 - val_loss: 0.0204\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0124 - val_loss: 0.0207\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb30467a040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3511 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.2063 - val_loss: 0.0458\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1168 - val_loss: 0.0437\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0608 - val_loss: 0.0417\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0371 - val_loss: 0.0396\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0325 - val_loss: 0.0371\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0304 - val_loss: 0.0359\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0282 - val_loss: 0.0347\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0262 - val_loss: 0.0336\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0246 - val_loss: 0.0323\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0231 - val_loss: 0.0305\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0220 - val_loss: 0.0278\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0212 - val_loss: 0.0254\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0206 - val_loss: 0.0237\n",
      "Epoch 14/60\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0203 - val_loss: 0.0226\n",
      "Epoch 15/60\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0199 - val_loss: 0.0216\n",
      "Epoch 16/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0193 - val_loss: 0.0209\n",
      "Epoch 17/60\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0186 - val_loss: 0.0206\n",
      "Epoch 18/60\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0180 - val_loss: 0.0205\n",
      "Epoch 19/60\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0172 - val_loss: 0.0204\n",
      "Epoch 20/60\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0165 - val_loss: 0.0203\n",
      "Epoch 21/60\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0157 - val_loss: 0.0202\n",
      "Epoch 22/60\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0154 - val_loss: 0.0200\n",
      "Epoch 23/60\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0150 - val_loss: 0.0199\n",
      "Epoch 24/60\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0146 - val_loss: 0.0198\n",
      "Epoch 25/60\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0144 - val_loss: 0.0197\n",
      "Epoch 26/60\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0141 - val_loss: 0.0194\n",
      "Epoch 27/60\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0140 - val_loss: 0.0194\n",
      "Epoch 28/60\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0139 - val_loss: 0.0195\n",
      "Epoch 29/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0139 - val_loss: 0.0196\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb306037ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3512 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0401 - val_loss: 0.0499\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.0342 - val_loss: 0.0480\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0172 - val_loss: 0.0450\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0101 - val_loss: 0.0377\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0112 - val_loss: 0.0386\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.0090 - val_loss: 0.0391\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3c5a66a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3513 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 0.0415 - val_loss: 0.0359\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0363 - val_loss: 0.0333\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0237 - val_loss: 0.0309\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0197 - val_loss: 0.0299\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0130 - val_loss: 0.0294\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0112 - val_loss: 0.0292\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0098 - val_loss: 0.0291\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0084 - val_loss: 0.0297\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0074 - val_loss: 0.0306\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb344da95e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3514 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.0467 - val_loss: 0.0452\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0256 - val_loss: 0.0390\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0171 - val_loss: 0.0372\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0135 - val_loss: 0.0355\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0101 - val_loss: 0.0330\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0084 - val_loss: 0.0317\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0100 - val_loss: 0.0324\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0077 - val_loss: 0.0337\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb45430cdc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3515 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 0.1185 - val_loss: 0.0527\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0647 - val_loss: 0.0215\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0360 - val_loss: 0.0176\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0229 - val_loss: 0.0205\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0197 - val_loss: 0.0209\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3e56ae550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3516 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 1s 710ms/step - loss: 0.0834 - val_loss: 0.0351\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.0335 - val_loss: 0.0304\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0319 - val_loss: 0.0211\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0216 - val_loss: 0.0207\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0119 - val_loss: 0.0201\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0110 - val_loss: 0.0202\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0107 - val_loss: 0.0202\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb37b4cf280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3517 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 1s 557ms/step - loss: 1.1134 - val_loss: 0.1439\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.5444 - val_loss: 0.1235\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1496 - val_loss: 0.0641\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0577 - val_loss: 0.0297\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0306 - val_loss: 0.0186\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0142 - val_loss: 0.0179\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0137 - val_loss: 0.0208\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0132 - val_loss: 0.0242\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb35df539d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3518 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 1s 692ms/step - loss: 0.3299 - val_loss: 0.0197\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.1642 - val_loss: 0.0213\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0251 - val_loss: 0.0212\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3cc25d550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3519 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.0623 - val_loss: 0.0414\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0323 - val_loss: 0.0688\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0215 - val_loss: 0.0500\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb36ea2edc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3520 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.2776 - val_loss: 0.0290\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0627 - val_loss: 0.0559\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0287 - val_loss: 0.0554\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb302317dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3521 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:5 out of the last 18 calls to <function Model.make_train_function.<locals>.train_function at 0x7fb301f32f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1398WARNING:tensorflow:5 out of the last 18 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb3006b13a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.1398 - val_loss: 0.0302\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0422 - val_loss: 0.0415\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0197 - val_loss: 0.0443\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb30060b430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3522 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x7fb2feb68430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3804WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb2fc2d7790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.3804 - val_loss: 0.0440\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1022 - val_loss: 0.0346\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0685 - val_loss: 0.0330\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0402 - val_loss: 0.0312\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0363 - val_loss: 0.0287\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0324 - val_loss: 0.0269\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0296 - val_loss: 0.0250\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0266 - val_loss: 0.0232\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0226 - val_loss: 0.0216\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0189 - val_loss: 0.0203\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0157 - val_loss: 0.0192\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0135 - val_loss: 0.0183\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0126 - val_loss: 0.0176\n",
      "Epoch 14/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0119 - val_loss: 0.0171\n",
      "Epoch 15/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0119 - val_loss: 0.0168\n",
      "Epoch 16/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0119 - val_loss: 0.0166\n",
      "Epoch 17/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0111 - val_loss: 0.0166\n",
      "Epoch 18/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0102 - val_loss: 0.0165\n",
      "Epoch 19/60\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0091 - val_loss: 0.0165\n",
      "Epoch 20/60\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0086 - val_loss: 0.0165\n",
      "Epoch 21/60\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0082 - val_loss: 0.0165\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2fb5f3b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3523 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.0665 - val_loss: 0.0271\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0328 - val_loss: 0.0236\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0173 - val_loss: 0.0198\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0081 - val_loss: 0.0188\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0115 - val_loss: 0.0183\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0080 - val_loss: 0.0182\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0069 - val_loss: 0.0181\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0112 - val_loss: 0.0186\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0076 - val_loss: 0.0189\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2f896c550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3524 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.0720 - val_loss: 0.0248\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0255 - val_loss: 0.0192\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0228 - val_loss: 0.0174\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0279 - val_loss: 0.0174\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0210 - val_loss: 0.0181\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb315e7b3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3525 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.1000 - val_loss: 0.0232\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0405 - val_loss: 0.0169\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0327 - val_loss: 0.0163\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0235 - val_loss: 0.0170\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0140 - val_loss: 0.0173\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3154db3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3526 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.0221 - val_loss: 0.0229\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0317 - val_loss: 0.0255\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0346 - val_loss: 0.0267\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3147fe8b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3527 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.1465 - val_loss: 0.0324\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0752 - val_loss: 0.0254\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0396 - val_loss: 0.0230\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0294 - val_loss: 0.0205\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0139 - val_loss: 0.0180\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0107 - val_loss: 0.0167\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0098 - val_loss: 0.0163\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0093 - val_loss: 0.0163\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0095 - val_loss: 0.0163\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0085 - val_loss: 0.0163\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3139e20d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3528 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.2162 - val_loss: 0.0176\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0481 - val_loss: 0.0157\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0199 - val_loss: 0.0154\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0175 - val_loss: 0.0159\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0161 - val_loss: 0.0171\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb308951940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3529 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.0290 - val_loss: 0.0264\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0291 - val_loss: 0.0287\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0191 - val_loss: 0.0182\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0121 - val_loss: 0.0166\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0097 - val_loss: 0.0167\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0083 - val_loss: 0.0167\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3462aa820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3530 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.0330 - val_loss: 0.0210\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0343 - val_loss: 0.0208\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0125 - val_loss: 0.0203\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0105 - val_loss: 0.0203\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0097 - val_loss: 0.0213\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb323e84670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3531 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.1943 - val_loss: 0.0148\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0822 - val_loss: 0.0141\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0446 - val_loss: 0.0161\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0365 - val_loss: 0.0168\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb323ed40d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3532 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.1615 - val_loss: 0.0182\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0489 - val_loss: 0.0232\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0177 - val_loss: 0.0280\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3625970d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3533 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.1438 - val_loss: 0.0239\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0298 - val_loss: 0.0282\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0337 - val_loss: 0.0294\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb334060af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3534 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 0.2583 - val_loss: 0.0215\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0392 - val_loss: 0.0494\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0595 - val_loss: 0.0610\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb36240fb80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3535 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:5 out of the last 14 calls to <function Model.make_train_function.<locals>.train_function at 0x7fb37971d790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0509WARNING:tensorflow:5 out of the last 14 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb3a4f11af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0509 - val_loss: 0.0139\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0268 - val_loss: 0.0128\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.0111 - val_loss: 0.0128\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.0107 - val_loss: 0.0130\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0105 - val_loss: 0.0133\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb4318a9ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3536 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.0290 - val_loss: 0.0227\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0250 - val_loss: 0.0175\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0152 - val_loss: 0.0142\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0092 - val_loss: 0.0148\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0088 - val_loss: 0.0177\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3eeeef040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3537 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.2571 - val_loss: 0.0481\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0977 - val_loss: 0.0296\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0329 - val_loss: 0.0198\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0192 - val_loss: 0.0139\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0208 - val_loss: 0.0120\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0201 - val_loss: 0.0117\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0150 - val_loss: 0.0117\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0089 - val_loss: 0.0117\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0083 - val_loss: 0.0117\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0079 - val_loss: 0.0118\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb4afcb2f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3538 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.1975 - val_loss: 0.0220\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1362 - val_loss: 0.0148\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0260 - val_loss: 0.0119\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0201 - val_loss: 0.0119\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0157 - val_loss: 0.0136\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0134 - val_loss: 0.0152\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3330ade50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3539 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.3439 - val_loss: 0.0406\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1473 - val_loss: 0.0267\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0532 - val_loss: 0.0160\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0301 - val_loss: 0.0121\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0267 - val_loss: 0.0112\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0190 - val_loss: 0.0111\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0148 - val_loss: 0.0110\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0116 - val_loss: 0.0110\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0116 - val_loss: 0.0109\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0111 - val_loss: 0.0109\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0098 - val_loss: 0.0110\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb32b102d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3540 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.1015 - val_loss: 0.0481\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0369 - val_loss: 0.0365\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0236 - val_loss: 0.0243\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0150 - val_loss: 0.0182\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0131 - val_loss: 0.0151\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0104 - val_loss: 0.0151\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0082 - val_loss: 0.0146\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0083 - val_loss: 0.0143\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0074 - val_loss: 0.0141\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0067 - val_loss: 0.0140\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0056 - val_loss: 0.0140\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0052 - val_loss: 0.0140\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0045 - val_loss: 0.0140\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3453ce9d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3541 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.0964 - val_loss: 0.0087\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0272 - val_loss: 0.0140\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0248 - val_loss: 0.0156\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb35779c0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3542 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 0.1166 - val_loss: 0.0093\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0564 - val_loss: 0.0203\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0632 - val_loss: 0.0400\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb357bde160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3543 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 305ms/step - loss: 0.0583 - val_loss: 0.0163\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0355 - val_loss: 0.0175\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0203 - val_loss: 0.0280\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb37e9c4ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3544 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:5 out of the last 23 calls to <function Model.make_train_function.<locals>.train_function at 0x7fb365944c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1073WARNING:tensorflow:5 out of the last 23 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb353a57dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 652ms/step - loss: 0.1073 - val_loss: 0.0201\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0351 - val_loss: 0.0150\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0214 - val_loss: 0.0110\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0098 - val_loss: 0.0088\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0126 - val_loss: 0.0084\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0156 - val_loss: 0.0081\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0114 - val_loss: 0.0079\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0103 - val_loss: 0.0078\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0089 - val_loss: 0.0077\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0074 - val_loss: 0.0077\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0066 - val_loss: 0.0076\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0062 - val_loss: 0.0076\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0057 - val_loss: 0.0076\n",
      "Epoch 14/60\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0054 - val_loss: 0.0076\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb35127ac10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3545 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.1193 - val_loss: 0.0201\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0356 - val_loss: 0.0195\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0209 - val_loss: 0.0215\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0171 - val_loss: 0.0232\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb400222280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3546 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.0889 - val_loss: 0.0313\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0964 - val_loss: 0.0334\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0453 - val_loss: 0.0298\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0296 - val_loss: 0.0297\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0193 - val_loss: 0.0304\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0185 - val_loss: 0.0318\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb350c20d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3547 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.1938 - val_loss: 0.0083\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.1119 - val_loss: 0.0169\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0206 - val_loss: 0.0186\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb34a8d0d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3548 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.0704 - val_loss: 0.0136\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0472 - val_loss: 0.0129\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0201 - val_loss: 0.0105\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0186 - val_loss: 0.0096\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0117 - val_loss: 0.0095\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0111 - val_loss: 0.0096\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0102 - val_loss: 0.0096\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb365c3d8b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3549 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.1215 - val_loss: 0.0307\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0268 - val_loss: 0.0102\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0322 - val_loss: 0.0100\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0254 - val_loss: 0.0157\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0252 - val_loss: 0.0209\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3642038b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3550 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.2509 - val_loss: 0.0792\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.1499 - val_loss: 0.0563\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0630 - val_loss: 0.0359\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0447 - val_loss: 0.0243\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0321 - val_loss: 0.0180\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0211 - val_loss: 0.0131\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0200 - val_loss: 0.0099\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0152 - val_loss: 0.0084\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0119 - val_loss: 0.0081\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0115 - val_loss: 0.0086\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0119 - val_loss: 0.0093\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3bcb815e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3551 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.0421 - val_loss: 0.0097\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0343 - val_loss: 0.0102\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0182 - val_loss: 0.0108\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb40dd89c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3552 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.9126 - val_loss: 0.0244\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3730 - val_loss: 0.0141\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0890 - val_loss: 0.0116\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0740 - val_loss: 0.0092\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0567 - val_loss: 0.0080\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0285 - val_loss: 0.0076\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0263 - val_loss: 0.0076\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0249 - val_loss: 0.0078\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0227 - val_loss: 0.0079\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3828515e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3553 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.0411 - val_loss: 0.0209\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0285 - val_loss: 0.0163\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0239 - val_loss: 0.0136\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0172 - val_loss: 0.0113\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0116 - val_loss: 0.0104\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0096 - val_loss: 0.0104\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0095 - val_loss: 0.0101\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0101 - val_loss: 0.0097\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0092 - val_loss: 0.0090\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0079 - val_loss: 0.0081\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0066 - val_loss: 0.0081\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0060 - val_loss: 0.0082\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3797b8d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3554 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.2748 - val_loss: 0.0101\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1021 - val_loss: 0.0069\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0661 - val_loss: 0.0190\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.028 - 0s 68ms/step - loss: 0.0284 - val_loss: 0.0452\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb39be82550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3555 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 488ms/step - loss: 0.0660 - val_loss: 0.0192\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0415 - val_loss: 0.0121\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0287 - val_loss: 0.0070\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0219 - val_loss: 0.0105\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0172 - val_loss: 0.0151\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3c4861ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3556 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 471ms/step - loss: 0.1326 - val_loss: 0.0132\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0572 - val_loss: 0.0076\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0354 - val_loss: 0.0070\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0190 - val_loss: 0.0069\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0103 - val_loss: 0.0073\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0085 - val_loss: 0.0079\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3bb9734c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3557 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.1093 - val_loss: 0.0062\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0536 - val_loss: 0.0076\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0307 - val_loss: 0.0063\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3e23e4b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3558 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.7323 - val_loss: 0.0281\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2324 - val_loss: 0.0165\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1632 - val_loss: 0.0148\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1092 - val_loss: 0.0136\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0764 - val_loss: 0.0126\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0519 - val_loss: 0.0117\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0463 - val_loss: 0.0109\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0426 - val_loss: 0.0103\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0406 - val_loss: 0.0098\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0389 - val_loss: 0.0093\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0374 - val_loss: 0.0088\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0358 - val_loss: 0.0084\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0341 - val_loss: 0.0080\n",
      "Epoch 14/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0322 - val_loss: 0.0077\n",
      "Epoch 15/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0301 - val_loss: 0.0074\n",
      "Epoch 16/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0281 - val_loss: 0.0069\n",
      "Epoch 17/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0264 - val_loss: 0.0065\n",
      "Epoch 18/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0247 - val_loss: 0.0062\n",
      "Epoch 19/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0231 - val_loss: 0.0061\n",
      "Epoch 20/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0216 - val_loss: 0.0061\n",
      "Epoch 21/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0202 - val_loss: 0.0062\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3f4006dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3559 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 1s 547ms/step - loss: 0.1272 - val_loss: 0.0132\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0294 - val_loss: 0.0251\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0339 - val_loss: 0.0267\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb47b652280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3560 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.2173 - val_loss: 0.0249\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0963 - val_loss: 0.0222\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0338 - val_loss: 0.0106\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0250 - val_loss: 0.0064\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0126 - val_loss: 0.0061\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0107 - val_loss: 0.0065\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0118 - val_loss: 0.0074\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3f67064c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3561 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.5275 - val_loss: 0.0172\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1322 - val_loss: 0.0200\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0424 - val_loss: 0.0209\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3cc843e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3562 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 482ms/step - loss: 0.0868 - val_loss: 0.0065\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0845 - val_loss: 0.0087\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0341 - val_loss: 0.0079\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3b2060550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3563 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.2447 - val_loss: 0.0090\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0701 - val_loss: 0.0069\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0691 - val_loss: 0.0067\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0387 - val_loss: 0.0073\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0413 - val_loss: 0.0068\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3c3d1aee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3564 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.1157 - val_loss: 0.0166\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0506 - val_loss: 0.0255\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0508 - val_loss: 0.0258\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb389379820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3565 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 1s 574ms/step - loss: 0.1005 - val_loss: 0.0116\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1211 - val_loss: 0.0122\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0281 - val_loss: 0.0123\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3d4ca3790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3566 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.1208 - val_loss: 0.0146\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0483 - val_loss: 0.0174\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0341 - val_loss: 0.0121\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0258 - val_loss: 0.0123\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0290 - val_loss: 0.0088\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0184 - val_loss: 0.0067\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0181 - val_loss: 0.0059\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0149 - val_loss: 0.0058\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0131 - val_loss: 0.0057\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0113 - val_loss: 0.0057\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0110 - val_loss: 0.0058\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0102 - val_loss: 0.0061\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb36dd104c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3567 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.0927 - val_loss: 0.0344\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0834 - val_loss: 0.0932\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0444 - val_loss: 0.0848\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb36f447a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3568 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.1506 - val_loss: 0.0153\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.1736 - val_loss: 0.0112\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0366 - val_loss: 0.0099\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0204 - val_loss: 0.0099\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0204 - val_loss: 0.0103\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3766568b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3569 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 0.3313 - val_loss: 0.0433\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1282 - val_loss: 0.0467\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0613 - val_loss: 0.0314\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0473 - val_loss: 0.0198\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0366 - val_loss: 0.0173\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0314 - val_loss: 0.0154\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0286 - val_loss: 0.0139\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0259 - val_loss: 0.0126\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0232 - val_loss: 0.0115\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0207 - val_loss: 0.0105\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0188 - val_loss: 0.0097\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0166 - val_loss: 0.0090\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0148 - val_loss: 0.0084\n",
      "Epoch 14/60\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.0133 - val_loss: 0.0079\n",
      "Epoch 15/60\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0125 - val_loss: 0.0076\n",
      "Epoch 16/60\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0121 - val_loss: 0.0074\n",
      "Epoch 17/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.011 - 0s 75ms/step - loss: 0.0115 - val_loss: 0.0072\n",
      "Epoch 18/60\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0111 - val_loss: 0.0072\n",
      "Epoch 19/60\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0106 - val_loss: 0.0071\n",
      "Epoch 20/60\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0096 - val_loss: 0.0071\n",
      "Epoch 21/60\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0088 - val_loss: 0.0071\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3bcb391f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3570 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 0.2597 - val_loss: 0.0777\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1200 - val_loss: 0.0665\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0699 - val_loss: 0.0539\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0394 - val_loss: 0.0401\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0294 - val_loss: 0.0226\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0196 - val_loss: 0.0138\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0188 - val_loss: 0.0106\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0154 - val_loss: 0.0090\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0137 - val_loss: 0.0082\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0123 - val_loss: 0.0077\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0109 - val_loss: 0.0074\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0103 - val_loss: 0.0071\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0091 - val_loss: 0.0072\n",
      "Epoch 14/60\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0083 - val_loss: 0.0073\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb36399c4c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3571 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.0737 - val_loss: 0.0357\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0473 - val_loss: 0.0295\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0382 - val_loss: 0.0229\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0201 - val_loss: 0.0206\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0162 - val_loss: 0.0187\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0121 - val_loss: 0.0160\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0106 - val_loss: 0.0143\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0083 - val_loss: 0.0151\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0079 - val_loss: 0.0168\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb356ac2ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3572 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.6781 - val_loss: 0.0756\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1176 - val_loss: 0.0203\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0680 - val_loss: 0.0088\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0729 - val_loss: 0.0084\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0378 - val_loss: 0.0079\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0203 - val_loss: 0.0077\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.0160 - val_loss: 0.0080\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0161 - val_loss: 0.0080\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb35768fc10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3573 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 459ms/step - loss: 0.1537 - val_loss: 0.0321\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0819 - val_loss: 0.0415\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0581 - val_loss: 0.0370\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb35c190160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3574 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 1s 703ms/step - loss: 0.0689 - val_loss: 0.0293\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0240 - val_loss: 0.0290\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0202 - val_loss: 0.0276\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0198 - val_loss: 0.0258\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.0144 - val_loss: 0.0237\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0131 - val_loss: 0.0222\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0123 - val_loss: 0.0213\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0105 - val_loss: 0.0199\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0094 - val_loss: 0.0184\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0085 - val_loss: 0.0175\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0076 - val_loss: 0.0170\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0065 - val_loss: 0.0164\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0058 - val_loss: 0.0160\n",
      "Epoch 14/60\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0058 - val_loss: 0.0155\n",
      "Epoch 15/60\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0056 - val_loss: 0.0151\n",
      "Epoch 16/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0052 - val_loss: 0.0147\n",
      "Epoch 17/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0048 - val_loss: 0.0143\n",
      "Epoch 18/60\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0045 - val_loss: 0.0138\n",
      "Epoch 19/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0044 - val_loss: 0.0135\n",
      "Epoch 20/60\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0043 - val_loss: 0.0133\n",
      "Epoch 21/60\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.0040 - val_loss: 0.0133\n",
      "Epoch 22/60\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0037 - val_loss: 0.0135\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb35e3bd310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3575 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 0.0326 - val_loss: 0.0152\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0226 - val_loss: 0.0144\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0196 - val_loss: 0.0108\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0164 - val_loss: 0.0100\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0111 - val_loss: 0.0091\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0091 - val_loss: 0.0087\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0083 - val_loss: 0.0087\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0076 - val_loss: 0.0102\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb479524700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3576 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.0720 - val_loss: 0.0205\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0449 - val_loss: 0.0147\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0332 - val_loss: 0.0127\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0177 - val_loss: 0.0096\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0122 - val_loss: 0.0081\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0110 - val_loss: 0.0082\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0091 - val_loss: 0.0083\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb43a28ee50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3577 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.0797 - val_loss: 0.0140\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0358 - val_loss: 0.0119\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0203 - val_loss: 0.0105\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0162 - val_loss: 0.0093\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0129 - val_loss: 0.0086\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0135 - val_loss: 0.0082\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0103 - val_loss: 0.0080\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0083 - val_loss: 0.0080\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0068 - val_loss: 0.0080\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0068 - val_loss: 0.0081\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb342a3b9d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3578 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 0.0796 - val_loss: 0.0227\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0378 - val_loss: 0.0256\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0133 - val_loss: 0.0292\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb33412fb80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3579 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 0.1118 - val_loss: 0.0652\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0436 - val_loss: 0.0531\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0389 - val_loss: 0.0358\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0282 - val_loss: 0.0225\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0209 - val_loss: 0.0149\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0165 - val_loss: 0.0116\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0157 - val_loss: 0.0100\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0145 - val_loss: 0.0090\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0120 - val_loss: 0.0086\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0098 - val_loss: 0.0083\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0088 - val_loss: 0.0085\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0081 - val_loss: 0.0089\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb32fbf49d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3580 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 1s 672ms/step - loss: 0.1908 - val_loss: 0.0199\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0490 - val_loss: 0.0165\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0609 - val_loss: 0.0086\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0236 - val_loss: 0.0082\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0184 - val_loss: 0.0107\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0155 - val_loss: 0.0139\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3194469d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3581 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.1090 - val_loss: 0.0295\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0514 - val_loss: 0.0242\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0566 - val_loss: 0.0100\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0264 - val_loss: 0.0069\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0200 - val_loss: 0.0066\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0149 - val_loss: 0.0068\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0136 - val_loss: 0.0067\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb31c148ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3582 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 0.1844 - val_loss: 0.0344\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1393 - val_loss: 0.0282\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0668 - val_loss: 0.0266\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0488 - val_loss: 0.0250\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0445 - val_loss: 0.0210\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0410 - val_loss: 0.0194\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0390 - val_loss: 0.0187\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0370 - val_loss: 0.0181\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0351 - val_loss: 0.0173\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0330 - val_loss: 0.0165\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0313 - val_loss: 0.0157\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0295 - val_loss: 0.0148\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0277 - val_loss: 0.0132\n",
      "Epoch 14/60\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0266 - val_loss: 0.0114\n",
      "Epoch 15/60\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0259 - val_loss: 0.0104\n",
      "Epoch 16/60\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0251 - val_loss: 0.0093\n",
      "Epoch 17/60\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0240 - val_loss: 0.0086\n",
      "Epoch 18/60\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0228 - val_loss: 0.0081\n",
      "Epoch 19/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0216 - val_loss: 0.0077\n",
      "Epoch 20/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0198 - val_loss: 0.0075\n",
      "Epoch 21/60\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0184 - val_loss: 0.0074\n",
      "Epoch 22/60\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0178 - val_loss: 0.0075\n",
      "Epoch 23/60\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0177 - val_loss: 0.0076\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb31f325310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3583 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.0890 - val_loss: 0.0439\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0704 - val_loss: 0.0294\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0338 - val_loss: 0.0220\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0123 - val_loss: 0.0170\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0146 - val_loss: 0.0139\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0112 - val_loss: 0.0127\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0106 - val_loss: 0.0119\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0092 - val_loss: 0.0111\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0089 - val_loss: 0.0108\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0082 - val_loss: 0.0108\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0075 - val_loss: 0.0110\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0064 - val_loss: 0.0118\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb324373c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3584 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.2067 - val_loss: 0.0663\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0835 - val_loss: 0.0238\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1054 - val_loss: 0.0144\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0300 - val_loss: 0.0114\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0252 - val_loss: 0.0091\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0202 - val_loss: 0.0093\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0152 - val_loss: 0.0085\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0135 - val_loss: 0.0080\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0118 - val_loss: 0.0079\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0106 - val_loss: 0.0080\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0097 - val_loss: 0.0080\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb30ab1ddc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3585 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.1484 - val_loss: 0.0465\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0971 - val_loss: 0.0274\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0678 - val_loss: 0.0210\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0459 - val_loss: 0.0176\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0249 - val_loss: 0.0147\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0182 - val_loss: 0.0116\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0165 - val_loss: 0.0101\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0098 - val_loss: 0.0095\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0096 - val_loss: 0.0088\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0093 - val_loss: 0.0084\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0090 - val_loss: 0.0082\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0084 - val_loss: 0.0085\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0074 - val_loss: 0.0090\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3bcb0bee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3586 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.0812 - val_loss: 0.0328\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0651 - val_loss: 0.0277\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0441 - val_loss: 0.0289\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0290 - val_loss: 0.0277\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb36e8a5ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3587 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.0996 - val_loss: 0.0222\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0611 - val_loss: 0.0216\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0363 - val_loss: 0.0182\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0234 - val_loss: 0.0143\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0155 - val_loss: 0.0115\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0119 - val_loss: 0.0102\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0110 - val_loss: 0.0104\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0107 - val_loss: 0.0111\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb379b7f160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3588 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.1661 - val_loss: 0.0362\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0501 - val_loss: 0.0304\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0395 - val_loss: 0.0273\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0248 - val_loss: 0.0264\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0207 - val_loss: 0.0255\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0109 - val_loss: 0.0240\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0088 - val_loss: 0.0220\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0089 - val_loss: 0.0201\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0084 - val_loss: 0.0185\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0080 - val_loss: 0.0174\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0078 - val_loss: 0.0168\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0069 - val_loss: 0.0165\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0062 - val_loss: 0.0164\n",
      "Epoch 14/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0060 - val_loss: 0.0167\n",
      "Epoch 15/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0062 - val_loss: 0.0172\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb43a2bd820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3589 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.2287 - val_loss: 0.0357\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1346 - val_loss: 0.0202\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0878 - val_loss: 0.0205\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0470 - val_loss: 0.0195\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0297 - val_loss: 0.0188\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0196 - val_loss: 0.0179\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0131 - val_loss: 0.0178\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0116 - val_loss: 0.0171\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0103 - val_loss: 0.0164\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0085 - val_loss: 0.0158\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.0074 - val_loss: 0.0153\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0065 - val_loss: 0.0153\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0062 - val_loss: 0.0152\n",
      "Epoch 14/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0062 - val_loss: 0.0150\n",
      "Epoch 15/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0055 - val_loss: 0.0147\n",
      "Epoch 16/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0053 - val_loss: 0.0144\n",
      "Epoch 17/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0051 - val_loss: 0.0141\n",
      "Epoch 18/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0052 - val_loss: 0.0139\n",
      "Epoch 19/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0053 - val_loss: 0.0137\n",
      "Epoch 20/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0052 - val_loss: 0.0138\n",
      "Epoch 21/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0050 - val_loss: 0.0139\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb38cc53c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3590 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 301ms/step - loss: 0.9309 - val_loss: 0.1443\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.3065 - val_loss: 0.0774\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1338 - val_loss: 0.0408\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0535 - val_loss: 0.0259\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0302 - val_loss: 0.0266\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0384 - val_loss: 0.0227\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0214 - val_loss: 0.0190\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0178 - val_loss: 0.0180\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0173 - val_loss: 0.0185\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0161 - val_loss: 0.0191\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3576c9ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3591 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.1814 - val_loss: 0.0462\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1185 - val_loss: 0.0496\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0339 - val_loss: 0.0487\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb41a5011f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3592 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.1175 - val_loss: 0.0283\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0409 - val_loss: 0.0217\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0371 - val_loss: 0.0212\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0207 - val_loss: 0.0211\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0149 - val_loss: 0.0212\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0119 - val_loss: 0.0203\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0111 - val_loss: 0.0200\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0107 - val_loss: 0.0200\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0086 - val_loss: 0.0199\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0082 - val_loss: 0.0198\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0073 - val_loss: 0.0198\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0067 - val_loss: 0.0198\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0059 - val_loss: 0.0199\n",
      "Epoch 14/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0052 - val_loss: 0.0202\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb30b1b7790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3593 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.0631 - val_loss: 0.0378\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0280 - val_loss: 0.0305\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0243 - val_loss: 0.0264\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0129 - val_loss: 0.0228\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0141 - val_loss: 0.0239\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0106 - val_loss: 0.0252\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb33307c0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3594 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.0709 - val_loss: 0.0388\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0304 - val_loss: 0.0467\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0295 - val_loss: 0.0480\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3151271f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3595 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.1244 - val_loss: 0.0493\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0545 - val_loss: 0.0429\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0382 - val_loss: 0.0403\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0304 - val_loss: 0.0381\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0266 - val_loss: 0.0350\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0224 - val_loss: 0.0319\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0176 - val_loss: 0.0289\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.0122 - val_loss: 0.0255\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0094 - val_loss: 0.0225\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0082 - val_loss: 0.0204\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0092 - val_loss: 0.0192\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0095 - val_loss: 0.0185\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0086 - val_loss: 0.0186\n",
      "Epoch 14/60\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0081 - val_loss: 0.0187\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb301f640d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3596 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 459ms/step - loss: 0.1440 - val_loss: 0.0577\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0707 - val_loss: 0.0394\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0316 - val_loss: 0.0332\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0232 - val_loss: 0.0296\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0217 - val_loss: 0.0284\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0180 - val_loss: 0.0283\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0116 - val_loss: 0.0285\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0103 - val_loss: 0.0287\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb329b46d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3597 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.1329 - val_loss: 0.0433\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0679 - val_loss: 0.0338\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0232 - val_loss: 0.0270\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0153 - val_loss: 0.0216\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0146 - val_loss: 0.0185\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0142 - val_loss: 0.0171\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0127 - val_loss: 0.0162\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0092 - val_loss: 0.0156\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0071 - val_loss: 0.0150\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0073 - val_loss: 0.0146\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0067 - val_loss: 0.0144\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0060 - val_loss: 0.0145\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0055 - val_loss: 0.0147\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb341b1dd30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3598 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.3104 - val_loss: 0.1102\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1142 - val_loss: 0.0545\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0603 - val_loss: 0.0565\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0458 - val_loss: 0.0562\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb315c99af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3599 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 0.2445 - val_loss: 0.1311\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0724 - val_loss: 0.0449\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0272 - val_loss: 0.0198\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0238 - val_loss: 0.0135\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0162 - val_loss: 0.0119\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0197 - val_loss: 0.0117\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0150 - val_loss: 0.0118\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0134 - val_loss: 0.0117\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0117 - val_loss: 0.0113\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0100 - val_loss: 0.0113\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0089 - val_loss: 0.0115\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0082 - val_loss: 0.0117\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3008c7af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3600 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 0.0600 - val_loss: 0.0190\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0193 - val_loss: 0.0190\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0329 - val_loss: 0.0205\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb313963a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3601 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.1771 - val_loss: 0.0394\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0258 - val_loss: 0.0485\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0162 - val_loss: 0.0486\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3008a7790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3602 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.1587 - val_loss: 0.0185\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0411 - val_loss: 0.0131\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0346 - val_loss: 0.0127\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0229 - val_loss: 0.0113\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0171 - val_loss: 0.0112\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0149 - val_loss: 0.0112\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0105 - val_loss: 0.0112\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0072 - val_loss: 0.0113\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0081 - val_loss: 0.0126\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3143b8940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3603 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.0548 - val_loss: 0.0262\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0498 - val_loss: 0.0247\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0180 - val_loss: 0.0287\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0181 - val_loss: 0.0349\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2ed839700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3604 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.0277 - val_loss: 0.0306\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0419 - val_loss: 0.0339\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0143 - val_loss: 0.0324\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2edd191f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3605 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 290ms/step - loss: 0.0727 - val_loss: 0.0384\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0260 - val_loss: 0.0296\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0213 - val_loss: 0.0255\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0110 - val_loss: 0.0261\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0106 - val_loss: 0.0330\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2ee201550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3606 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.0917 - val_loss: 0.0529\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0187 - val_loss: 0.0559\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0133 - val_loss: 0.0593\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2ee7d21f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3607 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.1273 - val_loss: 0.0277\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0591 - val_loss: 0.0449\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0293 - val_loss: 0.0522\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2eecc10d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3608 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.4196 - val_loss: 0.0106\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0979 - val_loss: 0.0196\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0374 - val_loss: 0.0370\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2ef18c1f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3609 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_train_function.<locals>.train_function at 0x7fb2ef208040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0658WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb2ef554160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 0.0658 - val_loss: 0.0634\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0298 - val_loss: 0.0746\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0258 - val_loss: 0.0698\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2ef685040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3610 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x7fb2ef685790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2305WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb2f0a51040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.2305 - val_loss: 0.0649\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0620 - val_loss: 0.0559\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0273 - val_loss: 0.0511\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0183 - val_loss: 0.0450\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0166 - val_loss: 0.0398\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0166 - val_loss: 0.0364\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0146 - val_loss: 0.0342\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0124 - val_loss: 0.0316\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0101 - val_loss: 0.0305\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0083 - val_loss: 0.0305\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0068 - val_loss: 0.0306\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.006 - 0s 20ms/step - loss: 0.0065 - val_loss: 0.0302\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0065 - val_loss: 0.0294\n",
      "Epoch 14/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0064 - val_loss: 0.0283\n",
      "Epoch 15/60\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0059 - val_loss: 0.0272\n",
      "Epoch 16/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0055 - val_loss: 0.0268\n",
      "Epoch 17/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0051 - val_loss: 0.0269\n",
      "Epoch 18/60\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0047 - val_loss: 0.0273\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2f0a51e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3611 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.1393 - val_loss: 0.0106\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0992 - val_loss: 0.0092\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0225 - val_loss: 0.0093\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0134 - val_loss: 0.0107\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2f134edc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3612 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.0379 - val_loss: 0.0258\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0349 - val_loss: 0.0265\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0236 - val_loss: 0.0344\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2f3319ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3613 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 0.0390 - val_loss: 0.0536\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0192 - val_loss: 0.0461\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0180 - val_loss: 0.0386\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0110 - val_loss: 0.0323\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0082 - val_loss: 0.0274\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0066 - val_loss: 0.0246\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0056 - val_loss: 0.0227\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0051 - val_loss: 0.0210\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0046 - val_loss: 0.0208\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0041 - val_loss: 0.0215\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0038 - val_loss: 0.0223\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2f4aa2af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3614 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.2585 - val_loss: 0.0548\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.1561 - val_loss: 0.0373\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0269 - val_loss: 0.0289\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0152 - val_loss: 0.0212\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0190 - val_loss: 0.0183\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0185 - val_loss: 0.0191\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0164 - val_loss: 0.0206\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2f61a38b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3615 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 0.3366 - val_loss: 0.0595\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0744 - val_loss: 0.0575\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0213 - val_loss: 0.0593\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0138 - val_loss: 0.0610\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2f886c790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3616 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.0356 - val_loss: 0.0289\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0255 - val_loss: 0.0245\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0178 - val_loss: 0.0218\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0109 - val_loss: 0.0188\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0088 - val_loss: 0.0163\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0075 - val_loss: 0.0144\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0066 - val_loss: 0.0125\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0056 - val_loss: 0.0115\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0047 - val_loss: 0.0107\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0048 - val_loss: 0.0107\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0045 - val_loss: 0.0103\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0039 - val_loss: 0.0099\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0035 - val_loss: 0.0103\n",
      "Epoch 14/60\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0031 - val_loss: 0.0111\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2d8db18b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3617 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.0997 - val_loss: 0.0505\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0227 - val_loss: 0.0552\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0194 - val_loss: 0.0611\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2db4b5700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3618 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 298ms/step - loss: 0.1365 - val_loss: 0.0770\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0415 - val_loss: 0.0527\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0230 - val_loss: 0.0352\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0114 - val_loss: 0.0291\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0090 - val_loss: 0.0267\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0080 - val_loss: 0.0254\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0063 - val_loss: 0.0247\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0060 - val_loss: 0.0261\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0061 - val_loss: 0.0262\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2dca78550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3619 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.0320 - val_loss: 0.0761\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0223 - val_loss: 0.0795\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0154 - val_loss: 0.0750\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0115 - val_loss: 0.0692\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0081 - val_loss: 0.0643\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0075 - val_loss: 0.0580\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0075 - val_loss: 0.0533\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0067 - val_loss: 0.0501\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0052 - val_loss: 0.0501\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0046 - val_loss: 0.0521\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2ded01310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3620 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 17s 17s/step - loss: 0.5218 - val_loss: 0.0490\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0866 - val_loss: 0.0908\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0495 - val_loss: 0.0869\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2ddb3f4c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3621 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 0.0450 - val_loss: 0.1902\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0603 - val_loss: 0.1961\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0395 - val_loss: 0.1577\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0244 - val_loss: 0.1139\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0151 - val_loss: 0.0853\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0132 - val_loss: 0.0663\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0086 - val_loss: 0.0563\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0058 - val_loss: 0.0504\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0049 - val_loss: 0.0472\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.0046 - val_loss: 0.0445\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.0049 - val_loss: 0.0407\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.0051 - val_loss: 0.0373\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.0050 - val_loss: 0.0341\n",
      "Epoch 14/60\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0047 - val_loss: 0.0309\n",
      "Epoch 15/60\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0042 - val_loss: 0.0278\n",
      "Epoch 16/60\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.0036 - val_loss: 0.0253\n",
      "Epoch 17/60\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0032 - val_loss: 0.0236\n",
      "Epoch 18/60\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0030 - val_loss: 0.0225\n",
      "Epoch 19/60\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0028 - val_loss: 0.0218\n",
      "Epoch 20/60\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0028 - val_loss: 0.0210\n",
      "Epoch 21/60\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.0027 - val_loss: 0.0202\n",
      "Epoch 22/60\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0026 - val_loss: 0.0196\n",
      "Epoch 23/60\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0024 - val_loss: 0.0192\n",
      "Epoch 24/60\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.0022 - val_loss: 0.0189\n",
      "Epoch 25/60\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0021 - val_loss: 0.0188\n",
      "Epoch 26/60\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0020 - val_loss: 0.0186\n",
      "Epoch 27/60\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0020 - val_loss: 0.0184\n",
      "Epoch 28/60\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0019 - val_loss: 0.0179\n",
      "Epoch 29/60\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0018 - val_loss: 0.0173\n",
      "Epoch 30/60\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0017 - val_loss: 0.0168\n",
      "Epoch 31/60\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0017 - val_loss: 0.0164\n",
      "Epoch 32/60\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0016 - val_loss: 0.0164\n",
      "Epoch 33/60\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.0016 - val_loss: 0.0165\n",
      "Epoch 34/60\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0015 - val_loss: 0.0165\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3c4ff4310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3622 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0704 - val_loss: 0.0607\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.0445 - val_loss: 0.0393\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0246 - val_loss: 0.0225\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.0270 - val_loss: 0.0244\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0137 - val_loss: 0.0254\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb387cf8670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3623 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 0.2402 - val_loss: 0.0235\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0352 - val_loss: 0.0502\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0177 - val_loss: 0.0592\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3c48ee0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3624 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 0.0445 - val_loss: 0.0484\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0101 - val_loss: 0.0381\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0082 - val_loss: 0.0309\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0094 - val_loss: 0.0268\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0059 - val_loss: 0.0246\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.0046 - val_loss: 0.0223\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0049 - val_loss: 0.0203\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0051 - val_loss: 0.0183\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0046 - val_loss: 0.0168\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0044 - val_loss: 0.0153\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0042 - val_loss: 0.0144\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0040 - val_loss: 0.0138\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0037 - val_loss: 0.0136\n",
      "Epoch 14/60\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0035 - val_loss: 0.0137\n",
      "Epoch 15/60\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0034 - val_loss: 0.0135\n",
      "Epoch 16/60\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0032 - val_loss: 0.0129\n",
      "Epoch 17/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0030 - val_loss: 0.0120\n",
      "Epoch 18/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0029 - val_loss: 0.0111\n",
      "Epoch 19/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0027 - val_loss: 0.0103\n",
      "Epoch 20/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0026 - val_loss: 0.0095\n",
      "Epoch 21/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0024 - val_loss: 0.0088\n",
      "Epoch 22/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0023 - val_loss: 0.0085\n",
      "Epoch 23/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0022 - val_loss: 0.0085\n",
      "Epoch 24/60\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0020 - val_loss: 0.0084\n",
      "Epoch 25/60\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0019 - val_loss: 0.0084\n",
      "Epoch 26/60\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0018 - val_loss: 0.0084\n",
      "Epoch 27/60\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0017 - val_loss: 0.0087\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb39a906940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3625 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 1s 883ms/step - loss: 0.8637 - val_loss: 0.0334\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.1537 - val_loss: 0.0393\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0177 - val_loss: 0.0451\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb365bcee50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3626 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 1.3301 - val_loss: 0.0815\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.3827 - val_loss: 0.0119\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2020 - val_loss: 0.0101\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0428 - val_loss: 0.0291\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0222 - val_loss: 0.0555\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb329bfe430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3627 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 0.2021 - val_loss: 0.0708\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0425 - val_loss: 0.0957\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0251 - val_loss: 0.1023\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3f039f0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3628 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 1s 916ms/step - loss: 0.7105 - val_loss: 0.0772\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.1111 - val_loss: 0.0380\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0344 - val_loss: 0.0250\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.0321 - val_loss: 0.0171\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0308 - val_loss: 0.0130\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0328 - val_loss: 0.0123\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0284 - val_loss: 0.0116\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0216 - val_loss: 0.0101\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0162 - val_loss: 0.0098\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0128 - val_loss: 0.0099\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0106 - val_loss: 0.0103\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3e56aef70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3629 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 0.1639 - val_loss: 0.0453\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0564 - val_loss: 0.0256\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0266 - val_loss: 0.0136\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0157 - val_loss: 0.0108\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.0125 - val_loss: 0.0100\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0110 - val_loss: 0.0103\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0103 - val_loss: 0.0113\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2dc6da3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3630 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.1763 - val_loss: 0.0597\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0738 - val_loss: 0.0453\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0327 - val_loss: 0.0342\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0199 - val_loss: 0.0257\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0111 - val_loss: 0.0194\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0095 - val_loss: 0.0155\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0098 - val_loss: 0.0136\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0093 - val_loss: 0.0127\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0077 - val_loss: 0.0125\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0065 - val_loss: 0.0123\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0060 - val_loss: 0.0123\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0060 - val_loss: 0.0123\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0058 - val_loss: 0.0122\n",
      "Epoch 14/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0055 - val_loss: 0.0122\n",
      "Epoch 15/60\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0050 - val_loss: 0.0121\n",
      "Epoch 16/60\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0047 - val_loss: 0.0121\n",
      "Epoch 17/60\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0045 - val_loss: 0.0122\n",
      "Epoch 18/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0043 - val_loss: 0.0121\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2d898aaf0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3631 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 0.0177 - val_loss: 0.0407\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0284 - val_loss: 0.0414\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0109 - val_loss: 0.0370\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0142 - val_loss: 0.0355\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0069 - val_loss: 0.0319\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0073 - val_loss: 0.0280\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0060 - val_loss: 0.0260\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0059 - val_loss: 0.0253\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0044 - val_loss: 0.0248\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0041 - val_loss: 0.0246\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0035 - val_loss: 0.0245\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0036 - val_loss: 0.0244\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0035 - val_loss: 0.0241\n",
      "Epoch 14/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0033 - val_loss: 0.0240\n",
      "Epoch 15/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0031 - val_loss: 0.0242\n",
      "Epoch 16/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0031 - val_loss: 0.0244\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2f5be8550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3632 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.6877 - val_loss: 0.2559\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2168 - val_loss: 0.1363\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0704 - val_loss: 0.0760\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0376 - val_loss: 0.0570\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0289 - val_loss: 0.0432\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0216 - val_loss: 0.0353\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0186 - val_loss: 0.0298\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0161 - val_loss: 0.0254\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0122 - val_loss: 0.0224\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0099 - val_loss: 0.0202\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0094 - val_loss: 0.0190\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.009 - 0s 20ms/step - loss: 0.0097 - val_loss: 0.0177\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0103 - val_loss: 0.0168\n",
      "Epoch 14/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0102 - val_loss: 0.0163\n",
      "Epoch 15/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0095 - val_loss: 0.0161\n",
      "Epoch 16/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0087 - val_loss: 0.0161\n",
      "Epoch 17/60\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0076 - val_loss: 0.0161\n",
      "Epoch 18/60\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0067 - val_loss: 0.0161\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2f43100d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3633 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.0813 - val_loss: 0.0365\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0330 - val_loss: 0.0499\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0195 - val_loss: 0.0563\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2f0b60ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3634 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.0635 - val_loss: 0.0608\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0408 - val_loss: 0.0575\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0270 - val_loss: 0.0530\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0199 - val_loss: 0.0500\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0197 - val_loss: 0.0479\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0129 - val_loss: 0.0456\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0103 - val_loss: 0.0434\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0090 - val_loss: 0.0407\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0086 - val_loss: 0.0389\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0073 - val_loss: 0.0372\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0062 - val_loss: 0.0353\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0055 - val_loss: 0.0333\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0052 - val_loss: 0.0315\n",
      "Epoch 14/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0048 - val_loss: 0.0298\n",
      "Epoch 15/60\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0046 - val_loss: 0.0285\n",
      "Epoch 16/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0046 - val_loss: 0.0275\n",
      "Epoch 17/60\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0045 - val_loss: 0.0266\n",
      "Epoch 18/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0040 - val_loss: 0.0259\n",
      "Epoch 19/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0038 - val_loss: 0.0253\n",
      "Epoch 20/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0038 - val_loss: 0.0248\n",
      "Epoch 21/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0036 - val_loss: 0.0244\n",
      "Epoch 22/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0032 - val_loss: 0.0243\n",
      "Epoch 23/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0031 - val_loss: 0.0240\n",
      "Epoch 24/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0030 - val_loss: 0.0238\n",
      "Epoch 25/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0030 - val_loss: 0.0236\n",
      "Epoch 26/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0029 - val_loss: 0.0235\n",
      "Epoch 27/60\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0028 - val_loss: 0.0236\n",
      "Epoch 28/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0027 - val_loss: 0.0237\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2ef249ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3635 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.0338 - val_loss: 0.0375\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0106 - val_loss: 0.0449\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0097 - val_loss: 0.0447\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2ee7d2550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3636 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.0490 - val_loss: 0.0489\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0321 - val_loss: 0.0467\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0177 - val_loss: 0.0458\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0115 - val_loss: 0.0391\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0100 - val_loss: 0.0348\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0077 - val_loss: 0.0326\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0082 - val_loss: 0.0321\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0063 - val_loss: 0.0319\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0058 - val_loss: 0.0319\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0052 - val_loss: 0.0321\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2edebb670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3637 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 1.3468 - val_loss: 0.0895\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4567 - val_loss: 0.0725\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1834 - val_loss: 0.0625\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0618 - val_loss: 0.0530\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0476 - val_loss: 0.0482\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0365 - val_loss: 0.0438\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0294 - val_loss: 0.0413\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0250 - val_loss: 0.0403\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0229 - val_loss: 0.0397\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0217 - val_loss: 0.0388\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0208 - val_loss: 0.0380\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0202 - val_loss: 0.0372\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.019 - 0s 83ms/step - loss: 0.0195 - val_loss: 0.0366\n",
      "Epoch 14/60\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0189 - val_loss: 0.0360\n",
      "Epoch 15/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0182 - val_loss: 0.0354\n",
      "Epoch 16/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0175 - val_loss: 0.0348\n",
      "Epoch 17/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0168 - val_loss: 0.0343\n",
      "Epoch 18/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0161 - val_loss: 0.0338\n",
      "Epoch 19/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0155 - val_loss: 0.0333\n",
      "Epoch 20/60\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0149 - val_loss: 0.0328\n",
      "Epoch 21/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0143 - val_loss: 0.0324\n",
      "Epoch 22/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0137 - val_loss: 0.0319\n",
      "Epoch 23/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0133 - val_loss: 0.0315\n",
      "Epoch 24/60\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0128 - val_loss: 0.0311\n",
      "Epoch 25/60\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0122 - val_loss: 0.0305\n",
      "Epoch 26/60\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0117 - val_loss: 0.0296\n",
      "Epoch 27/60\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0112 - val_loss: 0.0290\n",
      "Epoch 28/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0106 - val_loss: 0.0284\n",
      "Epoch 29/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0101 - val_loss: 0.0280\n",
      "Epoch 30/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0095 - val_loss: 0.0278\n",
      "Epoch 31/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0091 - val_loss: 0.0276\n",
      "Epoch 32/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0088 - val_loss: 0.0277\n",
      "Epoch 33/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0084 - val_loss: 0.0278\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb315b34280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3638 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.2573 - val_loss: 0.0596\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1466 - val_loss: 0.0456\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0924 - val_loss: 0.0445\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0306 - val_loss: 0.0418\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0186 - val_loss: 0.0393\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0141 - val_loss: 0.0379\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0117 - val_loss: 0.0366\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0108 - val_loss: 0.0356\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0113 - val_loss: 0.0350\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0113 - val_loss: 0.0343\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0108 - val_loss: 0.0337\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0099 - val_loss: 0.0332\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0091 - val_loss: 0.0329\n",
      "Epoch 14/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0084 - val_loss: 0.0327\n",
      "Epoch 15/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0083 - val_loss: 0.0326\n",
      "Epoch 16/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0081 - val_loss: 0.0325\n",
      "Epoch 17/60\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0080 - val_loss: 0.0324\n",
      "Epoch 18/60\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0077 - val_loss: 0.0323\n",
      "Epoch 19/60\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0074 - val_loss: 0.0323\n",
      "Epoch 20/60\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0072 - val_loss: 0.0323\n",
      "Epoch 21/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0071 - val_loss: 0.0323\n",
      "Epoch 22/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0069 - val_loss: 0.0323\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb31c5335e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3639 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5574 - val_loss: 0.0781\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1726 - val_loss: 0.0598\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1378 - val_loss: 0.0515\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0558 - val_loss: 0.0447\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0303 - val_loss: 0.0404\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0238 - val_loss: 0.0371\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0183 - val_loss: 0.0342\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0149 - val_loss: 0.0323\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0130 - val_loss: 0.0315\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0126 - val_loss: 0.0306\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0116 - val_loss: 0.0305\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0109 - val_loss: 0.0304\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0105 - val_loss: 0.0307\n",
      "Epoch 14/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0102 - val_loss: 0.0309\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3138c4160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3640 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 331ms/step - loss: 0.1166 - val_loss: 0.0324\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0381 - val_loss: 0.0378\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0148 - val_loss: 0.0396\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb315b939d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3641 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.1670 - val_loss: 0.0618\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0365 - val_loss: 0.0436\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0273 - val_loss: 0.0353\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0169 - val_loss: 0.0322\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0164 - val_loss: 0.0322\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0099 - val_loss: 0.0331\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3151275e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3642 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.2753 - val_loss: 0.0340\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1244 - val_loss: 0.0360\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0954 - val_loss: 0.0366\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb315b054c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3643 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.4433 - val_loss: 0.0969\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0898 - val_loss: 0.0542\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0426 - val_loss: 0.0384\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0261 - val_loss: 0.0351\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0234 - val_loss: 0.0345\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0181 - val_loss: 0.0341\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0163 - val_loss: 0.0338\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.017 - 0s 21ms/step - loss: 0.0171 - val_loss: 0.0338\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0143 - val_loss: 0.0341\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0110 - val_loss: 0.0343\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3d6392e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3644 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.0716 - val_loss: 0.0491\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0406 - val_loss: 0.0477\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0241 - val_loss: 0.0461\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0149 - val_loss: 0.0440\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0119 - val_loss: 0.0427\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0099 - val_loss: 0.0425\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0081 - val_loss: 0.0425\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0072 - val_loss: 0.0406\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0068 - val_loss: 0.0398\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0062 - val_loss: 0.0395\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0058 - val_loss: 0.0392\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0057 - val_loss: 0.0389\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0054 - val_loss: 0.0386\n",
      "Epoch 14/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0052 - val_loss: 0.0382\n",
      "Epoch 15/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0051 - val_loss: 0.0378\n",
      "Epoch 16/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0048 - val_loss: 0.0375\n",
      "Epoch 17/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0044 - val_loss: 0.0371\n",
      "Epoch 18/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0041 - val_loss: 0.0366\n",
      "Epoch 19/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0037 - val_loss: 0.0362\n",
      "Epoch 20/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0034 - val_loss: 0.0357\n",
      "Epoch 21/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0032 - val_loss: 0.0352\n",
      "Epoch 22/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0030 - val_loss: 0.0348\n",
      "Epoch 23/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0028 - val_loss: 0.0344\n",
      "Epoch 24/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0026 - val_loss: 0.0342\n",
      "Epoch 25/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0026 - val_loss: 0.0341\n",
      "Epoch 26/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0023 - val_loss: 0.0341\n",
      "Epoch 27/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0023 - val_loss: 0.0341\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb357c075e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3645 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 0.5629 - val_loss: 0.0604\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1823 - val_loss: 0.0410\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0598 - val_loss: 0.0375\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0278 - val_loss: 0.0371\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0201 - val_loss: 0.0360\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0152 - val_loss: 0.0358\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0146 - val_loss: 0.0368\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0129 - val_loss: 0.0374\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb41d13fc10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3646 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.0206 - val_loss: 0.0364\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0240 - val_loss: 0.0374\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0172 - val_loss: 0.0386\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3da872e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3647 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 0.0941 - val_loss: 0.0413\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0335 - val_loss: 0.0377\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0295 - val_loss: 0.0389\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0171 - val_loss: 0.0394\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb4189fd3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3648 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.0767 - val_loss: 0.0374\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0225 - val_loss: 0.0472\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0314 - val_loss: 0.0516\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb30bb61e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3649 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.1062 - val_loss: 0.0373\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0488 - val_loss: 0.0375\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0184 - val_loss: 0.0407\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb325212b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3650 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.0670 - val_loss: 0.0395\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0253 - val_loss: 0.0366\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0162 - val_loss: 0.0366\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0145 - val_loss: 0.0363\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0123 - val_loss: 0.0377\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0082 - val_loss: 0.0383\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb31f325160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3651 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.0232 - val_loss: 0.0405\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0204 - val_loss: 0.0389\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0166 - val_loss: 0.0383\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0101 - val_loss: 0.0385\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0081 - val_loss: 0.0385\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb31b1f7a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3652 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.9550 - val_loss: 0.0414\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3298 - val_loss: 0.0420\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1202 - val_loss: 0.0434\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb317f4bd30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3653 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.0312 - val_loss: 0.0393\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0147 - val_loss: 0.0392\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0116 - val_loss: 0.0393\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0085 - val_loss: 0.0398\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb34718cc10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3654 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.0499 - val_loss: 0.0392\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0324 - val_loss: 0.0390\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0187 - val_loss: 0.0387\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0154 - val_loss: 0.0387\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0125 - val_loss: 0.0399\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0097 - val_loss: 0.0397\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb32c4f2310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3655 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.0365 - val_loss: 0.0397\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0322 - val_loss: 0.0392\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0237 - val_loss: 0.0391\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0179 - val_loss: 0.0403\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0106 - val_loss: 0.0416\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb45af79550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3656 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.0273 - val_loss: 0.0461\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0166 - val_loss: 0.0485\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0188 - val_loss: 0.0497\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb33f41c700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3657 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.2332 - val_loss: 0.0358\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0742 - val_loss: 0.0376\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0474 - val_loss: 0.0398\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb35d8f43a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3658 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.1361 - val_loss: 0.0452\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0690 - val_loss: 0.0350\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0155 - val_loss: 0.0364\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0147 - val_loss: 0.0428\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb357b1a1f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3659 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.0866 - val_loss: 0.0350\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0255 - val_loss: 0.0351\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0158 - val_loss: 0.0346\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0081 - val_loss: 0.0347\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0074 - val_loss: 0.0347\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb357143af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3660 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.0733 - val_loss: 0.0328\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0242 - val_loss: 0.0329\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0219 - val_loss: 0.0330\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb34ba84c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3661 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.0477 - val_loss: 0.0400\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0268 - val_loss: 0.0375\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0198 - val_loss: 0.0338\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0207 - val_loss: 0.0345\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0152 - val_loss: 0.0353\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3f4d0e940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3662 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.0754 - val_loss: 0.0343\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0302 - val_loss: 0.0340\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0156 - val_loss: 0.0341\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0143 - val_loss: 0.0346\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb371a81af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3663 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 0.3939 - val_loss: 0.0404\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.1118 - val_loss: 0.0346\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0633 - val_loss: 0.0339\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0426 - val_loss: 0.0338\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0306 - val_loss: 0.0339\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0236 - val_loss: 0.0340\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb36e1cbb80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3664 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 0.2001 - val_loss: 0.0344\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0678 - val_loss: 0.0345\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0264 - val_loss: 0.0355\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3cc54faf0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3665 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.1890 - val_loss: 0.0324\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0600 - val_loss: 0.0403\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0318 - val_loss: 0.0391\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3a6115c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3666 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.0584 - val_loss: 0.0339\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0618 - val_loss: 0.0342\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0177 - val_loss: 0.0341\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3c7343f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3667 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:5 out of the last 16 calls to <function Model.make_train_function.<locals>.train_function at 0x7fb3b2284790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0263WARNING:tensorflow:5 out of the last 16 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb3d2c50d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.0263 - val_loss: 0.0354\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0180 - val_loss: 0.0377\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0083 - val_loss: 0.0390\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3c637a040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3668 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x7fb3c637a940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0856WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb3cad0a3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.0856 - val_loss: 0.0501\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0246 - val_loss: 0.0681\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0143 - val_loss: 0.0804\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb412418310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3669 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x7fb3f1ee0160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2010WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb47b6521f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 0.2010 - val_loss: 0.0349\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0770 - val_loss: 0.0346\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0459 - val_loss: 0.0351\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0286 - val_loss: 0.0348\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb410be9280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3670 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.1495 - val_loss: 0.0788\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.1475 - val_loss: 0.0631\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0540 - val_loss: 0.0470\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0207 - val_loss: 0.0419\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0133 - val_loss: 0.0422\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0099 - val_loss: 0.0427\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3d76db160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3671 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.1430 - val_loss: 0.0344\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0379 - val_loss: 0.0341\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0200 - val_loss: 0.0342\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0184 - val_loss: 0.0342\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3b9deea60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3672 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 1.1282 - val_loss: 0.1104\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.5225 - val_loss: 0.0557\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2116 - val_loss: 0.0327\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0809 - val_loss: 0.0403\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0374 - val_loss: 0.0473\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3c4861430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3673 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.2177 - val_loss: 0.0334\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0757 - val_loss: 0.0316\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0487 - val_loss: 0.0357\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.033 - 0s 28ms/step - loss: 0.0331 - val_loss: 0.0375\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb430bc70d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3674 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 0.2297 - val_loss: 0.0311\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1135 - val_loss: 0.0312\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0660 - val_loss: 0.0316\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb37b730040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3675 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.0900 - val_loss: 0.0335\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0376 - val_loss: 0.0331\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0235 - val_loss: 0.0331\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0135 - val_loss: 0.0359\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3c70433a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3676 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.2260 - val_loss: 0.0303\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0804 - val_loss: 0.0347\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.0419 - val_loss: 0.0366\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb35f7c4790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3677 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.6085 - val_loss: 0.0292\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1396 - val_loss: 0.0304\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0271 - val_loss: 0.0318\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb365806ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3678 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.3164 - val_loss: 0.0290\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0360 - val_loss: 0.0292\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0194 - val_loss: 0.0295\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb34a64cc10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3679 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:5 out of the last 14 calls to <function Model.make_train_function.<locals>.train_function at 0x7fb34a8d0e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3726WARNING:tensorflow:5 out of the last 14 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb35008f160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.3726 - val_loss: 0.0290\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1984 - val_loss: 0.0295\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1300 - val_loss: 0.0310\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb350c20820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3680 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x7fb34a8d0ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0389WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb431f31550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 0.0389 - val_loss: 0.0316\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0205 - val_loss: 0.0324\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0094 - val_loss: 0.0325\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb4713640d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3681 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x7fb3c042d940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1252WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb33b03c940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.1252 - val_loss: 0.0300\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0455 - val_loss: 0.0294\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0213 - val_loss: 0.0299\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0149 - val_loss: 0.0276\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0120 - val_loss: 0.0282\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0085 - val_loss: 0.0290\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3577fa4c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3682 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.6904 - val_loss: 0.0451\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2383 - val_loss: 0.0299\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1079 - val_loss: 0.0286\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0590 - val_loss: 0.0288\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0431 - val_loss: 0.0295\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb34be6f040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3683 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 0.2184 - val_loss: 0.0321\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1386 - val_loss: 0.0500\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0460 - val_loss: 0.0643\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb35a030700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3684 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.0925 - val_loss: 0.0325\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0250 - val_loss: 0.0314\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0148 - val_loss: 0.0318\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0123 - val_loss: 0.0313\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0087 - val_loss: 0.0315\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0041 - val_loss: 0.0321\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3458b6040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3685 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.2032 - val_loss: 0.0312\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.1112 - val_loss: 0.0312\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0718 - val_loss: 0.0302\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0441 - val_loss: 0.0297\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0301 - val_loss: 0.0294\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0226 - val_loss: 0.0325\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0170 - val_loss: 0.0361\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb32f95ae50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3686 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 1s 553ms/step - loss: 0.0858 - val_loss: 0.0854\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0222 - val_loss: 0.0886\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0434 - val_loss: 0.0718\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0218 - val_loss: 0.0623\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0102 - val_loss: 0.0582\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0078 - val_loss: 0.0563\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0068 - val_loss: 0.0557\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0057 - val_loss: 0.0556\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0045 - val_loss: 0.0561\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0041 - val_loss: 0.0573\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3c53dc8b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3687 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 306ms/step - loss: 0.2400 - val_loss: 0.0281\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0681 - val_loss: 0.0280\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0203 - val_loss: 0.0285\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0152 - val_loss: 0.0305\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3a5336af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3688 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.1693 - val_loss: 0.0287\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0784 - val_loss: 0.0278\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0522 - val_loss: 0.0268\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0388 - val_loss: 0.0276\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0342 - val_loss: 0.0290\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb36437c700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3689 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 0.5344 - val_loss: 0.2387\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6012 - val_loss: 0.1035\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.0628 - val_loss: 0.0463\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0402 - val_loss: 0.0292\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0341 - val_loss: 0.0268\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0327 - val_loss: 0.0262\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0294 - val_loss: 0.0266\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0239 - val_loss: 0.0274\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb335bdf280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3690 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 0.3027 - val_loss: 0.0314\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0379 - val_loss: 0.0295\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0231 - val_loss: 0.0293\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0257 - val_loss: 0.0294\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0206 - val_loss: 0.0297\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb35780e3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3691 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.2955 - val_loss: 0.0333\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1129 - val_loss: 0.0460\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0349 - val_loss: 0.0491\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb327c67820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3692 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 0.0836 - val_loss: 0.0274\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0377 - val_loss: 0.0274\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0094 - val_loss: 0.0314\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3089043a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3693 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.9480 - val_loss: 0.0821\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.3535 - val_loss: 0.0386\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1012 - val_loss: 0.0291\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0766 - val_loss: 0.0275\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0641 - val_loss: 0.0276\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0554 - val_loss: 0.0278\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb31b50c9d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3694 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 0.2093 - val_loss: 0.0303\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0627 - val_loss: 0.0328\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0262 - val_loss: 0.0380\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb313797ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3695 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 1.0571 - val_loss: 0.0773\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2268 - val_loss: 0.0385\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0996 - val_loss: 0.0274\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0528 - val_loss: 0.0255\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0358 - val_loss: 0.0288\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0293 - val_loss: 0.0342\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3141170d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3696 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.0525 - val_loss: 0.0317\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0352 - val_loss: 0.0338\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0247 - val_loss: 0.0361\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3154dba60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3697 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.0623 - val_loss: 0.0290\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0242 - val_loss: 0.0328\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0152 - val_loss: 0.0352\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb315e7b430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3698 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 0.6856 - val_loss: 0.0248\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2008 - val_loss: 0.0235\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0428 - val_loss: 0.0245\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0211 - val_loss: 0.0251\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2f961d670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3699 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.2394 - val_loss: 0.0262\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.1077 - val_loss: 0.0233\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0453 - val_loss: 0.0267\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0268 - val_loss: 0.0293\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2fc91b430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3700 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.0457 - val_loss: 0.0259\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0242 - val_loss: 0.0255\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0131 - val_loss: 0.0236\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0104 - val_loss: 0.0242\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0066 - val_loss: 0.0253\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3006464c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3701 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 299ms/step - loss: 0.0907 - val_loss: 0.0333\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0319 - val_loss: 0.0214\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0161 - val_loss: 0.0274\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0133 - val_loss: 0.0336\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb36e0b5940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3702 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.0643 - val_loss: 0.0270\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0905 - val_loss: 0.0225\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0175 - val_loss: 0.0242\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0130 - val_loss: 0.0311\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb36f0df790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3703 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.1175 - val_loss: 0.0320\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0268 - val_loss: 0.0235\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0197 - val_loss: 0.0219\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0143 - val_loss: 0.0215\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0110 - val_loss: 0.0212\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0073 - val_loss: 0.0211\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0059 - val_loss: 0.0211\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0044 - val_loss: 0.0212\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0038 - val_loss: 0.0212\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb374b9a940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3704 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.0306 - val_loss: 0.0279\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0315 - val_loss: 0.0252\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0134 - val_loss: 0.0229\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0141 - val_loss: 0.0224\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0115 - val_loss: 0.0226\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0095 - val_loss: 0.0228\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb42f0ac280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3705 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.0412 - val_loss: 0.0251\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0238 - val_loss: 0.0220\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0131 - val_loss: 0.0212\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0107 - val_loss: 0.0207\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0062 - val_loss: 0.0209\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0058 - val_loss: 0.0211\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3b5443f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3706 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.3391 - val_loss: 0.0198\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2539 - val_loss: 0.0206\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0945 - val_loss: 0.0211\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb43a3930d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3707 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.0767 - val_loss: 0.0246\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0387 - val_loss: 0.0232\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0328 - val_loss: 0.0221\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0194 - val_loss: 0.0218\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0119 - val_loss: 0.0212\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0090 - val_loss: 0.0207\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0074 - val_loss: 0.0205\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0067 - val_loss: 0.0202\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0051 - val_loss: 0.0201\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0041 - val_loss: 0.0202\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0037 - val_loss: 0.0205\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2ee045b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3708 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.0669 - val_loss: 0.0207\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0482 - val_loss: 0.0186\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0240 - val_loss: 0.0176\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0196 - val_loss: 0.0176\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0157 - val_loss: 0.0178\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2fb2d03a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3709 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.1183 - val_loss: 0.0373\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0582 - val_loss: 0.0271\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0517 - val_loss: 0.0225\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0346 - val_loss: 0.0224\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0202 - val_loss: 0.0221\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0199 - val_loss: 0.0219\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0184 - val_loss: 0.0217\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0173 - val_loss: 0.0217\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0156 - val_loss: 0.0217\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb30fa21040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3710 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.2920 - val_loss: 0.0222\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1000 - val_loss: 0.0173\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0578 - val_loss: 0.0163\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0289 - val_loss: 0.0157\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0181 - val_loss: 0.0154\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0129 - val_loss: 0.0158\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0109 - val_loss: 0.0168\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb31479a9d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3711 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.4843 - val_loss: 0.0629\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2624 - val_loss: 0.0521\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1360 - val_loss: 0.0403\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0740 - val_loss: 0.0312\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0498 - val_loss: 0.0244\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0364 - val_loss: 0.0201\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0279 - val_loss: 0.0161\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0229 - val_loss: 0.0146\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0191 - val_loss: 0.0145\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0173 - val_loss: 0.0153\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0164 - val_loss: 0.0174\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2eee1f4c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3712 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.1370 - val_loss: 0.0265\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0419 - val_loss: 0.0194\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0212 - val_loss: 0.0163\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0161 - val_loss: 0.0156\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0102 - val_loss: 0.0156\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0096 - val_loss: 0.0157\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2dc584040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3713 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.1683 - val_loss: 0.0150\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0579 - val_loss: 0.0124\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0318 - val_loss: 0.0120\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0220 - val_loss: 0.0125\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0157 - val_loss: 0.0124\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2f0997ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3714 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.0445 - val_loss: 0.0205\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0249 - val_loss: 0.0207\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0184 - val_loss: 0.0225\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2ef47d280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3715 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 481ms/step - loss: 0.1966 - val_loss: 0.0125\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0885 - val_loss: 0.0090\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0472 - val_loss: 0.0088\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0323 - val_loss: 0.0092\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0119 - val_loss: 0.0096\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2e8f04550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3716 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 298ms/step - loss: 0.2658 - val_loss: 0.0429\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0719 - val_loss: 0.0167\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0311 - val_loss: 0.0080\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0358 - val_loss: 0.0070\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0282 - val_loss: 0.0077\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0142 - val_loss: 0.0086\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2e9400ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3717 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.1456 - val_loss: 0.0202\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0658 - val_loss: 0.0406\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0327 - val_loss: 0.0463\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2e9993b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3718 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.0587 - val_loss: 0.0270\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0590 - val_loss: 0.0092\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0252 - val_loss: 0.0079\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0189 - val_loss: 0.0071\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0135 - val_loss: 0.0075\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0093 - val_loss: 0.0083\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2e9f510d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3719 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.1089 - val_loss: 0.0064\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0373 - val_loss: 0.0077\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0215 - val_loss: 0.0119\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2ea4f8040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3720 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.0695 - val_loss: 0.0131\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0381 - val_loss: 0.0121\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0368 - val_loss: 0.0117\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0242 - val_loss: 0.0117\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0169 - val_loss: 0.0123\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0141 - val_loss: 0.0132\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2eaaa1940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3721 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.0573 - val_loss: 0.0352\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0550 - val_loss: 0.0279\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0274 - val_loss: 0.0288\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0123 - val_loss: 0.0280\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2eb081820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3722 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 0.0712 - val_loss: 0.0279\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0283 - val_loss: 0.0203\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0174 - val_loss: 0.0172\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0149 - val_loss: 0.0169\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0158 - val_loss: 0.0173\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0114 - val_loss: 0.0173\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2c7f76ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3723 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.3285 - val_loss: 0.0199\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1131 - val_loss: 0.0301\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0441 - val_loss: 0.0374\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2c8cc0e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3724 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.1256 - val_loss: 0.0223\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0511 - val_loss: 0.0267\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0294 - val_loss: 0.0362\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2ca8ee1f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3725 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.0717 - val_loss: 0.0269\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0311 - val_loss: 0.0273\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0223 - val_loss: 0.0281\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2cbdf74c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3726 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:5 out of the last 16 calls to <function Model.make_train_function.<locals>.train_function at 0x7fb2cb69faf0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4123WARNING:tensorflow:5 out of the last 16 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb2cde7faf0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 0.4123 - val_loss: 0.3397\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1564 - val_loss: 0.1693\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0362 - val_loss: 0.0459\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0190 - val_loss: 0.0382\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0208 - val_loss: 0.0660\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0283 - val_loss: 0.0683\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2cf20dca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3727 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 303ms/step - loss: 0.1414 - val_loss: 0.0348\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0824 - val_loss: 0.0321\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0449 - val_loss: 0.0329\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0410 - val_loss: 0.0327\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2d0191af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3728 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.1821 - val_loss: 0.0755\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0439 - val_loss: 0.0416\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0592 - val_loss: 0.0392\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0268 - val_loss: 0.0433\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0221 - val_loss: 0.0461\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2d279b0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3729 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 0.2565 - val_loss: 0.0369\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.1199 - val_loss: 0.0412\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0442 - val_loss: 0.0350\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0357 - val_loss: 0.0291\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0345 - val_loss: 0.0295\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0319 - val_loss: 0.0303\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2d4a7e1f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3730 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.1878 - val_loss: 0.0352\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1128 - val_loss: 0.0353\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0376 - val_loss: 0.0344\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0232 - val_loss: 0.0354\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0223 - val_loss: 0.0360\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2d5c248b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3731 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.0816 - val_loss: 0.0521\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1051 - val_loss: 0.0779\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0276 - val_loss: 0.0978\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2d78ec790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3732 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 1s 502ms/step - loss: 0.1477 - val_loss: 0.0540\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0404 - val_loss: 0.0359\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0391 - val_loss: 0.0352\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0384 - val_loss: 0.0374\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0390 - val_loss: 0.0385\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2eb745ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3733 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.0532 - val_loss: 0.0376\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0338 - val_loss: 0.0387\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0330 - val_loss: 0.0395\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2b961ddc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3734 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 19s 19s/step - loss: 0.5659 - val_loss: 0.0628\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.1418 - val_loss: 0.0436\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0852 - val_loss: 0.0332\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0537 - val_loss: 0.0376\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0429 - val_loss: 0.0384\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2eeed4700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3735 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 1s 520ms/step - loss: 0.0614 - val_loss: 0.0379\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0241 - val_loss: 0.0370\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0296 - val_loss: 0.0362\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0194 - val_loss: 0.0366\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0157 - val_loss: 0.0371\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb44c591310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3736 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.8623 - val_loss: 0.1520\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2436 - val_loss: 0.0829\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0547 - val_loss: 0.0465\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0261 - val_loss: 0.0387\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0314 - val_loss: 0.0367\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0329 - val_loss: 0.0361\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0356 - val_loss: 0.0357\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0297 - val_loss: 0.0361\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0235 - val_loss: 0.0363\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb35e257670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3737 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.0974 - val_loss: 0.0385\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0379 - val_loss: 0.0389\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0292 - val_loss: 0.0389\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3f04e5e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3738 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 1.6347 - val_loss: 0.1385\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.9432 - val_loss: 0.0679\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.3759 - val_loss: 0.0418\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0959 - val_loss: 0.0463\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0437 - val_loss: 0.0476\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb36f09e5e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3739 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 0.1644 - val_loss: 0.0469\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0360 - val_loss: 0.0494\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0226 - val_loss: 0.0554\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3f22e2d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3740 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.2072 - val_loss: 0.0489\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0436 - val_loss: 0.0460\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0269 - val_loss: 0.0451\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0203 - val_loss: 0.0453\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0187 - val_loss: 0.0467\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2d7dc65e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3741 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 0.1577 - val_loss: 0.0456\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0559 - val_loss: 0.0460\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0383 - val_loss: 0.0465\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb43315aaf0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3742 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 0.2815 - val_loss: 0.0507\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2287 - val_loss: 0.0542\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1049 - val_loss: 0.0574\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2d7594f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3743 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 0.2753 - val_loss: 0.0517\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0751 - val_loss: 0.0485\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0485 - val_loss: 0.0472\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0364 - val_loss: 0.0466\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.029 - 0s 25ms/step - loss: 0.0290 - val_loss: 0.0474\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0253 - val_loss: 0.0488\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2d39c9790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3744 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 0.0779 - val_loss: 0.0639\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0592 - val_loss: 0.0538\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0233 - val_loss: 0.0486\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0189 - val_loss: 0.0489\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0158 - val_loss: 0.0493\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2d0191700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3745 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 1s 968ms/step - loss: 0.4476 - val_loss: 0.0459\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0547 - val_loss: 0.0477\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0542 - val_loss: 0.0492\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2cb69f5e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3746 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 0.0658 - val_loss: 0.0485\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0303 - val_loss: 0.0480\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0296 - val_loss: 0.0483\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0170 - val_loss: 0.0494\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2c89a3430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3747 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 484ms/step - loss: 0.1139 - val_loss: 0.0465\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0624 - val_loss: 0.0488\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0445 - val_loss: 0.0454\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0271 - val_loss: 0.0446\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0200 - val_loss: 0.0453\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0142 - val_loss: 0.0466\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2eaaa14c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3748 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 0.2836 - val_loss: 0.0693\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1194 - val_loss: 0.0524\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0778 - val_loss: 0.0476\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0487 - val_loss: 0.0469\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0306 - val_loss: 0.0472\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0250 - val_loss: 0.0476\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2e9993a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3749 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 302ms/step - loss: 0.1913 - val_loss: 0.0494\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0565 - val_loss: 0.0497\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0318 - val_loss: 0.0500\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2e8e2d280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3750 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.1142 - val_loss: 0.0463\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0351 - val_loss: 0.0587\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0211 - val_loss: 0.0599\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3056921f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3751 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.1743 - val_loss: 0.0433\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0370 - val_loss: 0.0467\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0398 - val_loss: 0.0475\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2fb2d0820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3752 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:5 out of the last 16 calls to <function Model.make_train_function.<locals>.train_function at 0x7fb30fa219d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0931WARNING:tensorflow:5 out of the last 16 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb3360f2160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 466ms/step - loss: 0.0931 - val_loss: 0.0498\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0367 - val_loss: 0.0502\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0305 - val_loss: 0.0502\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb303b34040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3753 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x7fb3f0106c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.9910WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb363805040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 303ms/step - loss: 1.9910 - val_loss: 0.0954\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5289 - val_loss: 0.0799\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2608 - val_loss: 0.0687\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1441 - val_loss: 0.0628\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0552 - val_loss: 0.0594\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0351 - val_loss: 0.0581\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0274 - val_loss: 0.0569\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0255 - val_loss: 0.0569\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0266 - val_loss: 0.0563\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0287 - val_loss: 0.0562\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0296 - val_loss: 0.0565\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0295 - val_loss: 0.0568\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb397dfbee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3754 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 0.1246 - val_loss: 0.0498\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0298 - val_loss: 0.0506\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0584 - val_loss: 0.0511\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3d63375e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3755 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.4093 - val_loss: 0.0732\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2079 - val_loss: 0.0617\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0627 - val_loss: 0.0569\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0419 - val_loss: 0.0561\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0251 - val_loss: 0.0583\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0211 - val_loss: 0.0617\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb326fa2550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3756 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 0.0552 - val_loss: 0.0472\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0234 - val_loss: 0.0475\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0156 - val_loss: 0.0490\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3034144c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3757 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.0948 - val_loss: 0.0533\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0521 - val_loss: 0.0537\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0433 - val_loss: 0.0540\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2fe8b5700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3758 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 0.3808 - val_loss: 0.0540\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2207 - val_loss: 0.0604\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0559 - val_loss: 0.0591\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2f9d6f700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3759 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:5 out of the last 16 calls to <function Model.make_train_function.<locals>.train_function at 0x7fb2f961d670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0578WARNING:tensorflow:5 out of the last 16 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb315ef99d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.0578 - val_loss: 0.0489\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0390 - val_loss: 0.0517\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0353 - val_loss: 0.0519\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb315d2f280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3760 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x7fb315ef9f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0825WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb31554cc10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 0.0825 - val_loss: 0.0517\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0631 - val_loss: 0.0513\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0322 - val_loss: 0.0508\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0215 - val_loss: 0.0506\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0205 - val_loss: 0.0519\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0165 - val_loss: 0.0517\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3154db1f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3761 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 2.0920 - val_loss: 0.2211\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.2424 - val_loss: 0.1011\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3585 - val_loss: 0.0570\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1287 - val_loss: 0.0513\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0577 - val_loss: 0.0520\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0340 - val_loss: 0.0536\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3145a8040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3762 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.0326 - val_loss: 0.0521\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0248 - val_loss: 0.0520\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0203 - val_loss: 0.0501\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0167 - val_loss: 0.0487\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0143 - val_loss: 0.0471\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0123 - val_loss: 0.0467\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0114 - val_loss: 0.0472\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0100 - val_loss: 0.0483\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb324349c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3763 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 0.1072 - val_loss: 0.0512\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0439 - val_loss: 0.0500\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0315 - val_loss: 0.0501\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0166 - val_loss: 0.0505\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3462aa9d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3764 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.1094 - val_loss: 0.0559\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0363 - val_loss: 0.0512\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0206 - val_loss: 0.0515\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0191 - val_loss: 0.0531\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb31a399af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3765 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.0649 - val_loss: 0.0490\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0541 - val_loss: 0.0483\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0259 - val_loss: 0.0498\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0162 - val_loss: 0.0496\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb33cbfb1f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3766 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 1s 626ms/step - loss: 0.1533 - val_loss: 0.0491\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.0564 - val_loss: 0.0502\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0224 - val_loss: 0.0527\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb365956940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3767 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 0.0927 - val_loss: 0.0489\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0421 - val_loss: 0.0456\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0264 - val_loss: 0.0469\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0207 - val_loss: 0.0488\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3c5430280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3768 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.3772 - val_loss: 0.0653\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.1033 - val_loss: 0.0548\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0329 - val_loss: 0.0523\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0212 - val_loss: 0.0502\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0240 - val_loss: 0.0508\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0284 - val_loss: 0.0509\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb334b9ed30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3769 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.1587 - val_loss: 0.0538\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0845 - val_loss: 0.0676\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0369 - val_loss: 0.0782\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3299280d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3770 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 484ms/step - loss: 0.1058 - val_loss: 0.0525\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0380 - val_loss: 0.0517\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0262 - val_loss: 0.0530\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0265 - val_loss: 0.0541\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb35d53b820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3771 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.1219 - val_loss: 0.0571\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0584 - val_loss: 0.0587\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0229 - val_loss: 0.0566\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0167 - val_loss: 0.0492\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0130 - val_loss: 0.0489\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0102 - val_loss: 0.0484\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0072 - val_loss: 0.0488\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0066 - val_loss: 0.0496\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb357086310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3772 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.8234 - val_loss: 0.0445\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1842 - val_loss: 0.0474\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1107 - val_loss: 0.0518\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb352c31c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3773 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.0481 - val_loss: 0.0512\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0271 - val_loss: 0.0501\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0210 - val_loss: 0.0494\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0170 - val_loss: 0.0495\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0166 - val_loss: 0.0526\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3fbe2b430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3774 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.1630 - val_loss: 0.0531\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0655 - val_loss: 0.0481\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0322 - val_loss: 0.0477\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0171 - val_loss: 0.0496\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0160 - val_loss: 0.0546\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb34b847ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3775 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.1188 - val_loss: 0.0536\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0949 - val_loss: 0.0553\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0810 - val_loss: 0.0543\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb365806a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3776 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.3515 - val_loss: 0.0624\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1503 - val_loss: 0.0564\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0474 - val_loss: 0.0546\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0295 - val_loss: 0.0539\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0234 - val_loss: 0.0530\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0203 - val_loss: 0.0524\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0198 - val_loss: 0.0522\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0197 - val_loss: 0.0523\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0201 - val_loss: 0.0526\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb36e6caa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3777 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.2497 - val_loss: 0.0517\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0757 - val_loss: 0.0503\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0189 - val_loss: 0.0546\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0199 - val_loss: 0.0579\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3943a4280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3778 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.0313 - val_loss: 0.0529\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0355 - val_loss: 0.0536\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0325 - val_loss: 0.0563\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3795c7c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3779 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 0.0662 - val_loss: 0.0430\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0366 - val_loss: 0.0490\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0281 - val_loss: 0.0487\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3c3b8f0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3780 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.1553 - val_loss: 0.0568\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0460 - val_loss: 0.0491\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0476 - val_loss: 0.0526\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0321 - val_loss: 0.0559\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3b996d430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3781 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.1459 - val_loss: 0.0505\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1250 - val_loss: 0.0517\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0572 - val_loss: 0.0545\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb417618040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3782 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0762 - val_loss: 0.0391\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.0403 - val_loss: 0.0434\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.0375 - val_loss: 0.0469\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3f1ee0b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3783 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 0.0310 - val_loss: 0.0414\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.0524 - val_loss: 0.0459\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0190 - val_loss: 0.0495\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3a88dcd30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3784 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:5 out of the last 14 calls to <function Model.make_train_function.<locals>.train_function at 0x7fb3c637aca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1077WARNING:tensorflow:5 out of the last 14 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb3c3d1a1f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 298ms/step - loss: 0.1077 - val_loss: 0.0639\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0554 - val_loss: 0.0517\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0343 - val_loss: 0.0480\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0279 - val_loss: 0.0468\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0274 - val_loss: 0.0472\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0238 - val_loss: 0.0469\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3a8943820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3785 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.3522 - val_loss: 0.0883\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0712 - val_loss: 0.1417\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0844 - val_loss: 0.1451\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb391b7ad30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3786 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.0558 - val_loss: 0.0404\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0541 - val_loss: 0.0351\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0396 - val_loss: 0.0317\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0221 - val_loss: 0.0303\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0268 - val_loss: 0.0302\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0215 - val_loss: 0.0304\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0147 - val_loss: 0.0310\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb36eb3f700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3787 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 1s 542ms/step - loss: 0.0773 - val_loss: 0.1491\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0430 - val_loss: 0.0875\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0239 - val_loss: 0.0534\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0202 - val_loss: 0.0430\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0159 - val_loss: 0.0400\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0129 - val_loss: 0.0371\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0115 - val_loss: 0.0347\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0096 - val_loss: 0.0333\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0076 - val_loss: 0.0323\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0070 - val_loss: 0.0317\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0058 - val_loss: 0.0313\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0048 - val_loss: 0.0310\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.004 - 0s 26ms/step - loss: 0.0044 - val_loss: 0.0309\n",
      "Epoch 14/60\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0038 - val_loss: 0.0308\n",
      "Epoch 15/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0034 - val_loss: 0.0308\n",
      "Epoch 16/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0030 - val_loss: 0.0307\n",
      "Epoch 17/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0027 - val_loss: 0.0306\n",
      "Epoch 18/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0024 - val_loss: 0.0305\n",
      "Epoch 19/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0023 - val_loss: 0.0304\n",
      "Epoch 20/60\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0022 - val_loss: 0.0301\n",
      "Epoch 21/60\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0021 - val_loss: 0.0294\n",
      "Epoch 22/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0020 - val_loss: 0.0288\n",
      "Epoch 23/60\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0020 - val_loss: 0.0285\n",
      "Epoch 24/60\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0019 - val_loss: 0.0283\n",
      "Epoch 25/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0019 - val_loss: 0.0282\n",
      "Epoch 26/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0017 - val_loss: 0.0280\n",
      "Epoch 27/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0017 - val_loss: 0.0279\n",
      "Epoch 28/60\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0016 - val_loss: 0.0278\n",
      "Epoch 29/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0015 - val_loss: 0.0277\n",
      "Epoch 30/60\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0014 - val_loss: 0.0275\n",
      "Epoch 31/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0014 - val_loss: 0.0273\n",
      "Epoch 32/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0014 - val_loss: 0.0272\n",
      "Epoch 33/60\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0013 - val_loss: 0.0271\n",
      "Epoch 34/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0013 - val_loss: 0.0270\n",
      "Epoch 35/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0012 - val_loss: 0.0269\n",
      "Epoch 36/60\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.0012 - val_loss: 0.0269\n",
      "Epoch 37/60\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0012 - val_loss: 0.0269\n",
      "Epoch 38/60\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0011 - val_loss: 0.0270\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3766a0ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3788 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.0666 - val_loss: 0.0419\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0241 - val_loss: 0.0327\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0269 - val_loss: 0.0294\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0178 - val_loss: 0.0310\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0167 - val_loss: 0.0332\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb34d6210d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3789 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.7111 - val_loss: 0.0798\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2039 - val_loss: 0.0834\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0525 - val_loss: 0.0795\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0252 - val_loss: 0.0750\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0238 - val_loss: 0.0712\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0327 - val_loss: 0.0715\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0299 - val_loss: 0.0747\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb357417e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3790 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 0.0377 - val_loss: 0.0417\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0442 - val_loss: 0.0425\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0315 - val_loss: 0.0408\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0308 - val_loss: 0.0398\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0203 - val_loss: 0.0386\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0190 - val_loss: 0.0374\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0140 - val_loss: 0.0361\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0122 - val_loss: 0.0347\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0101 - val_loss: 0.0334\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0088 - val_loss: 0.0322\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0069 - val_loss: 0.0311\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0061 - val_loss: 0.0302\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0051 - val_loss: 0.0295\n",
      "Epoch 14/60\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0048 - val_loss: 0.0290\n",
      "Epoch 15/60\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0042 - val_loss: 0.0292\n",
      "Epoch 16/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0037 - val_loss: 0.0294\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb35c1908b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3791 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 1s 624ms/step - loss: 0.1293 - val_loss: 0.0528\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0473 - val_loss: 0.0570\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0201 - val_loss: 0.0586\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb33cb4bb80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3792 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.0417 - val_loss: 0.0491\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0321 - val_loss: 0.0575\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0251 - val_loss: 0.0687\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb45af79940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3793 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 1s 691ms/step - loss: 0.1551 - val_loss: 0.0180\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0694 - val_loss: 0.0294\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0469 - val_loss: 0.0384\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb345b1be50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3794 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:5 out of the last 26 calls to <function Model.make_train_function.<locals>.train_function at 0x7fb35e3bdd30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2583WARNING:tensorflow:5 out of the last 26 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb3456a6a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 472ms/step - loss: 0.2583 - val_loss: 0.1041\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0529 - val_loss: 0.0829\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0162 - val_loss: 0.0580\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0202 - val_loss: 0.0432\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0243 - val_loss: 0.0397\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0145 - val_loss: 0.0393\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0137 - val_loss: 0.0402\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0113 - val_loss: 0.0396\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb32fbf44c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3795 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 488ms/step - loss: 0.0399 - val_loss: 0.0326\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0375 - val_loss: 0.0311\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0223 - val_loss: 0.0215\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0154 - val_loss: 0.0143\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0143 - val_loss: 0.0114\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0115 - val_loss: 0.0104\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0077 - val_loss: 0.0101\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0080 - val_loss: 0.0101\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0066 - val_loss: 0.0102\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0055 - val_loss: 0.0101\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0047 - val_loss: 0.0099\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0042 - val_loss: 0.0097\n",
      "Epoch 14/60\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0042 - val_loss: 0.0095\n",
      "Epoch 15/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0040 - val_loss: 0.0095\n",
      "Epoch 16/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0037 - val_loss: 0.0096\n",
      "Epoch 17/60\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0036 - val_loss: 0.0101\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb31b75aca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3796 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 301ms/step - loss: 0.0424 - val_loss: 0.0331\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0375 - val_loss: 0.0324\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0181 - val_loss: 0.0321\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0153 - val_loss: 0.0328\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0126 - val_loss: 0.0336\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb31ee349d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3797 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.3892 - val_loss: 0.0368\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1453 - val_loss: 0.0327\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0318 - val_loss: 0.0299\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0213 - val_loss: 0.0275\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0191 - val_loss: 0.0257\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0181 - val_loss: 0.0246\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0185 - val_loss: 0.0238\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0174 - val_loss: 0.0232\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0167 - val_loss: 0.0228\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0163 - val_loss: 0.0225\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0153 - val_loss: 0.0222\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0144 - val_loss: 0.0221\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0135 - val_loss: 0.0220\n",
      "Epoch 14/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0131 - val_loss: 0.0219\n",
      "Epoch 15/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0119 - val_loss: 0.0219\n",
      "Epoch 16/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0114 - val_loss: 0.0221\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3089d2940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3798 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 0.0966 - val_loss: 0.0364\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0716 - val_loss: 0.0444\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0284 - val_loss: 0.0461\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb48e5283a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3799 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 465ms/step - loss: 0.5968 - val_loss: 0.0165\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2065 - val_loss: 0.0336\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0696 - val_loss: 0.0463\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3cd0465e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3800 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.2117 - val_loss: 0.0479\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0586 - val_loss: 0.0451\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0383 - val_loss: 0.0371\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0236 - val_loss: 0.0302\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0187 - val_loss: 0.0250\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0134 - val_loss: 0.0220\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0124 - val_loss: 0.0202\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0109 - val_loss: 0.0193\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0101 - val_loss: 0.0183\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0100 - val_loss: 0.0171\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0087 - val_loss: 0.0160\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0070 - val_loss: 0.0153\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0057 - val_loss: 0.0151\n",
      "Epoch 14/60\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0052 - val_loss: 0.0154\n",
      "Epoch 15/60\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0050 - val_loss: 0.0161\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3b38584c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3801 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 1s 569ms/step - loss: 0.2220 - val_loss: 0.0284\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.063 - 0s 115ms/step - loss: 0.0636 - val_loss: 0.0327\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 293ms/step - loss: 0.0295 - val_loss: 0.0358\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb35caf5700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3802 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 0.3253 - val_loss: 0.0600\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0996 - val_loss: 0.0292\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0308 - val_loss: 0.0184\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0193 - val_loss: 0.0123\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.0158 - val_loss: 0.0090\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0137 - val_loss: 0.0069\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0125 - val_loss: 0.0063\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0118 - val_loss: 0.0060\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0113 - val_loss: 0.0059\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0104 - val_loss: 0.0059\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0097 - val_loss: 0.0059\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0085 - val_loss: 0.0060\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb30d63f0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3803 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 1s 558ms/step - loss: 0.0889 - val_loss: 0.0272\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.0351 - val_loss: 0.0303\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 0.0295 - val_loss: 0.0324\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb339663160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3804 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0581 - val_loss: 0.0248\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0444 - val_loss: 0.0226\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0286 - val_loss: 0.0249\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0204 - val_loss: 0.0259\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2fb5b44c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3805 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.2312 - val_loss: 0.0203\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2422 - val_loss: 0.0105\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0553 - val_loss: 0.0063\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0316 - val_loss: 0.0055\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0426 - val_loss: 0.0058\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0277 - val_loss: 0.0060\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb31480eee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3806 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 0.0645 - val_loss: 0.0187\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0491 - val_loss: 0.0149\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0317 - val_loss: 0.0079\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0191 - val_loss: 0.0064\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0229 - val_loss: 0.0063\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0144 - val_loss: 0.0066\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0138 - val_loss: 0.0067\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2fc5c68b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3807 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 0.2846 - val_loss: 0.0067\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1162 - val_loss: 0.0185\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0675 - val_loss: 0.0298\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2edd19160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3808 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 1s 600ms/step - loss: 0.1802 - val_loss: 0.0172\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.1241 - val_loss: 0.0569\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.118 - 0s 185ms/step - loss: 0.1180 - val_loss: 0.0304\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2ee7d2790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3809 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.0598 - val_loss: 0.0723\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0461 - val_loss: 0.0335\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0336 - val_loss: 0.0217\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0258 - val_loss: 0.0173\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0182 - val_loss: 0.0126\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0158 - val_loss: 0.0091\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0146 - val_loss: 0.0076\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0129 - val_loss: 0.0069\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0126 - val_loss: 0.0067\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0119 - val_loss: 0.0067\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0106 - val_loss: 0.0069\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2ef554ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3810 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1344 - val_loss: 0.0263\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0341 - val_loss: 0.0553\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0436 - val_loss: 0.0685\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2f1c5f160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3811 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 0.1076 - val_loss: 0.0251\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0542 - val_loss: 0.0300\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0462 - val_loss: 0.0272\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2f4aa2ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3812 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.1781 - val_loss: 0.0146\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0804 - val_loss: 0.0137\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0315 - val_loss: 0.0170\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0286 - val_loss: 0.0194\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2d7e6ef70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3813 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.1663 - val_loss: 0.0368\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0485 - val_loss: 0.0500\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0438 - val_loss: 0.0552\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb4860fb310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3814 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 1s 519ms/step - loss: 0.7611 - val_loss: 0.1646\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3323 - val_loss: 0.0603\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2033 - val_loss: 0.0402\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0712 - val_loss: 0.0325\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0365 - val_loss: 0.0256\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0284 - val_loss: 0.0205\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.0225 - val_loss: 0.0172\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.0239 - val_loss: 0.0152\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0244 - val_loss: 0.0134\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0224 - val_loss: 0.0120\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0206 - val_loss: 0.0110\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0199 - val_loss: 0.0104\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0198 - val_loss: 0.0104\n",
      "Epoch 14/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0187 - val_loss: 0.0112\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb36ea2e670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3815 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.0707 - val_loss: 0.0271\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0357 - val_loss: 0.0247\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0282 - val_loss: 0.0194\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0258 - val_loss: 0.0190\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0199 - val_loss: 0.0192\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0155 - val_loss: 0.0196\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb34548f1f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3816 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 0.5199 - val_loss: 0.0059\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1286 - val_loss: 0.0298\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0575 - val_loss: 0.0424\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3bcb81ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3817 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 0.0953 - val_loss: 0.0320\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0399 - val_loss: 0.0160\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0275 - val_loss: 0.0119\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0347 - val_loss: 0.0115\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0273 - val_loss: 0.0123\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0147 - val_loss: 0.0127\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3afb8c790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3818 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 464ms/step - loss: 0.0699 - val_loss: 0.0194\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0403 - val_loss: 0.0115\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0328 - val_loss: 0.0094\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.026 - 0s 28ms/step - loss: 0.0267 - val_loss: 0.0091\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0246 - val_loss: 0.0092\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0215 - val_loss: 0.0097\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb43b2f1550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3819 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 462ms/step - loss: 0.1858 - val_loss: 0.0219\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0815 - val_loss: 0.0215\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0377 - val_loss: 0.0189\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0314 - val_loss: 0.0181\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0273 - val_loss: 0.0182\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0230 - val_loss: 0.0189\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3930c0160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3820 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 0.1180 - val_loss: 0.0452\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0692 - val_loss: 0.0264\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0290 - val_loss: 0.0151\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0244 - val_loss: 0.0084\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0190 - val_loss: 0.0065\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0147 - val_loss: 0.0081\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0130 - val_loss: 0.0117\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2df6abc10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3821 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 0.4699 - val_loss: 0.0168\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.1175 - val_loss: 0.0127\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0365 - val_loss: 0.0114\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0281 - val_loss: 0.0104\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0253 - val_loss: 0.0094\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0236 - val_loss: 0.0084\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0200 - val_loss: 0.0082\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0170 - val_loss: 0.0080\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0177 - val_loss: 0.0079\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0123 - val_loss: 0.0081\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0106 - val_loss: 0.0088\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2eeb13550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3822 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.1723 - val_loss: 0.0423\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0669 - val_loss: 0.0379\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0528 - val_loss: 0.0323\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0237 - val_loss: 0.0273\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0188 - val_loss: 0.0191\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0213 - val_loss: 0.0149\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0159 - val_loss: 0.0124\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0130 - val_loss: 0.0114\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0115 - val_loss: 0.0116\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0079 - val_loss: 0.0113\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0070 - val_loss: 0.0112\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0062 - val_loss: 0.0128\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0053 - val_loss: 0.0144\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2f881b9d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3823 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 1s 501ms/step - loss: 0.2683 - val_loss: 0.0064\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0771 - val_loss: 0.0107\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0303 - val_loss: 0.0131\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2dc6dda60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3824 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.3416 - val_loss: 0.0435\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.1247 - val_loss: 0.0228\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0375 - val_loss: 0.0103\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0150 - val_loss: 0.0069\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0117 - val_loss: 0.0081\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0158 - val_loss: 0.0094\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2f5d46040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3825 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.2404 - val_loss: 0.0343\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1104 - val_loss: 0.0340\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0284 - val_loss: 0.0275\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0255 - val_loss: 0.0223\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0238 - val_loss: 0.0203\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0200 - val_loss: 0.0186\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0164 - val_loss: 0.0175\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0135 - val_loss: 0.0164\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0114 - val_loss: 0.0153\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0090 - val_loss: 0.0146\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0078 - val_loss: 0.0142\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0070 - val_loss: 0.0139\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0059 - val_loss: 0.0138\n",
      "Epoch 14/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0062 - val_loss: 0.0138\n",
      "Epoch 15/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0051 - val_loss: 0.0139\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2ed77f0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3826 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 1s 509ms/step - loss: 0.1885 - val_loss: 0.0633\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1286 - val_loss: 0.0532\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1001 - val_loss: 0.0461\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0255 - val_loss: 0.0416\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0201 - val_loss: 0.0401\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0206 - val_loss: 0.0404\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0160 - val_loss: 0.0412\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2ee9b1820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3827 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.3276 - val_loss: 0.0222\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1495 - val_loss: 0.0341\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0452 - val_loss: 0.0368\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2ea7a0700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3828 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 463ms/step - loss: 0.1654 - val_loss: 0.0275\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0640 - val_loss: 0.0098\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0512 - val_loss: 0.0074\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0268 - val_loss: 0.0058\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0209 - val_loss: 0.0054\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0216 - val_loss: 0.0057\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0171 - val_loss: 0.0066\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2c7e09e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3829 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 0.1504 - val_loss: 0.0450\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1601 - val_loss: 0.0670\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0523 - val_loss: 0.0722\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2e9d92d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3830 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.9070 - val_loss: 0.0395\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2794 - val_loss: 0.0061\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0899 - val_loss: 0.0066\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0412 - val_loss: 0.0080\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2ddde04c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3831 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.1091 - val_loss: 0.0058\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0351 - val_loss: 0.0125\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0376 - val_loss: 0.0145\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2c7f3f3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3832 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 1s 543ms/step - loss: 0.0546 - val_loss: 0.0267\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0998 - val_loss: 0.0180\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0418 - val_loss: 0.0150\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0201 - val_loss: 0.0139\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0220 - val_loss: 0.0137\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0304 - val_loss: 0.0160\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0103 - val_loss: 0.0187\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2c193caf0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3833 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.0396 - val_loss: 0.0291\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0226 - val_loss: 0.0318\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0216 - val_loss: 0.0324\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2c1df6280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3834 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 0.1176 - val_loss: 0.0505\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.0365 - val_loss: 0.0493\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0307 - val_loss: 0.0488\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0184 - val_loss: 0.0417\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0168 - val_loss: 0.0361\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0137 - val_loss: 0.0332\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0091 - val_loss: 0.0318\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0087 - val_loss: 0.0311\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0077 - val_loss: 0.0301\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0059 - val_loss: 0.0295\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0057 - val_loss: 0.0294\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0045 - val_loss: 0.0295\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.0042 - val_loss: 0.0295\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2c23e61f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3835 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.2673 - val_loss: 0.0173\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0677 - val_loss: 0.0166\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0441 - val_loss: 0.0200\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0324 - val_loss: 0.0243\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2c28b7040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3836 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 0.0674 - val_loss: 0.0412\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0307 - val_loss: 0.0333\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0260 - val_loss: 0.0213\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0135 - val_loss: 0.0166\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0085 - val_loss: 0.0159\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0073 - val_loss: 0.0158\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0053 - val_loss: 0.0167\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0057 - val_loss: 0.0177\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2c2c5b790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3837 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 1s 578ms/step - loss: 0.1808 - val_loss: 0.0179\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0785 - val_loss: 0.0271\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0345 - val_loss: 0.0327\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2c3152670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3838 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 1s 616ms/step - loss: 0.0863 - val_loss: 0.0272\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.0293 - val_loss: 0.0322\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0175 - val_loss: 0.0296\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2c35e1dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3839 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 0.0875 - val_loss: 0.0205\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.0412 - val_loss: 0.0136\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0355 - val_loss: 0.0098\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0300 - val_loss: 0.0129\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0244 - val_loss: 0.0138\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2c3ab18b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3840 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.1897 - val_loss: 0.0338\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0551 - val_loss: 0.0197\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0386 - val_loss: 0.0144\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0465 - val_loss: 0.0115\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0311 - val_loss: 0.0108\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0307 - val_loss: 0.0129\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0218 - val_loss: 0.0143\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2c5095280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3841 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 0.4389 - val_loss: 0.0233\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.0839 - val_loss: 0.0081\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0233 - val_loss: 0.0059\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0208 - val_loss: 0.0053\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0201 - val_loss: 0.0051\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0193 - val_loss: 0.0052\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0141 - val_loss: 0.0054\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2c55ae160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3842 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 1s 505ms/step - loss: 0.1203 - val_loss: 0.0112\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0239 - val_loss: 0.0067\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0313 - val_loss: 0.0060\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0144 - val_loss: 0.0059\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0111 - val_loss: 0.0060\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0104 - val_loss: 0.0062\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2c6643a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3843 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1799 - val_loss: 0.0183\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 0.0426 - val_loss: 0.0291\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0533 - val_loss: 0.0370\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2cd490940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3844 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1602 - val_loss: 0.0059\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.0533 - val_loss: 0.0083\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0511 - val_loss: 0.0099\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2d5996160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3845 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.1693 - val_loss: 0.0066\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0496 - val_loss: 0.0081\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0569 - val_loss: 0.0223\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2a92a2ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3846 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:5 out of the last 16 calls to <function Model.make_train_function.<locals>.train_function at 0x7fb2a7c6a430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1657WARNING:tensorflow:5 out of the last 16 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb2aa586c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1657 - val_loss: 0.0364\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0897 - val_loss: 0.0266\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0423 - val_loss: 0.0180\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.030 - 0s 56ms/step - loss: 0.0301 - val_loss: 0.0121\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0328 - val_loss: 0.0083\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0161 - val_loss: 0.0063\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.0099 - val_loss: 0.0056\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0057 - val_loss: 0.0056\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.0056 - val_loss: 0.0059\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2ac01a700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3847 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 0.0712 - val_loss: 0.0056\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0375 - val_loss: 0.0054\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0185 - val_loss: 0.0063\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0258 - val_loss: 0.0054\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2ad5215e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3848 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.0978 - val_loss: 0.0129\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0538 - val_loss: 0.0089\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0456 - val_loss: 0.0067\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0233 - val_loss: 0.0066\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0260 - val_loss: 0.0076\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0114 - val_loss: 0.0089\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2ae6f9d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3849 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.1764 - val_loss: 0.0048\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1327 - val_loss: 0.0087\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0589 - val_loss: 0.0051\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2b0a03c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3850 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.2230 - val_loss: 0.0167\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0505 - val_loss: 0.0218\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0377 - val_loss: 0.0223\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2b20993a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3851 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 0.1046 - val_loss: 0.0108\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0460 - val_loss: 0.0116\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0284 - val_loss: 0.0094\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0247 - val_loss: 0.0072\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0135 - val_loss: 0.0055\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0115 - val_loss: 0.0048\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0099 - val_loss: 0.0047\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0085 - val_loss: 0.0050\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0076 - val_loss: 0.0051\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2b4d9f0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3852 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 0.2210 - val_loss: 0.0243\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0557 - val_loss: 0.0231\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0158 - val_loss: 0.0112\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0242 - val_loss: 0.0078\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0104 - val_loss: 0.0077\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0126 - val_loss: 0.0069\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0082 - val_loss: 0.0066\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0076 - val_loss: 0.0057\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0093 - val_loss: 0.0055\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0050 - val_loss: 0.0054\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0055 - val_loss: 0.0058\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0048 - val_loss: 0.0065\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2b5d58820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3853 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 0.0963 - val_loss: 0.0080\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0399 - val_loss: 0.0051\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0310 - val_loss: 0.0054\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0318 - val_loss: 0.0070\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3c4a09af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3854 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 1s 661ms/step - loss: 0.1250 - val_loss: 0.0161\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0573 - val_loss: 0.0063\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0268 - val_loss: 0.0045\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0452 - val_loss: 0.0047\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0169 - val_loss: 0.0053\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3cb74aaf0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3855 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.4742 - val_loss: 0.0176\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1670 - val_loss: 0.0100\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1001 - val_loss: 0.0155\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0456 - val_loss: 0.0177\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb36eedd700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3856 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 0.1154 - val_loss: 0.0186\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1074 - val_loss: 0.0210\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0459 - val_loss: 0.0225\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb4442ea160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3857 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 303ms/step - loss: 0.9415 - val_loss: 0.0578\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2019 - val_loss: 0.0229\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0895 - val_loss: 0.0171\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0550 - val_loss: 0.0138\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0458 - val_loss: 0.0111\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0234 - val_loss: 0.0084\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0223 - val_loss: 0.0068\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0148 - val_loss: 0.0062\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0116 - val_loss: 0.0061\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0109 - val_loss: 0.0058\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0084 - val_loss: 0.0055\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0085 - val_loss: 0.0053\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.0072 - val_loss: 0.0053\n",
      "Epoch 14/60\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0063 - val_loss: 0.0054\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb33cbfb700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3858 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 0.0344 - val_loss: 0.0071\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0397 - val_loss: 0.0066\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0306 - val_loss: 0.0086\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0246 - val_loss: 0.0120\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb34ccd9280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3859 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 301ms/step - loss: 0.0879 - val_loss: 0.0142\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0405 - val_loss: 0.0146\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0212 - val_loss: 0.0141\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0230 - val_loss: 0.0114\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0145 - val_loss: 0.0070\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0090 - val_loss: 0.0055\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0070 - val_loss: 0.0060\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0094 - val_loss: 0.0070\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3812dff70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3860 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 487ms/step - loss: 0.1249 - val_loss: 0.0060\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0399 - val_loss: 0.0062\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0341 - val_loss: 0.0075\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2b38e89d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3861 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 1s 835ms/step - loss: 1.2872 - val_loss: 0.0090\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8629 - val_loss: 0.0056\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1485 - val_loss: 0.0071\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0563 - val_loss: 0.0145\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2af6179d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3862 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 301ms/step - loss: 0.1334 - val_loss: 0.0121\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0475 - val_loss: 0.0074\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0201 - val_loss: 0.0065\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0279 - val_loss: 0.0063\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0143 - val_loss: 0.0063\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0062 - val_loss: 0.0063\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0044 - val_loss: 0.0060\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0061 - val_loss: 0.0059\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0037 - val_loss: 0.0059\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0044 - val_loss: 0.0058\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0037 - val_loss: 0.0059\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0033 - val_loss: 0.0060\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2acf43550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3863 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 490ms/step - loss: 0.1718 - val_loss: 0.0145\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.0335 - val_loss: 0.0193\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.0666 - val_loss: 0.0442\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2c512d1f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3864 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 0.1058 - val_loss: 0.0125\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0437 - val_loss: 0.0107\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0336 - val_loss: 0.0080\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0246 - val_loss: 0.0066\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0122 - val_loss: 0.0061\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0085 - val_loss: 0.0059\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0072 - val_loss: 0.0059\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0067 - val_loss: 0.0059\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0063 - val_loss: 0.0059\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2c5095f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3865 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 0.0543 - val_loss: 0.0103\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0624 - val_loss: 0.0126\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0396 - val_loss: 0.0143\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2c27893a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3866 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.0595 - val_loss: 0.0166\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0508 - val_loss: 0.0125\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0225 - val_loss: 0.0119\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0198 - val_loss: 0.0106\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0121 - val_loss: 0.0093\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0093 - val_loss: 0.0080\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0071 - val_loss: 0.0074\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0054 - val_loss: 0.0074\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.0055 - val_loss: 0.0072\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0061 - val_loss: 0.0074\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0040 - val_loss: 0.0083\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2c23e6ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3867 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3740 - val_loss: 0.0815\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.1447 - val_loss: 0.0417\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.1082 - val_loss: 0.0294\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0840 - val_loss: 0.0231\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.0417 - val_loss: 0.0153\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0304 - val_loss: 0.0125\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0208 - val_loss: 0.0105\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0174 - val_loss: 0.0084\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0148 - val_loss: 0.0071\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0135 - val_loss: 0.0063\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0106 - val_loss: 0.0058\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0099 - val_loss: 0.0056\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0093 - val_loss: 0.0057\n",
      "Epoch 14/60\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.0084 - val_loss: 0.0059\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2ead713a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "loss = []\n",
    "preds = []\n",
    "seed(1)\n",
    "for retrain_idx in range(552):\n",
    "    X = Xl.iloc[t_train_start[retrain_idx]:t_train_end[retrain_idx],:]\n",
    "    X_idx = X.apply(pd.Series.nunique) != 1\n",
    "    X = X.loc[:,X_idx]\n",
    "    X_val = Xl.loc[t_val_start[retrain_idx]:t_val_end[retrain_idx],X_idx]\n",
    "    X_test = Xl.loc[t_test_start[retrain_idx]:t_test_end[retrain_idx],X_idx]\n",
    "    y = y_agg.iloc[t_train_start[retrain_idx]:t_train_end[retrain_idx],:]\n",
    "    y_val = y_agg.loc[t_val_start[retrain_idx]:t_val_end[retrain_idx],:]\n",
    "    y_test = y_agg.loc[t_test_start[retrain_idx]:t_test_end[retrain_idx],:]\n",
    "    model = Sequential()\n",
    "    model.add(LayerNormalization())\n",
    "    model.add(Dense(128,activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(64,activation='tanh'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(32,activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(32,activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(16,activation='relu'))\n",
    "    model.add(Dense(16,activation='relu'))\n",
    "    model.add(Dense(16,activation='relu'))\n",
    "    model.add(Dense(8,activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    optimizer = Adam(learning_rate=0.006)\n",
    "    model.compile(optimizer=optimizer,loss='mse')\n",
    "    early_stop = EarlyStopping(monitor='val_loss', verbose=0, patience=2)\n",
    "    history = model.fit(x=X,y=y,validation_data=(X_val,y_val), batch_size=128, epochs=60,verbose=1,callbacks=[early_stop])\n",
    "    preds.append(model.predict(X_test))\n",
    "    loss.append(min(history.history['val_loss']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_org = y_agg.loc[t_test_start[0]:t_test_end[551],:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate R^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   -0.45381\n",
       "dtype: float64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-np.sum((np.squeeze(y_org)-np.squeeze(preds))**2)/np.sum((y_org-np.mean(y_org))**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A good R^2 is expected to be between 0 to 0.05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Finance.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
