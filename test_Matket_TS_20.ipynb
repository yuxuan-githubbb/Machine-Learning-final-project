{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "NcDhtxLCV8Tw",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, LayerNormalization, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from numpy.random import seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 426
    },
    "id": "vI12F-E9V8T1",
    "outputId": "869138a1-ef3d-4c37-86c8-e408129de90a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "Xl = pd.read_csv('Xl.csv',header=None)\n",
    "Xs = pd.read_csv('Xs.csv',header=None)\n",
    "R = pd.read_csv('y.csv',header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_agg=R.iloc[::-1].rolling(window=12).sum().iloc[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Psf8guRAV8T1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "t_train_start = list(range(46*12))\n",
    "t_train_end =[x+120 for x in t_train_start]\n",
    "t_val_start= [x for x in t_train_end]\n",
    "t_val_end = [x+60 for x in t_val_start]\n",
    "t_test_start = [x for x in t_val_end]\n",
    "t_test_end = [x for x in t_test_start]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(552,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(t_test_end) #model needed to be retrained every month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "731"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_test_end[551]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.3943 - val_loss: 0.0313\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1167 - val_loss: 0.0313\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 2.0091 - val_loss: 0.0333\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.4053 - val_loss: 0.0314\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.6728 - val_loss: 0.0321\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 0.5898 - val_loss: 0.0402\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.2033 - val_loss: 0.0309\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1637 - val_loss: 0.0310\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_3 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 1.1156 - val_loss: 0.0494\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4186 - val_loss: 0.0370\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.1659 - val_loss: 0.0309\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.1198 - val_loss: 0.0254\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0842 - val_loss: 0.0211\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0615 - val_loss: 0.0210\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0518 - val_loss: 0.0261\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_4 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 1.4096 - val_loss: 0.0327\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4796 - val_loss: 0.0321\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2425 - val_loss: 0.0295\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0933 - val_loss: 0.0316\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb59cdd5790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_5 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 0.4187 - val_loss: 0.0444\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.1087 - val_loss: 0.0266\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0626 - val_loss: 0.0246\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0500 - val_loss: 0.0306\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5a4478b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_6 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 0.6453 - val_loss: 0.0373\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2939 - val_loss: 0.0314\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.2647 - val_loss: 0.0300\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1904 - val_loss: 0.0301\n",
      "WARNING:tensorflow:7 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5895bfd30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_7 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 0.7454 - val_loss: 0.0314\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2436 - val_loss: 0.0299\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1201 - val_loss: 0.0306\n",
      "WARNING:tensorflow:8 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5a4478040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_8 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 1.0110 - val_loss: 0.1029\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4408 - val_loss: 0.2131\n",
      "WARNING:tensorflow:9 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5882360d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_9 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.3914WARNING:tensorflow:5 out of the last 14 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb58b535040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.2966 - val_loss: 0.0884\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1312 - val_loss: 0.0806\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0776 - val_loss: 0.0683\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0713 - val_loss: 0.0531\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0552 - val_loss: 0.0431\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0579 - val_loss: 0.0382\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0498 - val_loss: 0.0353\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0381 - val_loss: 0.0338\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0339 - val_loss: 0.0332\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0277 - val_loss: 0.0330\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0186 - val_loss: 0.0327\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.0211 - val_loss: 0.0325\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0204 - val_loss: 0.0322\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0193 - val_loss: 0.0323\n",
      "WARNING:tensorflow:10 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5a7b228b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_10 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 283ms/step - loss: 0.8966 - val_loss: 0.0471\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.5322 - val_loss: 0.0381\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.3450 - val_loss: 0.0376\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.2276 - val_loss: 0.0409\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5895bf550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_11 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.5348 - val_loss: 0.0383\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.3433 - val_loss: 0.0421\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb59b0cdee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_12 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 1.6413 - val_loss: 0.1034\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5624 - val_loss: 0.0435\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2788 - val_loss: 0.0568\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5a2849040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_13 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.8392WARNING:tensorflow:5 out of the last 24 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb5a4478040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.7178 - val_loss: 0.0333\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.3996 - val_loss: 0.0343\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb58b5af0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_14 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.8911WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb58b5351f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6527 - val_loss: 0.0475\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.2798 - val_loss: 0.0394\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1263 - val_loss: 0.0343\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0663 - val_loss: 0.0347\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb59cc9daf0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_15 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1347WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb58c2171f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.9897 - val_loss: 0.0447\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.3239 - val_loss: 0.0596\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb589cc99d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_16 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2604WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb5a2f8cf70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.2067 - val_loss: 0.0403\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1304 - val_loss: 0.0519\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5a2f8cd30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_17 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2525WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb5a4179160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.2052 - val_loss: 0.0322\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0640 - val_loss: 0.0343\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5a2849160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_18 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.3454WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb5a2813ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.3028 - val_loss: 0.0419\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0925 - val_loss: 0.0340\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1526 - val_loss: 0.0335\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0539 - val_loss: 0.0312\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0490 - val_loss: 0.0310\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0266 - val_loss: 0.0315\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb58c4d6310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_19 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 0.3269 - val_loss: 0.0351\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1464 - val_loss: 0.0408\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5a2849430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_20 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.5936 - val_loss: 0.0280\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4954 - val_loss: 0.0415\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb589ab9ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_21 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.7936 - val_loss: 0.0612\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6410 - val_loss: 0.0598\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2476 - val_loss: 0.0618\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb58bb5dee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_22 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.3795WARNING:tensorflow:5 out of the last 14 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb589ab9c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.3296 - val_loss: 0.0503\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1641 - val_loss: 0.0586\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5a2f8cd30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_23 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.8785WARNING:tensorflow:6 out of the last 16 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb5a2813700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.6340 - val_loss: 0.0936\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.2413 - val_loss: 0.0455\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0890 - val_loss: 0.0344\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0622 - val_loss: 0.0336\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0623 - val_loss: 0.0342\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5a2849310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_24 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.9503 - val_loss: 0.0391\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2348 - val_loss: 0.0354\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0864 - val_loss: 0.0353\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1743 - val_loss: 0.0364\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb58b77f550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_25 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 0.6645 - val_loss: 0.0471\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2757 - val_loss: 0.0372\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1476 - val_loss: 0.0411\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb588236c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_26 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.6254 - val_loss: 0.0357\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2172 - val_loss: 0.0409\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb58c4d6af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_27 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.7852WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb5a2d0c5e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 0.6391 - val_loss: 0.2014\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1570 - val_loss: 0.1452\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1370 - val_loss: 0.1062\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0735 - val_loss: 0.0645\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0610 - val_loss: 0.0419\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0543 - val_loss: 0.0410\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0284 - val_loss: 0.0458\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb58c2d14c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_28 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.2325 - val_loss: 0.0901\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.1964 - val_loss: 0.0917\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb58d594ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_29 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 0.9658 - val_loss: 0.0367\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5011 - val_loss: 0.0431\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5899e3ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_30 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 1.2499 - val_loss: 0.0352\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5068 - val_loss: 0.0514\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb58c2444c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_31 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.7491WARNING:tensorflow:5 out of the last 14 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb58e1c1b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 2.2567 - val_loss: 0.0323\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.9627 - val_loss: 0.0415\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb58bff5700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_32 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.7865WARNING:tensorflow:6 out of the last 16 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb58c244c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 1.6840 - val_loss: 0.0307\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.9808 - val_loss: 0.0310\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb589ab9940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_33 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.8260WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb589cc94c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 1.3675 - val_loss: 0.3617\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.3955 - val_loss: 0.2105\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.2430 - val_loss: 0.1567\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0923 - val_loss: 0.1262\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0462 - val_loss: 0.0939\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0333 - val_loss: 0.0657\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0241 - val_loss: 0.0469\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0257 - val_loss: 0.0399\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0255 - val_loss: 0.0391\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0241 - val_loss: 0.0393\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5a7aebca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_34 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.8591 - val_loss: 0.0345\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2561 - val_loss: 0.0316\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0808 - val_loss: 0.0309\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0760 - val_loss: 0.0303\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0516 - val_loss: 0.0303\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0470 - val_loss: 0.0314\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb58e3feb80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_35 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.5283 - val_loss: 0.1985\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2082 - val_loss: 0.2542\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb58bb5dee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_36 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.5569 - val_loss: 0.0903\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.2433 - val_loss: 0.0710\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0832 - val_loss: 0.0519\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0604 - val_loss: 0.0412\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0464 - val_loss: 0.0341\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0444 - val_loss: 0.0309\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0442 - val_loss: 0.0297\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0362 - val_loss: 0.0294\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0184 - val_loss: 0.0292\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0200 - val_loss: 0.0289\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0183 - val_loss: 0.0286\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0136 - val_loss: 0.0283\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0104 - val_loss: 0.0280\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0116 - val_loss: 0.0278\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0133 - val_loss: 0.0278\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb58c6d0820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_37 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 1.2456 - val_loss: 0.0321\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5250 - val_loss: 0.0328\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb58c4c53a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_38 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.8871 - val_loss: 1.1634\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4747 - val_loss: 0.8437\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2575 - val_loss: 0.5873\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1049 - val_loss: 0.4387\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0706 - val_loss: 0.3469\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0796 - val_loss: 0.2944\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0684 - val_loss: 0.2497\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0472 - val_loss: 0.2127\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0382 - val_loss: 0.1803\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0361 - val_loss: 0.1522\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0251 - val_loss: 0.1294\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0147 - val_loss: 0.1115\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0112 - val_loss: 0.0972\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0113 - val_loss: 0.0862\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0111 - val_loss: 0.0782\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0154 - val_loss: 0.0732\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0068 - val_loss: 0.0702\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0096 - val_loss: 0.0680\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0069 - val_loss: 0.0660\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0194 - val_loss: 0.0646\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0101 - val_loss: 0.0630\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0083 - val_loss: 0.0610\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0090 - val_loss: 0.0591\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0097 - val_loss: 0.0578\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0068 - val_loss: 0.0569\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0060 - val_loss: 0.0555\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0062 - val_loss: 0.0543\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0106 - val_loss: 0.0539\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0080 - val_loss: 0.0536\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0070 - val_loss: 0.0533\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0059 - val_loss: 0.0528\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0049 - val_loss: 0.0518\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0045 - val_loss: 0.0507\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0050 - val_loss: 0.0497\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0064 - val_loss: 0.0487\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0048 - val_loss: 0.0480\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0054 - val_loss: 0.0471\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0083 - val_loss: 0.0457\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0047 - val_loss: 0.0442\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0042 - val_loss: 0.0428\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0049 - val_loss: 0.0415\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0066 - val_loss: 0.0400\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.005 - 0s 12ms/step - loss: 0.0042 - val_loss: 0.0386\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0066 - val_loss: 0.0375\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0038 - val_loss: 0.0368\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0064 - val_loss: 0.0364\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0046 - val_loss: 0.0359\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0036 - val_loss: 0.0356\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0069 - val_loss: 0.0356\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0041 - val_loss: 0.0353\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0034 - val_loss: 0.0349\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0035 - val_loss: 0.0347\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0057 - val_loss: 0.0343\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0043 - val_loss: 0.0337\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0051 - val_loss: 0.0328\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0053 - val_loss: 0.0319\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0035 - val_loss: 0.0315\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0086 - val_loss: 0.0307\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0049 - val_loss: 0.0301\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0058 - val_loss: 0.0296\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5900c5160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_39 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 1.3485 - val_loss: 0.0746\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.3440 - val_loss: 0.0756\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb58c4c51f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_40 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 0.1757 - val_loss: 0.0334\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0941 - val_loss: 0.0338\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb58bb42ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_41 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.5328 - val_loss: 0.0370\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2694 - val_loss: 0.0335\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1181 - val_loss: 0.0339\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb58c296e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_42 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.8149WARNING:tensorflow:5 out of the last 68 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb5900c5160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 0.6401 - val_loss: 0.0381\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2384 - val_loss: 0.0423\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb58d08b790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_43 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.9998WARNING:tensorflow:6 out of the last 70 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb58b77f820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.8303 - val_loss: 0.0362\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.3663 - val_loss: 0.0363\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb58bb42790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_44 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.9048WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb5900a80d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 0.7439 - val_loss: 0.0289\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0993 - val_loss: 0.0373\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb58e9c0820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_45 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5215WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb58ee7b160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.4472 - val_loss: 0.0316\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1454 - val_loss: 0.0341\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb58ee7bd30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_46 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0854WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb58e9c0790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 0.7800 - val_loss: 0.0403\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2656 - val_loss: 0.0609\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5a7aebca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_47 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.4854WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb58b77f1f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 1.0303 - val_loss: 0.0415\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2372 - val_loss: 0.0357\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0759 - val_loss: 0.0346\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0746 - val_loss: 0.0340\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0702 - val_loss: 0.0336\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0613 - val_loss: 0.0344\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb589ab99d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_48 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 0.4559 - val_loss: 0.0349\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1579 - val_loss: 0.0324\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0953 - val_loss: 0.0318\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0792 - val_loss: 0.0317\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0641 - val_loss: 0.0327\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb58bb42ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_49 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.7561 - val_loss: 0.0380\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.2570 - val_loss: 0.0581\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5916d0ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_50 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 160ms/step - loss: 0.3045 - val_loss: 0.0307\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.0982 - val_loss: 0.0318\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5900c5280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_51 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5880WARNING:tensorflow:5 out of the last 16 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb58c296e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.4682 - val_loss: 0.3299\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.1095 - val_loss: 0.4101\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb58bff55e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_52 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5051WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb5916d0c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 0.3975 - val_loss: 0.0496\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1523 - val_loss: 0.0330\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1031 - val_loss: 0.0283\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0571 - val_loss: 0.0288\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb58ee7b160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_53 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.3031WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb591c5b0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 1.0628 - val_loss: 0.0395\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2661 - val_loss: 0.0484\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb591c5be50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_54 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.3421WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb58c6d04c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.3028 - val_loss: 0.0630\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1390 - val_loss: 0.0534\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1220 - val_loss: 0.0518\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0809 - val_loss: 0.0499\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0499 - val_loss: 0.0411\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0430 - val_loss: 0.0353\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0353 - val_loss: 0.0316\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0189 - val_loss: 0.0304\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0143 - val_loss: 0.0298\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0208 - val_loss: 0.0303\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb58b77fb80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_55 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 2.3914 - val_loss: 0.0323\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.8517 - val_loss: 0.0313\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.3921 - val_loss: 0.0304\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1826 - val_loss: 0.0314\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb58d653c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_56 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.6105 - val_loss: 0.0285\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2145 - val_loss: 0.0357\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb591cfa430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_57 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 241ms/step - loss: 1.6253 - val_loss: 0.1137\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6207 - val_loss: 0.1117\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2742 - val_loss: 0.1227\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5899e39d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_58 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.8571WARNING:tensorflow:5 out of the last 20 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb58bb424c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.6889 - val_loss: 0.0887\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1857 - val_loss: 0.0934\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb589ab9d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_59 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2735WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb58ec4fdc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 1.0288 - val_loss: 0.0723\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4155 - val_loss: 0.0391\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.2701 - val_loss: 0.0232\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1630 - val_loss: 0.0181\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0998 - val_loss: 0.0177\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0815 - val_loss: 0.0187\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb591398430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_60 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 1.4800 - val_loss: 0.0207\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.6506 - val_loss: 0.0275\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5925d5160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_61 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 1.3164 - val_loss: 0.0408\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6078 - val_loss: 0.0258\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2282 - val_loss: 0.0182\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1140 - val_loss: 0.0128\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0586 - val_loss: 0.0111\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0460 - val_loss: 0.0121\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb593452160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_62 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.4811 - val_loss: 0.0335\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2369 - val_loss: 0.0318\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.1875 - val_loss: 0.0351\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb591cfa940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_63 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.7432 - val_loss: 0.0556\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1910 - val_loss: 0.0413\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1504 - val_loss: 0.0344\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0964 - val_loss: 0.0313\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0627 - val_loss: 0.0270\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0420 - val_loss: 0.0229\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0446 - val_loss: 0.0207\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0476 - val_loss: 0.0211\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5913984c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_64 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.8501 - val_loss: 0.0455\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.2340 - val_loss: 0.0621\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb591c5bb80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_65 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.5426 - val_loss: 0.1192\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.1981 - val_loss: 0.1076\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0971 - val_loss: 0.1226\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb58ecd21f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_66 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.9226 - val_loss: 0.0195\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2078 - val_loss: 0.0170\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1455 - val_loss: 0.0195\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5913989d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_67 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4334WARNING:tensorflow:5 out of the last 17 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb5a2849820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.3731 - val_loss: 0.0497\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1218 - val_loss: 0.0327\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0547 - val_loss: 0.0240\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0500 - val_loss: 0.0213\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0416 - val_loss: 0.0200\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0275 - val_loss: 0.0193\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0244 - val_loss: 0.0187\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0230 - val_loss: 0.0180\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0174 - val_loss: 0.0175\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0138 - val_loss: 0.0169\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0121 - val_loss: 0.0164\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0126 - val_loss: 0.0162\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0152 - val_loss: 0.0167\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb58e7a7790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_68 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.9100 - val_loss: 0.0374\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.3655 - val_loss: 0.0123\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1563 - val_loss: 0.0177\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5a7aeb700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_69 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 0.6740 - val_loss: 0.0354\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3586 - val_loss: 0.0307\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.1640 - val_loss: 0.0276\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0695 - val_loss: 0.0237\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0569 - val_loss: 0.0199\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0479 - val_loss: 0.0174\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0547 - val_loss: 0.0159\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0423 - val_loss: 0.0154\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0320 - val_loss: 0.0155\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5930cf280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_70 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 1.1266 - val_loss: 0.0426\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.4944 - val_loss: 0.0238\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1989 - val_loss: 0.0219\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1250 - val_loss: 0.0439\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5925d5790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_71 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.9605 - val_loss: 0.0148\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2104 - val_loss: 0.0171\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb591d0c820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_72 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.9985 - val_loss: 0.0155\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.3282 - val_loss: 0.0136\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.1204 - val_loss: 0.0143\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb58e3dd790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_73 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4802WARNING:tensorflow:5 out of the last 19 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb5907ad280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.3256 - val_loss: 0.0123\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2369 - val_loss: 0.0140\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb594e03280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_74 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.0117WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb5a2f8c790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 1.7062 - val_loss: 0.8698\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7987 - val_loss: 0.7821\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.3422 - val_loss: 0.5987\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1426 - val_loss: 0.5054\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.1147 - val_loss: 0.4343\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1038 - val_loss: 0.4014\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0770 - val_loss: 0.3793\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0554 - val_loss: 0.3584\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0518 - val_loss: 0.3400\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0530 - val_loss: 0.3258\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0477 - val_loss: 0.3086\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0389 - val_loss: 0.2902\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0319 - val_loss: 0.2706\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0249 - val_loss: 0.2548\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0208 - val_loss: 0.2438\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0235 - val_loss: 0.2335\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0217 - val_loss: 0.2340\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5934ae790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_75 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 1.0034 - val_loss: 0.0239\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.3684 - val_loss: 0.0326\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb58bb428b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_76 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 1.1774 - val_loss: 0.0153\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.5232 - val_loss: 0.0105\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1740 - val_loss: 0.0149\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5a7aebb80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_77 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 1.0105 - val_loss: 0.0102\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.4579 - val_loss: 0.0112\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb591e9f160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_78 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2472WARNING:tensorflow:5 out of the last 25 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb5955be160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 1.0326 - val_loss: 0.3140\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3486 - val_loss: 0.1931\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.1664 - val_loss: 0.1090\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1105 - val_loss: 0.0592\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0760 - val_loss: 0.0323\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0806 - val_loss: 0.0211\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0738 - val_loss: 0.0169\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0454 - val_loss: 0.0154\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0382 - val_loss: 0.0154\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0303 - val_loss: 0.0159\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb59594b8b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_79 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 0.8530 - val_loss: 0.0133\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1611 - val_loss: 0.0184\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb59377b820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_80 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 0.6442 - val_loss: 0.0140\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.3614 - val_loss: 0.0230\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5a2849820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_81 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.5201 - val_loss: 0.0135\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2194 - val_loss: 0.0128\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0928 - val_loss: 0.0144\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb58bf8d940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_82 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5243WARNING:tensorflow:5 out of the last 18 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb59357f160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.7943 - val_loss: 0.0488\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4963 - val_loss: 0.0481\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1738 - val_loss: 0.0486\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb594e94f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_83 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.5101WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb59534e040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 1.3444 - val_loss: 0.0139\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4267 - val_loss: 0.0107\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1333 - val_loss: 0.0148\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb59534eee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_84 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.4189WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb5907ad1f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 1.0171 - val_loss: 0.1590\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.2303 - val_loss: 0.2437\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb58e9534c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_85 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.3538WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb5900c5f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 1.0613 - val_loss: 0.3608\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4151 - val_loss: 0.1712\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1749 - val_loss: 0.0740\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0874 - val_loss: 0.0349\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0694 - val_loss: 0.0231\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0658 - val_loss: 0.0152\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0442 - val_loss: 0.0119\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0458 - val_loss: 0.0117\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0365 - val_loss: 0.0120\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb58d4c4430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_86 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.3769 - val_loss: 0.0483\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2682 - val_loss: 0.0389\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1223 - val_loss: 0.0316\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0867 - val_loss: 0.0301\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.1101 - val_loss: 0.0285\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0870 - val_loss: 0.0261\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0883 - val_loss: 0.0222\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0580 - val_loss: 0.0245\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb59377b700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_87 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 0.7138 - val_loss: 0.0156\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.2699 - val_loss: 0.0144\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0948 - val_loss: 0.0145\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb59594b8b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_88 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.8053 - val_loss: 0.0174\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2527 - val_loss: 0.0154\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.1189 - val_loss: 0.0141\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0881 - val_loss: 0.0148\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5958cb550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_89 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 1.2155 - val_loss: 0.0162\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4431 - val_loss: 0.0211\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5a2f6d9d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_90 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.3039WARNING:tensorflow:5 out of the last 18 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb5a7aeb700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.2836 - val_loss: 0.0217\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.1315 - val_loss: 0.0231\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb58ee7b3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_91 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6235WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb58e953040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.5061 - val_loss: 0.0179\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1583 - val_loss: 0.0251\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb58e9534c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_92 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.8285WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb596933a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.7255 - val_loss: 0.0298\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2883 - val_loss: 0.0237\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.1947 - val_loss: 0.0234\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.1246 - val_loss: 0.0213\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.1206 - val_loss: 0.0173\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0574 - val_loss: 0.0156\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0537 - val_loss: 0.0168\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb594e94550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_93 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.1808 - val_loss: 0.1411\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0565 - val_loss: 0.1519\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5a2a02550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_94 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 0.6040 - val_loss: 0.0515\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2039 - val_loss: 0.0642\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb596933820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_95 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 0.3488 - val_loss: 0.0450\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1734 - val_loss: 0.0448\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.1012 - val_loss: 0.0438\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0498 - val_loss: 0.0425\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0453 - val_loss: 0.0408\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0342 - val_loss: 0.0394\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0282 - val_loss: 0.0381\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0262 - val_loss: 0.0364\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0248 - val_loss: 0.0344\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0145 - val_loss: 0.0320\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0145 - val_loss: 0.0311\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0140 - val_loss: 0.0312\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb591c5b160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_96 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 1.4493 - val_loss: 0.5712\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.7402 - val_loss: 0.2209\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4643 - val_loss: 0.0820\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1874 - val_loss: 0.0255\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.1330 - val_loss: 0.0154\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1158 - val_loss: 0.0160\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb58e3dd700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_97 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.2975 - val_loss: 0.0384\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1516 - val_loss: 0.0661\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb59550fb80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_98 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 251ms/step - loss: 0.3306 - val_loss: 0.0622\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.1338 - val_loss: 0.0623\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb57870b3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_99 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 278ms/step - loss: 0.5010 - val_loss: 0.0213\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.1082 - val_loss: 0.0257\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb59594b280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_100 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.9598WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb58e3dd700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 1s 465ms/step - loss: 2.9063 - val_loss: 0.0201\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 1.3570 - val_loss: 0.0165\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6889 - val_loss: 0.0177\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5930cfee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_101 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.7712WARNING:tensorflow:6 out of the last 16 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb58e953ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 241ms/step - loss: 0.6159 - val_loss: 0.0846\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.2815 - val_loss: 0.0411\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1559 - val_loss: 0.0223\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.1165 - val_loss: 0.0197\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1060 - val_loss: 0.0228\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5953e53a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_102 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 314ms/step - loss: 0.2748 - val_loss: 0.0220\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1806 - val_loss: 0.0236\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb57807cf70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_103 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 273ms/step - loss: 0.3688 - val_loss: 0.0253\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.1622 - val_loss: 0.0269\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb579fca040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_104 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0221WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb57a966dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 247ms/step - loss: 0.8037 - val_loss: 0.1051\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.3399 - val_loss: 0.0928\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.1478 - val_loss: 0.0821\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0876 - val_loss: 0.0754\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0729 - val_loss: 0.0657\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0508 - val_loss: 0.0558\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0421 - val_loss: 0.0477\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0410 - val_loss: 0.0419\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0409 - val_loss: 0.0384\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0365 - val_loss: 0.0366\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0315 - val_loss: 0.0367\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb57b17cc10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_105 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 195ms/step - loss: 0.4623 - val_loss: 0.0248\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.2017 - val_loss: 0.0254\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb591e9f310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_106 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 229ms/step - loss: 0.6015 - val_loss: 0.0333\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.3502 - val_loss: 0.0286\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.1967 - val_loss: 0.0265\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.1118 - val_loss: 0.0260\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0567 - val_loss: 0.0252\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0804 - val_loss: 0.0248\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0431 - val_loss: 0.0249\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb58c4d6b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_107 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 289ms/step - loss: 0.3577 - val_loss: 0.0649\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.2227 - val_loss: 0.0379\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0702 - val_loss: 0.0310\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0504 - val_loss: 0.0276\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0529 - val_loss: 0.0292\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5958cbca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_108 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 268ms/step - loss: 0.2251 - val_loss: 0.0247\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1241 - val_loss: 0.0244\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.1022 - val_loss: 0.0241\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0542 - val_loss: 0.0241\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0306 - val_loss: 0.0242\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb58b5354c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_109 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 241ms/step - loss: 0.6482 - val_loss: 0.0682\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.4275 - val_loss: 0.0406\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.2201 - val_loss: 0.0299\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.1354 - val_loss: 0.0272\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0966 - val_loss: 0.0263\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0679 - val_loss: 0.0255\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0834 - val_loss: 0.0257\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5924c1310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_110 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 233ms/step - loss: 0.4211 - val_loss: 0.0283\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1461 - val_loss: 0.0293\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb58c4d6430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_111 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 582ms/step - loss: 1.1972 - val_loss: 0.0395\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5585 - val_loss: 0.0341\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 0.2552 - val_loss: 0.0304\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.3799 - val_loss: 0.0282\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.2393 - val_loss: 0.0268\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.1581 - val_loss: 0.0273\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb589ab9670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_112 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 194ms/step - loss: 0.6229 - val_loss: 0.0277\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2868 - val_loss: 0.0251\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.1292 - val_loss: 0.0239\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0591 - val_loss: 0.0231\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0309 - val_loss: 0.0222\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0366 - val_loss: 0.0220\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0483 - val_loss: 0.0221\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb58e953ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_113 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.8687 - val_loss: 0.0504\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.6034 - val_loss: 0.0401\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.2826 - val_loss: 0.0337\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.1346 - val_loss: 0.0293\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0747 - val_loss: 0.0274\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0800 - val_loss: 0.0261\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0544 - val_loss: 0.0255\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0449 - val_loss: 0.0255\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0522 - val_loss: 0.0258\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb57b17cf70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_114 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 1.6530 - val_loss: 0.0962\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.8747 - val_loss: 0.0798\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.4554 - val_loss: 0.0562\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.1672 - val_loss: 0.0418\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0560 - val_loss: 0.0332\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0345 - val_loss: 0.0294\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0392 - val_loss: 0.0277\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0418 - val_loss: 0.0314\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb57ab4c040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_115 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.4498 - val_loss: 0.1657\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1313 - val_loss: 0.1279\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.1135 - val_loss: 0.1278\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0581 - val_loss: 0.1383\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb57c9293a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_116 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 230ms/step - loss: 1.0457 - val_loss: 0.6939\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.3977 - val_loss: 0.5964\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1383 - val_loss: 0.4997\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1447 - val_loss: 0.4104\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1049 - val_loss: 0.3286\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0649 - val_loss: 0.2669\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0367 - val_loss: 0.2259\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0323 - val_loss: 0.1929\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0229 - val_loss: 0.1650\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0191 - val_loss: 0.1384\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0188 - val_loss: 0.1124\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0198 - val_loss: 0.0894\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0176 - val_loss: 0.0714\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0171 - val_loss: 0.0588\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0152 - val_loss: 0.0497\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0121 - val_loss: 0.0447\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0124 - val_loss: 0.0434\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0089 - val_loss: 0.0439\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb58bf8d1f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_117 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.9512 - val_loss: 0.0515\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.6413 - val_loss: 0.0348\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2476 - val_loss: 0.0317\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.1364 - val_loss: 0.0304\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1099 - val_loss: 0.0300\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1192 - val_loss: 0.0304\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5a1ed3700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_118 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 1.4117 - val_loss: 0.0317\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5919 - val_loss: 0.0464\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb595ca0280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_119 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 0.2939 - val_loss: 0.0536\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.1105 - val_loss: 0.0461\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0537 - val_loss: 0.0423\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0511 - val_loss: 0.0408\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0363 - val_loss: 0.0419\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb59594b700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_120 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 1.0223 - val_loss: 0.1659\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4828 - val_loss: 0.1973\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5783104c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_121 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5694WARNING:tensorflow:5 out of the last 16 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb57ca03ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 1s 496ms/step - loss: 0.5440 - val_loss: 0.3331\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.2955 - val_loss: 0.1509\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1463 - val_loss: 0.0709\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1160 - val_loss: 0.0496\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1423 - val_loss: 0.0371\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0836 - val_loss: 0.0304\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0692 - val_loss: 0.0287\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0644 - val_loss: 0.0272\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0331 - val_loss: 0.0259\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0240 - val_loss: 0.0273\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb594202dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_122 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 0.9167 - val_loss: 0.0864\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.2625 - val_loss: 0.0540\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.1106 - val_loss: 0.0292\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0646 - val_loss: 0.0227\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0721 - val_loss: 0.0235\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5919f5550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_123 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.5923 - val_loss: 0.0390\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2952 - val_loss: 0.0502\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb594fcf700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_124 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.8227 - val_loss: 0.0317\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2162 - val_loss: 0.0331\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb57d0360d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_125 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.3807WARNING:tensorflow:5 out of the last 20 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb57d5c7ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6784 - val_loss: 0.0495\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4416 - val_loss: 0.0384\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.1878 - val_loss: 0.0332\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1622 - val_loss: 0.0306\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0977 - val_loss: 0.0299\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0696 - val_loss: 0.0299\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb57b2790d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_126 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 0.6444 - val_loss: 0.0364\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.2475 - val_loss: 0.0278\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1061 - val_loss: 0.0277\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0891 - val_loss: 0.0307\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb57dad70d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_127 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 1.1519 - val_loss: 0.0604\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5955 - val_loss: 0.0671\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5808903a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_128 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 1.0579 - val_loss: 0.0557\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4147 - val_loss: 0.0816\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb57bd9e430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_129 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2718WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb57b26d700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 0.9038 - val_loss: 0.1972\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.3217 - val_loss: 0.0868\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.1712 - val_loss: 0.0350\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1247 - val_loss: 0.0317\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0878 - val_loss: 0.0553\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5919cda60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_130 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.5140WARNING:tensorflow:5 out of the last 14 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb594e03550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 1.2587 - val_loss: 0.0452\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5974 - val_loss: 0.0694\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5907ad3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_131 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0761WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb59377b940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 1.0432 - val_loss: 0.0259\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4756 - val_loss: 0.0243\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.2064 - val_loss: 0.0288\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb59594b4c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_132 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.3003 - val_loss: 0.2059\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.1555 - val_loss: 0.2486\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb579d99dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_133 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1248WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb58108bca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 0.9505 - val_loss: 0.0441\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.4176 - val_loss: 0.0395\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1272 - val_loss: 0.0384\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0699 - val_loss: 0.0370\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0505 - val_loss: 0.0336\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0510 - val_loss: 0.0310\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0494 - val_loss: 0.0296\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0400 - val_loss: 0.0290\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0390 - val_loss: 0.0288\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0282 - val_loss: 0.0286\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0224 - val_loss: 0.0283\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0202 - val_loss: 0.0280\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0166 - val_loss: 0.0275\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0154 - val_loss: 0.0271\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0102 - val_loss: 0.0266\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0096 - val_loss: 0.0263\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0089 - val_loss: 0.0260\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0088 - val_loss: 0.0258\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0083 - val_loss: 0.0256\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0103 - val_loss: 0.0254\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0102 - val_loss: 0.0253\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0120 - val_loss: 0.0252\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0096 - val_loss: 0.0251\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0100 - val_loss: 0.0250\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0095 - val_loss: 0.0249\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0086 - val_loss: 0.0248\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0066 - val_loss: 0.0247\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0094 - val_loss: 0.0245\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0098 - val_loss: 0.0245\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0085 - val_loss: 0.0246\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb57b62baf0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_134 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 165ms/step - loss: 1.2155 - val_loss: 0.0335\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4421 - val_loss: 0.0472\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5930cf280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_135 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 122ms/step - loss: 0.4022 - val_loss: 0.0232\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.3064 - val_loss: 0.0227\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1197 - val_loss: 0.0245\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb57bd55ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_136 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 217ms/step - loss: 0.4587 - val_loss: 0.0325\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.1903 - val_loss: 0.0308\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1494 - val_loss: 0.0299\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.1024 - val_loss: 0.0305\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5a1ed30d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_137 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.3903WARNING:tensorflow:5 out of the last 40 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb57abc7940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 0.3583 - val_loss: 0.0391\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1438 - val_loss: 0.0340\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0607 - val_loss: 0.0297\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0364 - val_loss: 0.0268\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0223 - val_loss: 0.0259\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0252 - val_loss: 0.0259\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0220 - val_loss: 0.0258\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0190 - val_loss: 0.0255\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 0.0167 - val_loss: 0.0258\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb57b279160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_138 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 353ms/step - loss: 0.6751 - val_loss: 0.0488\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.1659 - val_loss: 0.0316\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0963 - val_loss: 0.0259\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.0730 - val_loss: 0.0257\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0433 - val_loss: 0.0257\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb580890f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_139 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 0.5767 - val_loss: 0.0790\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.2463 - val_loss: 0.0701\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1400 - val_loss: 0.0598\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1142 - val_loss: 0.0584\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0738 - val_loss: 0.0552\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0552 - val_loss: 0.0538\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0651 - val_loss: 0.0541\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb57ddd23a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_140 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 0.6961 - val_loss: 0.1391\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1974 - val_loss: 0.1282\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0709 - val_loss: 0.0976\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0690 - val_loss: 0.0774\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0672 - val_loss: 0.0676\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0589 - val_loss: 0.0592\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0433 - val_loss: 0.0547\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0393 - val_loss: 0.0534\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.0283 - val_loss: 0.0543\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb581b0ae50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_141 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 1.0724 - val_loss: 0.3086\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.6198 - val_loss: 0.3632\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb57eae49d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_142 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.2649 - val_loss: 0.0260\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0839 - val_loss: 0.0277\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb58e7a7700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_143 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.4643 - val_loss: 0.0888\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1346 - val_loss: 0.1144\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5955bed30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_144 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5435WARNING:tensorflow:5 out of the last 16 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb5957274c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.4931 - val_loss: 0.0378\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.2090 - val_loss: 0.0303\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0656 - val_loss: 0.0290\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0590 - val_loss: 0.0309\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb594fa5940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_145 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2977WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb57aeacf70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 1.1756 - val_loss: 0.0485\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.5559 - val_loss: 0.0602\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb58108be50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_146 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4808WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb581b91700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 0.5099 - val_loss: 0.0521\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.3885 - val_loss: 0.0561\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb57ca9f0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_147 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5613WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb594e03550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 210ms/step - loss: 0.5117 - val_loss: 0.1813\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2166 - val_loss: 0.1326\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1420 - val_loss: 0.0940\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1203 - val_loss: 0.0706\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0550 - val_loss: 0.0533\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0401 - val_loss: 0.0425\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0421 - val_loss: 0.0372\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0438 - val_loss: 0.0359\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0336 - val_loss: 0.0353\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0251 - val_loss: 0.0366\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb57807c310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_148 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 0.8205 - val_loss: 0.0376\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.3333 - val_loss: 0.0656\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb595ca0c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_149 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 158ms/step - loss: 0.5425 - val_loss: 0.0934\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.2656 - val_loss: 0.0768\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1832 - val_loss: 0.0606\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0991 - val_loss: 0.0408\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0757 - val_loss: 0.0337\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0754 - val_loss: 0.0317\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0463 - val_loss: 0.0332\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb58e9533a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_150 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 122ms/step - loss: 0.8373 - val_loss: 0.1941\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.2196 - val_loss: 0.1558\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0795 - val_loss: 0.1135\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0713 - val_loss: 0.0781\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0754 - val_loss: 0.0563\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0612 - val_loss: 0.0436\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0378 - val_loss: 0.0371\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0252 - val_loss: 0.0357\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0225 - val_loss: 0.0359\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb580890310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_151 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.6046 - val_loss: 0.0168\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.3408 - val_loss: 0.0194\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5812ab0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_152 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 0.8191 - val_loss: 0.0659\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.3435 - val_loss: 0.0832\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5814f5160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_153 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.9128 - val_loss: 0.3456\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3679 - val_loss: 0.3329\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1319 - val_loss: 0.2774\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0812 - val_loss: 0.1919\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0636 - val_loss: 0.1236\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.0647 - val_loss: 0.0835\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0487 - val_loss: 0.0628\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0591 - val_loss: 0.0448\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0243 - val_loss: 0.0330\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0202 - val_loss: 0.0254\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0274 - val_loss: 0.0186\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0260 - val_loss: 0.0158\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0283 - val_loss: 0.0159\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5825abaf0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_154 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 307ms/step - loss: 0.2834 - val_loss: 0.0252\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.0951 - val_loss: 0.0300\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb57807c1f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_155 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 270ms/step - loss: 1.0361 - val_loss: 0.0923\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.3574 - val_loss: 0.0838\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.1900 - val_loss: 0.0787\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.1310 - val_loss: 0.0805\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb59594bb80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_156 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 372ms/step - loss: 0.4574 - val_loss: 0.1094\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1561 - val_loss: 0.1029\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.1493 - val_loss: 0.0908\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0958 - val_loss: 0.0885\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0688 - val_loss: 0.0786\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0532 - val_loss: 0.0680\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0607 - val_loss: 0.0649\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0521 - val_loss: 0.0656\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb581050310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_157 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 269ms/step - loss: 1.2007 - val_loss: 0.2291\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5026 - val_loss: 0.1167\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.2169 - val_loss: 0.0542\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0919 - val_loss: 0.0284\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0832 - val_loss: 0.0199\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0757 - val_loss: 0.0181\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0820 - val_loss: 0.0179\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0872 - val_loss: 0.0180\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb57cacc940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_158 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 373ms/step - loss: 0.4975 - val_loss: 0.0999\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.3211 - val_loss: 0.0626\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.1931 - val_loss: 0.0467\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1079 - val_loss: 0.0445\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0804 - val_loss: 0.0479\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb581b91d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_159 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 1.0039 - val_loss: 0.0374\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4209 - val_loss: 0.0653\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb57cc4aaf0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_160 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 0.5740 - val_loss: 0.0770\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2237 - val_loss: 0.1106\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb584912ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_161 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0435WARNING:tensorflow:5 out of the last 18 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb591997040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 1s 320ms/step - loss: 0.8187 - val_loss: 0.0586\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2381 - val_loss: 0.0415\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1540 - val_loss: 0.0299\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1342 - val_loss: 0.0214\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0862 - val_loss: 0.0189\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0877 - val_loss: 0.0176\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0518 - val_loss: 0.0170\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0442 - val_loss: 0.0187\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5907addc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_162 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.4533 - val_loss: 0.0792\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1560 - val_loss: 0.0651\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1264 - val_loss: 0.0509\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0773 - val_loss: 0.0393\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0736 - val_loss: 0.0322\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0582 - val_loss: 0.0281\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0385 - val_loss: 0.0264\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0284 - val_loss: 0.0255\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0233 - val_loss: 0.0248\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0215 - val_loss: 0.0237\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0176 - val_loss: 0.0231\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0208 - val_loss: 0.0229\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0214 - val_loss: 0.0238\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5812aba60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_163 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.6609 - val_loss: 0.0601\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2408 - val_loss: 0.0484\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0957 - val_loss: 0.0492\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb57bd9e550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_164 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.7461 - val_loss: 0.0181\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.3484 - val_loss: 0.0234\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb580890d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_165 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 183ms/step - loss: 0.7889 - val_loss: 0.0350\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1807 - val_loss: 0.0286\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1324 - val_loss: 0.0249\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0796 - val_loss: 0.0230\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0554 - val_loss: 0.0222\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0355 - val_loss: 0.0223\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb57b26d430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_166 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 175ms/step - loss: 0.4766 - val_loss: 0.0724\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.2489 - val_loss: 0.0580\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.1259 - val_loss: 0.0405\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0669 - val_loss: 0.0321\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0703 - val_loss: 0.0312\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0562 - val_loss: 0.0341\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5851e65e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_167 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 176ms/step - loss: 0.5800 - val_loss: 0.0515\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2680 - val_loss: 0.0676\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5846b63a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_168 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 166ms/step - loss: 0.7879 - val_loss: 0.0382\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2516 - val_loss: 0.0304\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1403 - val_loss: 0.0254\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1311 - val_loss: 0.0251\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1240 - val_loss: 0.0288\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb59300cca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_169 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 1.1473 - val_loss: 0.2031\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.3281 - val_loss: 0.1890\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.2323 - val_loss: 0.1309\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1361 - val_loss: 0.0921\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1064 - val_loss: 0.0735\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0848 - val_loss: 0.0706\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0488 - val_loss: 0.0752\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb58e953700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_170 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 185ms/step - loss: 0.9539 - val_loss: 0.0495\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4038 - val_loss: 0.0651\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb57b279040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_171 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.9324 - val_loss: 0.0419\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.2566 - val_loss: 0.0608\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb57aeacc10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_172 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.7782 - val_loss: 0.0942\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2570 - val_loss: 0.0803\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1317 - val_loss: 0.0635\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1146 - val_loss: 0.0493\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0962 - val_loss: 0.0451\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0851 - val_loss: 0.0506\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb594fa5550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_173 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 326ms/step - loss: 0.7113 - val_loss: 0.0533\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.2384 - val_loss: 0.0540\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5808eba60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_174 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 252ms/step - loss: 0.5929 - val_loss: 0.0761\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.3059 - val_loss: 0.0683\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.1614 - val_loss: 0.0671\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0690 - val_loss: 0.0702\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb58486e790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_175 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.6469 - val_loss: 0.0477\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.3039 - val_loss: 0.0333\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.1091 - val_loss: 0.0263\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0612 - val_loss: 0.0219\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0928 - val_loss: 0.0221\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5848a0040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_176 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.5681 - val_loss: 0.0966\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.2499 - val_loss: 0.1066\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb57b279280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_177 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 256ms/step - loss: 0.9696 - val_loss: 0.0870\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.3844 - val_loss: 0.0560\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1959 - val_loss: 0.0436\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0714 - val_loss: 0.0417\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0557 - val_loss: 0.0400\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0630 - val_loss: 0.0377\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0661 - val_loss: 0.0367\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.0530 - val_loss: 0.0375\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb57ccd59d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_178 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 207ms/step - loss: 1.3688 - val_loss: 0.0455\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4100 - val_loss: 0.0345\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.1613 - val_loss: 0.0267\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1086 - val_loss: 0.0231\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0817 - val_loss: 0.0207\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0550 - val_loss: 0.0198\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0470 - val_loss: 0.0193\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0437 - val_loss: 0.0189\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0369 - val_loss: 0.0184\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0306 - val_loss: 0.0179\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0217 - val_loss: 0.0177\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0164 - val_loss: 0.0174\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0143 - val_loss: 0.0172\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0162 - val_loss: 0.0169\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0156 - val_loss: 0.0166\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0143 - val_loss: 0.0168\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb57b658430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_179 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 448ms/step - loss: 0.3988 - val_loss: 0.0571\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.1568 - val_loss: 0.0485\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0899 - val_loss: 0.0489\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb57ee7e670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_180 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 339ms/step - loss: 0.8952 - val_loss: 0.0167\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.5121 - val_loss: 0.0320\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb58136bf70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_181 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.8728 - val_loss: 0.0207\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4453 - val_loss: 0.0242\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb583420ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_182 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0551WARNING:tensorflow:5 out of the last 24 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb585f1e040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 122ms/step - loss: 0.8038 - val_loss: 0.0240\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2755 - val_loss: 0.0179\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1293 - val_loss: 0.0384\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb585d4a670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_183 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4979WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb56a4bf280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 0.3814 - val_loss: 0.0423\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0762 - val_loss: 0.0369\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0630 - val_loss: 0.0321\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0464 - val_loss: 0.0293\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0456 - val_loss: 0.0300\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb56ab360d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_184 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 0.8814 - val_loss: 0.0963\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4285 - val_loss: 0.0668\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2257 - val_loss: 0.0512\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1184 - val_loss: 0.0421\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0962 - val_loss: 0.0366\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0741 - val_loss: 0.0347\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0511 - val_loss: 0.0344\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0404 - val_loss: 0.0349\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb585d4af70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_185 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.5713 - val_loss: 0.0566\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1338 - val_loss: 0.0777\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb581d14040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_186 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.9196 - val_loss: 0.0518\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4154 - val_loss: 0.0542\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb594f27a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_187 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.5242 - val_loss: 0.0492\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2114 - val_loss: 0.0461\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1665 - val_loss: 0.0520\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb57d05c1f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_188 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.9053WARNING:tensorflow:5 out of the last 16 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb58533a670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.6984 - val_loss: 0.1927\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1894 - val_loss: 0.1694\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1259 - val_loss: 0.1395\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.1064 - val_loss: 0.1139\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0791 - val_loss: 0.0978\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0689 - val_loss: 0.0858\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0560 - val_loss: 0.0756\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0327 - val_loss: 0.0691\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0197 - val_loss: 0.0683\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0277 - val_loss: 0.0685\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb58533ad30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_189 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 1.3440 - val_loss: 0.0573\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6882 - val_loss: 0.0340\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4362 - val_loss: 0.0261\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1268 - val_loss: 0.0207\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0877 - val_loss: 0.0185\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0832 - val_loss: 0.0178\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0942 - val_loss: 0.0178\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb586f06160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_190 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.4332 - val_loss: 0.0435\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1062 - val_loss: 0.0253\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0591 - val_loss: 0.0186\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0579 - val_loss: 0.0180\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0519 - val_loss: 0.0182\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb58251e670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_191 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 1.8094 - val_loss: 0.0666\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6786 - val_loss: 0.0310\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3747 - val_loss: 0.0214\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1831 - val_loss: 0.0199\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1454 - val_loss: 0.0215\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb56b4c40d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_192 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 0.2022 - val_loss: 0.0421\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0735 - val_loss: 0.0362\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0417 - val_loss: 0.0336\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0333 - val_loss: 0.0337\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5863d9790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_193 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 0.9241 - val_loss: 0.0468\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.3710 - val_loss: 0.0627\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb57cc4a3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_194 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6096 - val_loss: 0.2229\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1580 - val_loss: 0.2426\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5812ab9d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_195 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2720WARNING:tensorflow:5 out of the last 14 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb57ddd2700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.2384 - val_loss: 0.0185\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1292 - val_loss: 0.0185\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb596933ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_196 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6495WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb5818d41f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.5437 - val_loss: 0.0881\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.1868 - val_loss: 0.0878\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0896 - val_loss: 0.0810\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0596 - val_loss: 0.0636\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0369 - val_loss: 0.0474\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0394 - val_loss: 0.0389\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0287 - val_loss: 0.0342\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0303 - val_loss: 0.0307\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0254 - val_loss: 0.0291\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0222 - val_loss: 0.0274\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0176 - val_loss: 0.0252\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0152 - val_loss: 0.0233\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0187 - val_loss: 0.0217\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0106 - val_loss: 0.0201\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0100 - val_loss: 0.0191\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0083 - val_loss: 0.0188\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0140 - val_loss: 0.0187\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0094 - val_loss: 0.0189\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb585f1eca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_197 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 1.6690 - val_loss: 0.0322\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5493 - val_loss: 0.0190\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1916 - val_loss: 0.0289\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb58e7a7700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_198 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 1.5136 - val_loss: 0.0398\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.5543 - val_loss: 0.0194\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2921 - val_loss: 0.0185\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1723 - val_loss: 0.0189\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb585d80670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_199 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6139 - val_loss: 0.0480\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2528 - val_loss: 0.0359\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1203 - val_loss: 0.0301\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0550 - val_loss: 0.0276\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0377 - val_loss: 0.0268\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0364 - val_loss: 0.0272\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb56be7b940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_200 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.9257 - val_loss: 0.0255\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.3422 - val_loss: 0.0302\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5799d2dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_201 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.2048 - val_loss: 0.0413\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1203 - val_loss: 0.0410\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0637 - val_loss: 0.0313\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0627 - val_loss: 0.0262\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0389 - val_loss: 0.0253\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0264 - val_loss: 0.0267\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb56ab36a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_202 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 0.4759 - val_loss: 0.0297\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1597 - val_loss: 0.0391\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb585f1eca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_203 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.8468WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0038s vs `on_train_batch_end` time: 0.0107s). Check your callbacks.\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 0.7155 - val_loss: 0.0249\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2839 - val_loss: 0.0208\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1266 - val_loss: 0.0184\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0577 - val_loss: 0.0173\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0404 - val_loss: 0.0169\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0321 - val_loss: 0.0169\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0438 - val_loss: 0.0169\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb58015d5e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_204 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 1.0082 - val_loss: 0.0712\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2218 - val_loss: 0.0212\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1231 - val_loss: 0.0189\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1130 - val_loss: 0.0255\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb58533a5e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_205 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.9617 - val_loss: 0.0706\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3038 - val_loss: 0.1244\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5843148b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_206 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6827 - val_loss: 0.0258\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.2140 - val_loss: 0.0203\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1437 - val_loss: 0.0175\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1129 - val_loss: 0.0168\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0568 - val_loss: 0.0175\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb568dae790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_207 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 2.1350 - val_loss: 0.1461\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8674 - val_loss: 0.1063\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3375 - val_loss: 0.0727\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1493 - val_loss: 0.0503\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0788 - val_loss: 0.0389\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0677 - val_loss: 0.0311\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0581 - val_loss: 0.0272\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0580 - val_loss: 0.0276\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb56d11e310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_208 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 545ms/step - loss: 1.0560 - val_loss: 0.0159\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6013 - val_loss: 0.0245\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb57d05c790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_209 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.4314 - val_loss: 0.0851\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1533 - val_loss: 0.0631\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0714 - val_loss: 0.0574\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0605 - val_loss: 0.0582\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb58251e430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_210 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.7027 - val_loss: 0.0341\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.2929 - val_loss: 0.0446\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb58533a9d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_211 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4516WARNING:tensorflow:5 out of the last 17 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb58015dc10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.3577 - val_loss: 0.0485\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1578 - val_loss: 0.0278\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1546 - val_loss: 0.0218\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1225 - val_loss: 0.0189\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0875 - val_loss: 0.0184\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0881 - val_loss: 0.0180\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0549 - val_loss: 0.0172\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0401 - val_loss: 0.0167\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0244 - val_loss: 0.0168\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5825e2160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_212 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 1.0238 - val_loss: 0.0498\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4194 - val_loss: 0.0514\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb57eeb6280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_213 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.5447 - val_loss: 0.0163\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.2171 - val_loss: 0.0146\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1161 - val_loss: 0.0164\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb57b658700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_214 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.3716 - val_loss: 0.0226\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2606 - val_loss: 0.0286\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb581d6a280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_215 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.7710WARNING:tensorflow:5 out of the last 17 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb56c84f820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.5462 - val_loss: 0.0188\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1904 - val_loss: 0.0166\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0915 - val_loss: 0.0150\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0901 - val_loss: 0.0141\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0509 - val_loss: 0.0149\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb56c8131f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_216 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.6093 - val_loss: 0.0327\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.1547 - val_loss: 0.0394\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb56f4a4c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_217 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.3384WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb56c8139d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 1.0822 - val_loss: 0.0160\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3218 - val_loss: 0.0129\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1192 - val_loss: 0.0129\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb57b658790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_218 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.4505 - val_loss: 0.0642\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1691 - val_loss: 0.0630\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0617 - val_loss: 0.0582\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0485 - val_loss: 0.0527\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0388 - val_loss: 0.0474\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0272 - val_loss: 0.0432\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0269 - val_loss: 0.0404\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0294 - val_loss: 0.0377\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0203 - val_loss: 0.0351\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0126 - val_loss: 0.0329\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0140 - val_loss: 0.0307\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0152 - val_loss: 0.0284\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0162 - val_loss: 0.0261\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0109 - val_loss: 0.0241\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0124 - val_loss: 0.0225\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0114 - val_loss: 0.0211\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0101 - val_loss: 0.0201\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0082 - val_loss: 0.0191\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0078 - val_loss: 0.0184\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0068 - val_loss: 0.0180\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0112 - val_loss: 0.0176\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0052 - val_loss: 0.0179\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb568d1aa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_219 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.5645 - val_loss: 0.0575\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1919 - val_loss: 0.0879\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb594f27a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_220 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 1.0372 - val_loss: 0.0180\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4080 - val_loss: 0.0156\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3271 - val_loss: 0.0129\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1342 - val_loss: 0.0121\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1414 - val_loss: 0.0147\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5857baa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_221 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 1.0403 - val_loss: 0.0374\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5195 - val_loss: 0.0144\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3050 - val_loss: 0.0118\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.3163 - val_loss: 0.0121\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb585140430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_222 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.7698 - val_loss: 0.0286\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1734 - val_loss: 0.0335\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb586732a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_223 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.7103 - val_loss: 0.2165\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2949 - val_loss: 0.1401\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1119 - val_loss: 0.1013\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0833 - val_loss: 0.0758\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0641 - val_loss: 0.0448\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0661 - val_loss: 0.0363\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0314 - val_loss: 0.0354\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0346 - val_loss: 0.0378\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb56b411ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_224 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 0.3033 - val_loss: 0.0336\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1350 - val_loss: 0.0351\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb56bc7cee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_225 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.7285 - val_loss: 0.0112\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1852 - val_loss: 0.0139\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb56dd8f820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_226 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 0.8662 - val_loss: 0.0143\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5853 - val_loss: 0.0096\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.2171 - val_loss: 0.0140\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb585140670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_227 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4500WARNING:tensorflow:5 out of the last 16 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb56c9988b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.4456 - val_loss: 0.0374\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2929 - val_loss: 0.0120\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1237 - val_loss: 0.0078\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0807 - val_loss: 0.0080\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb56d5dcb80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_228 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.3837WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb586732e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.3268 - val_loss: 0.1178\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1415 - val_loss: 0.0576\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1113 - val_loss: 0.0387\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0774 - val_loss: 0.0323\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0576 - val_loss: 0.0307\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0427 - val_loss: 0.0305\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0293 - val_loss: 0.0306\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb57c9e0c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_229 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.6525 - val_loss: 0.0436\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3436 - val_loss: 0.0302\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1542 - val_loss: 0.0240\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1058 - val_loss: 0.0200\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0717 - val_loss: 0.0178\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0571 - val_loss: 0.0161\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0327 - val_loss: 0.0149\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0343 - val_loss: 0.0147\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0313 - val_loss: 0.0150\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb581806820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_230 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.6589 - val_loss: 0.3036\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1924 - val_loss: 0.2907\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1145 - val_loss: 0.2987\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb56a4bfe50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_231 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.7001 - val_loss: 0.0110\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3942 - val_loss: 0.0088\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1077 - val_loss: 0.0083\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0557 - val_loss: 0.0080\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0755 - val_loss: 0.0080\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0720 - val_loss: 0.0083\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb581d6ad30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_232 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 0.5943 - val_loss: 0.0220\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1831 - val_loss: 0.0176\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0806 - val_loss: 0.0149\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0761 - val_loss: 0.0155\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5702e1ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_233 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 1.4677 - val_loss: 0.2911\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4792 - val_loss: 0.2214\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1586 - val_loss: 0.1621\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0790 - val_loss: 0.1127\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0670 - val_loss: 0.0741\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0320 - val_loss: 0.0523\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0326 - val_loss: 0.0401\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0262 - val_loss: 0.0311\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0272 - val_loss: 0.0239\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0226 - val_loss: 0.0175\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0240 - val_loss: 0.0130\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0272 - val_loss: 0.0109\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0133 - val_loss: 0.0096\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0138 - val_loss: 0.0089\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0100 - val_loss: 0.0087\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0092 - val_loss: 0.0087\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0094 - val_loss: 0.0087\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb570502af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_234 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.9499 - val_loss: 0.0346\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3352 - val_loss: 0.0465\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5720b5430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_235 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 1s 600ms/step - loss: 0.7538 - val_loss: 0.0368\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2286 - val_loss: 0.0190\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0940 - val_loss: 0.0129\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0524 - val_loss: 0.0093\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0843 - val_loss: 0.0081\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0658 - val_loss: 0.0086\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb57d05c1f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_236 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.8953 - val_loss: 0.0179\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2958 - val_loss: 0.0208\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5702e1f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_237 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 0.9965 - val_loss: 0.0199\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.5440 - val_loss: 0.0083\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2478 - val_loss: 0.0070\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2797 - val_loss: 0.0101\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb58e953e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_238 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.5809 - val_loss: 0.0152\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.2534 - val_loss: 0.0217\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb57ee7e430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_239 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4015WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb581214f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.3162 - val_loss: 0.0072\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1400 - val_loss: 0.0084\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb58251ec10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_240 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.7940WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb56d5dc4c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.8054 - val_loss: 0.0516\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.3771 - val_loss: 0.0290\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1647 - val_loss: 0.0168\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1007 - val_loss: 0.0108\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0491 - val_loss: 0.0083\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0535 - val_loss: 0.0071\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0379 - val_loss: 0.0065\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0350 - val_loss: 0.0064\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0205 - val_loss: 0.0065\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb56c998430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_241 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6605 - val_loss: 0.0100\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3357 - val_loss: 0.0110\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb56b326670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_242 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 1.1243 - val_loss: 0.0638\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.6246 - val_loss: 0.0253\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2502 - val_loss: 0.0156\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1654 - val_loss: 0.0089\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1199 - val_loss: 0.0067\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0897 - val_loss: 0.0057\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0719 - val_loss: 0.0051\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0748 - val_loss: 0.0056\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb56c624700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_243 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 1.3585 - val_loss: 0.0220\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6250 - val_loss: 0.0296\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb571e94040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_244 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.3684 - val_loss: 0.0263\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1390 - val_loss: 0.0254\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0986 - val_loss: 0.0260\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb575b814c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_245 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.3723 - val_loss: 0.0330\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.1144 - val_loss: 0.0337\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb58e953790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_246 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2578WARNING:tensorflow:5 out of the last 16 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb56c624ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 1.0047 - val_loss: 0.0114\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.2217 - val_loss: 0.0266\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb56b3261f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_247 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1288WARNING:tensorflow:6 out of the last 18 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb581d14430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.9462 - val_loss: 0.0066\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.3444 - val_loss: 0.0089\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb56c9985e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_248 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6914WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb568a3be50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.4816 - val_loss: 0.0113\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1850 - val_loss: 0.0072\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1377 - val_loss: 0.0075\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb584912160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_249 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.7124WARNING:tensorflow:6 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb56a4bf4c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.5277 - val_loss: 0.0525\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.2993 - val_loss: 0.0306\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1488 - val_loss: 0.0240\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1304 - val_loss: 0.0288\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5812abb80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_250 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.7063WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb594e03550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 1.3917 - val_loss: 0.0505\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5234 - val_loss: 0.0199\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.2132 - val_loss: 0.0105\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0994 - val_loss: 0.0077\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0761 - val_loss: 0.0069\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0560 - val_loss: 0.0067\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0466 - val_loss: 0.0066\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0408 - val_loss: 0.0066\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5702e15e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_251 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 1.2533 - val_loss: 0.3745\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6820 - val_loss: 0.2195\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3245 - val_loss: 0.1299\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1157 - val_loss: 0.0693\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1176 - val_loss: 0.0371\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1003 - val_loss: 0.0211\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0704 - val_loss: 0.0162\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0602 - val_loss: 0.0156\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0434 - val_loss: 0.0151\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0361 - val_loss: 0.0153\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb570232430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_252 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.5447 - val_loss: 0.0103\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1106 - val_loss: 0.0075\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1040 - val_loss: 0.0078\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5703f0e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_253 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 1.1615 - val_loss: 0.0201\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3100 - val_loss: 0.0290\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb56e2bf0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_254 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 1.1982 - val_loss: 0.0258\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6085 - val_loss: 0.0235\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2501 - val_loss: 0.0184\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1422 - val_loss: 0.0132\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0909 - val_loss: 0.0097\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0509 - val_loss: 0.0082\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0439 - val_loss: 0.0077\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0384 - val_loss: 0.0075\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0568 - val_loss: 0.0077\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb57384ec10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_255 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 0.3027 - val_loss: 0.1009\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0827 - val_loss: 0.0815\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0700 - val_loss: 0.0624\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0548 - val_loss: 0.0550\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0307 - val_loss: 0.0529\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0262 - val_loss: 0.0463\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0203 - val_loss: 0.0364\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0261 - val_loss: 0.0291\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0225 - val_loss: 0.0286\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0166 - val_loss: 0.0302\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb581d14d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_256 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.4981 - val_loss: 0.0223\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2083 - val_loss: 0.0238\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5728b5040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_257 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 0.8329 - val_loss: 0.0469\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.7129 - val_loss: 0.0577\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb56c6743a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_258 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.7753 - val_loss: 0.0105\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5718 - val_loss: 0.0093\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3142 - val_loss: 0.0098\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5812ab1f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_259 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2377WARNING:tensorflow:5 out of the last 18 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb5849121f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.2233 - val_loss: 0.0332\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1447 - val_loss: 0.0383\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb56b4c4a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_260 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.3596WARNING:tensorflow:6 out of the last 20 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb56c6e84c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 0.3302 - val_loss: 0.0099\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1712 - val_loss: 0.0159\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb56bd4c3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_261 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5673WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb56c8f5ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.4596 - val_loss: 0.0120\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2057 - val_loss: 0.0265\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5812148b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_262 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0098WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb5766ba4c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.7898 - val_loss: 0.0118\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2007 - val_loss: 0.0501\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb575b81820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_263 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5553WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb5729105e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6116 - val_loss: 0.0111\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2283 - val_loss: 0.0085\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.1549 - val_loss: 0.0078\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0840 - val_loss: 0.0082\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb573f38a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_264 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.7255WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb577775d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.7283 - val_loss: 0.0705\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.3249 - val_loss: 0.0648\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1058 - val_loss: 0.0696\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5778bc4c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_265 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6002WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb5812ab940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.4352 - val_loss: 0.0173\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.2158 - val_loss: 0.0201\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb56bb591f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_266 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2557WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb574afb4c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 1.1485 - val_loss: 0.0156\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4455 - val_loss: 0.0106\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.2135 - val_loss: 0.0077\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1465 - val_loss: 0.0076\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0788 - val_loss: 0.0103\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb575b81430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_267 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 1.0244 - val_loss: 0.0359\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5556 - val_loss: 0.0095\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3239 - val_loss: 0.0067\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1851 - val_loss: 0.0067\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1001 - val_loss: 0.0068\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb56c624820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_268 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 0.6109 - val_loss: 0.0127\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0969 - val_loss: 0.0262\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb586f063a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_269 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.4780 - val_loss: 0.0560\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1852 - val_loss: 0.0565\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb581d6a820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_270 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.3280WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb56abbfca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.9939 - val_loss: 0.1799\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2974 - val_loss: 0.1716\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.1374 - val_loss: 0.1755\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb572091dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_271 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5779WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb585d80f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.4787 - val_loss: 0.0566\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.1918 - val_loss: 0.0503\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1505 - val_loss: 0.0482\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0775 - val_loss: 0.0469\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0565 - val_loss: 0.0459\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0471 - val_loss: 0.0479\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb56bc17b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_272 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 210ms/step - loss: 0.6191 - val_loss: 0.0820\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2501 - val_loss: 0.0561\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0943 - val_loss: 0.0423\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0430 - val_loss: 0.0356\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0361 - val_loss: 0.0355\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0323 - val_loss: 0.0388\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb572916160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_273 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 0.8365 - val_loss: 0.0388\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2454 - val_loss: 0.0445\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb572eb59d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_274 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 0.4052 - val_loss: 0.0556\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1472 - val_loss: 0.0526\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0809 - val_loss: 0.0578\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb57c111e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_275 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 1.3953 - val_loss: 0.1406\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4811 - val_loss: 0.0883\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1889 - val_loss: 0.0537\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1992 - val_loss: 0.0343\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2186 - val_loss: 0.0307\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1552 - val_loss: 0.0331\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb56e0bd3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_276 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 0.3548 - val_loss: 0.0819\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0973 - val_loss: 0.0514\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0767 - val_loss: 0.0361\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0574 - val_loss: 0.0360\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0623 - val_loss: 0.0401\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb570201c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_277 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.3216 - val_loss: 0.1195\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1074 - val_loss: 0.0156\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0542 - val_loss: 0.1516\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb57384eee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_278 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 1.6191 - val_loss: 0.0356\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.7831 - val_loss: 0.0253\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3643 - val_loss: 0.0166\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1575 - val_loss: 0.0125\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1346 - val_loss: 0.0116\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0893 - val_loss: 0.0131\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb56f772700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_279 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 1.6305 - val_loss: 0.0364\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.7834 - val_loss: 0.0494\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5818063a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_280 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 0.2252 - val_loss: 0.0357\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2085 - val_loss: 0.0292\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0829 - val_loss: 0.0212\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0676 - val_loss: 0.0171\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0507 - val_loss: 0.0148\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0269 - val_loss: 0.0134\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0290 - val_loss: 0.0122\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0202 - val_loss: 0.0116\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0250 - val_loss: 0.0115\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0175 - val_loss: 0.0115\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0166 - val_loss: 0.0117\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb56c6e8940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_281 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 1.0569 - val_loss: 0.1263\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4747 - val_loss: 0.0503\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2608 - val_loss: 0.0217\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.1681 - val_loss: 0.0131\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1390 - val_loss: 0.0128\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0898 - val_loss: 0.0130\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb574afb700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_282 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 1.6492 - val_loss: 0.0125\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7567 - val_loss: 0.0185\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb56b411dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_283 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 0.5597 - val_loss: 0.0542\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1888 - val_loss: 0.0316\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1029 - val_loss: 0.0200\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0798 - val_loss: 0.0140\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0612 - val_loss: 0.0123\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0567 - val_loss: 0.0130\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb557ea59d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_284 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.4704 - val_loss: 0.0200\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3278 - val_loss: 0.0141\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1074 - val_loss: 0.0132\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0525 - val_loss: 0.0134\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb559bea4c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_285 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.2592 - val_loss: 0.0486\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0589 - val_loss: 0.0428\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0535 - val_loss: 0.0415\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0471 - val_loss: 0.0416\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb55c01f0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_286 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 0.5833 - val_loss: 0.0436\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2011 - val_loss: 0.0391\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1114 - val_loss: 0.0317\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0894 - val_loss: 0.0233\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0451 - val_loss: 0.0183\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0390 - val_loss: 0.0147\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0306 - val_loss: 0.0130\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0249 - val_loss: 0.0126\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0171 - val_loss: 0.0126\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0134 - val_loss: 0.0127\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5729fe5e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_287 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 0.6405 - val_loss: 0.0142\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1822 - val_loss: 0.0145\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb559aa5940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_288 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 1.2462 - val_loss: 0.0323\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4341 - val_loss: 0.0148\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2193 - val_loss: 0.0127\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1492 - val_loss: 0.0196\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5778bca60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_289 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.6355 - val_loss: 0.0600\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2049 - val_loss: 0.0662\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb574afb1f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_290 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0930WARNING:tensorflow:5 out of the last 19 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb56c998700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.9773 - val_loss: 0.0366\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2502 - val_loss: 0.0415\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5808eb9d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_291 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.5206WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb5702e18b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 1.2011 - val_loss: 0.0220\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6974 - val_loss: 0.0424\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb56c674430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_292 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.9640WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb5702325e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.7519 - val_loss: 0.1555\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2618 - val_loss: 0.1216\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0771 - val_loss: 0.0845\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0561 - val_loss: 0.0591\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0865 - val_loss: 0.0538\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0744 - val_loss: 0.0662\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb57384eca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_293 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 0.9561 - val_loss: 0.0481\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1834 - val_loss: 0.0408\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0700 - val_loss: 0.0365\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0730 - val_loss: 0.0341\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0717 - val_loss: 0.0334\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0521 - val_loss: 0.0337\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb572d95af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_294 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 1.2489 - val_loss: 0.2139\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.3449 - val_loss: 0.2996\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb572dd2670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_295 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6273 - val_loss: 0.0522\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2430 - val_loss: 0.0411\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1207 - val_loss: 0.0233\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0949 - val_loss: 0.0161\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0680 - val_loss: 0.0141\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0481 - val_loss: 0.0141\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb57a8179d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_296 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 1.1085 - val_loss: 0.1246\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2959 - val_loss: 0.1042\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1015 - val_loss: 0.0811\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0764 - val_loss: 0.0640\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0829 - val_loss: 0.0551\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0688 - val_loss: 0.0515\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0344 - val_loss: 0.0489\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0336 - val_loss: 0.0494\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb55c920430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_297 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 0.2141 - val_loss: 0.1452\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0537 - val_loss: 0.0822\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0595 - val_loss: 0.0718\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0437 - val_loss: 0.0772\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5808eb820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_298 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.9961 - val_loss: 0.1638\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4603 - val_loss: 0.1089\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2095 - val_loss: 0.0616\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1287 - val_loss: 0.0370\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0866 - val_loss: 0.0192\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0602 - val_loss: 0.0108\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0442 - val_loss: 0.0081\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0311 - val_loss: 0.0079\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0337 - val_loss: 0.0087\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb557ea5ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_299 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.8591 - val_loss: 0.0138\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2524 - val_loss: 0.0118\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1063 - val_loss: 0.0154\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb572d95d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_300 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.9133 - val_loss: 0.0719\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2837 - val_loss: 0.0836\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb570232550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_301 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.5528 - val_loss: 0.0705\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1408 - val_loss: 0.0590\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0606 - val_loss: 0.0567\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0508 - val_loss: 0.0537\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0373 - val_loss: 0.0509\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0238 - val_loss: 0.0483\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0188 - val_loss: 0.0472\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0170 - val_loss: 0.0474\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb581d6a820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_302 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 3.7409 - val_loss: 1.2234\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.4718 - val_loss: 0.9677\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7209 - val_loss: 0.7030\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3322 - val_loss: 0.4827\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1581 - val_loss: 0.2828\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1145 - val_loss: 0.1524\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1097 - val_loss: 0.0759\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0991 - val_loss: 0.0378\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0870 - val_loss: 0.0218\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0637 - val_loss: 0.0145\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0499 - val_loss: 0.0112\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0360 - val_loss: 0.0095\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0289 - val_loss: 0.0082\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0273 - val_loss: 0.0073\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0215 - val_loss: 0.0068\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0191 - val_loss: 0.0066\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0155 - val_loss: 0.0066\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0174 - val_loss: 0.0067\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb56c8f59d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_303 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 167ms/step - loss: 0.7585 - val_loss: 0.0236\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3422 - val_loss: 0.0159\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1486 - val_loss: 0.0086\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1107 - val_loss: 0.0054\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0783 - val_loss: 0.0049\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0769 - val_loss: 0.0049\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0560 - val_loss: 0.0050\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5778bc310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_304 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.4587 - val_loss: 0.1764\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2026 - val_loss: 0.1622\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1517 - val_loss: 0.1308\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0936 - val_loss: 0.1127\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0466 - val_loss: 0.0979\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0334 - val_loss: 0.0784\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0308 - val_loss: 0.0639\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0239 - val_loss: 0.0593\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0320 - val_loss: 0.0603\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb572091f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_305 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 0.4578 - val_loss: 0.1089\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2459 - val_loss: 0.0812\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1177 - val_loss: 0.0633\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0738 - val_loss: 0.0546\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1011 - val_loss: 0.0497\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0656 - val_loss: 0.0488\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0469 - val_loss: 0.0503\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb55c01faf0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_306 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.8160 - val_loss: 0.0359\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2712 - val_loss: 0.0623\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb55a24eca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_307 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 0.8230 - val_loss: 0.0510\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2638 - val_loss: 0.0347\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.1188 - val_loss: 0.0269\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1224 - val_loss: 0.0297\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb55de3c1f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_308 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 1.0821 - val_loss: 0.0837\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3999 - val_loss: 0.0654\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1778 - val_loss: 0.0516\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1209 - val_loss: 0.0497\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0895 - val_loss: 0.0536\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb55fe0f9d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_309 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.4771 - val_loss: 0.1265\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1315 - val_loss: 0.1312\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb570232310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_310 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 1.7735 - val_loss: 0.1010\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5938 - val_loss: 0.0397\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1885 - val_loss: 0.0133\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1049 - val_loss: 0.0067\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1116 - val_loss: 0.0062\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0829 - val_loss: 0.0061\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0443 - val_loss: 0.0070\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb559c18e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_311 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.4409 - val_loss: 0.1187\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1586 - val_loss: 0.0938\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1143 - val_loss: 0.0727\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0802 - val_loss: 0.0522\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0683 - val_loss: 0.0400\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0538 - val_loss: 0.0443\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb573dc6b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_312 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 1.1967 - val_loss: 0.0751\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4267 - val_loss: 0.0920\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5778bc8b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_313 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 0.3531 - val_loss: 0.1492\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1409 - val_loss: 0.0998\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0659 - val_loss: 0.0763\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0599 - val_loss: 0.0696\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0235 - val_loss: 0.0619\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0160 - val_loss: 0.0539\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0165 - val_loss: 0.0455\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0153 - val_loss: 0.0385\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0108 - val_loss: 0.0320\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0104 - val_loss: 0.0271\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0095 - val_loss: 0.0233\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0088 - val_loss: 0.0208\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0089 - val_loss: 0.0196\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0166 - val_loss: 0.0189\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0056 - val_loss: 0.0187\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0073 - val_loss: 0.0191\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb56c8f5ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_314 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.1179 - val_loss: 0.0508\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0320 - val_loss: 0.0397\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0274 - val_loss: 0.0264\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0153 - val_loss: 0.0197\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0119 - val_loss: 0.0147\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0122 - val_loss: 0.0128\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0094 - val_loss: 0.0114\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0070 - val_loss: 0.0109\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0080 - val_loss: 0.0110\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5702e1c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_315 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 0.4303 - val_loss: 0.0890\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1527 - val_loss: 0.1023\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb572916160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_316 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 1.7361 - val_loss: 0.0713\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.8605 - val_loss: 0.0441\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5101 - val_loss: 0.0336\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.2181 - val_loss: 0.0311\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1181 - val_loss: 0.0286\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1424 - val_loss: 0.0246\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1065 - val_loss: 0.0222\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0964 - val_loss: 0.0194\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0744 - val_loss: 0.0181\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0525 - val_loss: 0.0177\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0406 - val_loss: 0.0178\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb557ea5550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_317 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 0.5776 - val_loss: 0.0303\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2672 - val_loss: 0.0224\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0894 - val_loss: 0.0179\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0840 - val_loss: 0.0162\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0636 - val_loss: 0.0156\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0463 - val_loss: 0.0155\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0573 - val_loss: 0.0163\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb55c920820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_318 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.7362 - val_loss: 0.2137\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2862 - val_loss: 0.0777\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1505 - val_loss: 0.0310\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.1226 - val_loss: 0.0263\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0704 - val_loss: 0.0372\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb55d5778b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_319 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 1.3639 - val_loss: 0.1591\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3791 - val_loss: 0.1379\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1949 - val_loss: 0.1200\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0749 - val_loss: 0.1019\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0694 - val_loss: 0.0921\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0521 - val_loss: 0.0923\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb55d8c7160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_320 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.4500 - val_loss: 0.2048\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1633 - val_loss: 0.1275\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1135 - val_loss: 0.0820\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1027 - val_loss: 0.0533\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0963 - val_loss: 0.0505\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0486 - val_loss: 0.0491\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0323 - val_loss: 0.0489\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0263 - val_loss: 0.0460\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0348 - val_loss: 0.0405\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0207 - val_loss: 0.0373\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0150 - val_loss: 0.0356\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0174 - val_loss: 0.0342\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0174 - val_loss: 0.0330\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0147 - val_loss: 0.0323\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0153 - val_loss: 0.0318\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0154 - val_loss: 0.0312\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0092 - val_loss: 0.0303\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0108 - val_loss: 0.0294\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0091 - val_loss: 0.0286\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0084 - val_loss: 0.0282\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0081 - val_loss: 0.0282\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5612a7c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_321 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 0.7000 - val_loss: 0.0347\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2049 - val_loss: 0.0429\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb55c873280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_322 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.4473 - val_loss: 0.0645\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1109 - val_loss: 0.0646\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb55d568af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_323 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.7236 - val_loss: 0.0898\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2747 - val_loss: 0.0807\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2627 - val_loss: 0.0675\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1050 - val_loss: 0.0521\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0817 - val_loss: 0.0432\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0715 - val_loss: 0.0363\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0477 - val_loss: 0.0340\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0346 - val_loss: 0.0343\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb56c4db5e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_324 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.4333 - val_loss: 0.0614\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1763 - val_loss: 0.0515\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0629 - val_loss: 0.0449\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0386 - val_loss: 0.0393\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0418 - val_loss: 0.0354\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0275 - val_loss: 0.0344\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0300 - val_loss: 0.0340\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0210 - val_loss: 0.0340\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0189 - val_loss: 0.0343\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5703ba310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_325 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 0.2600 - val_loss: 0.0434\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0880 - val_loss: 0.0423\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0423 - val_loss: 0.0411\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0353 - val_loss: 0.0415\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb575b81820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_326 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.3847 - val_loss: 0.0814\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2385 - val_loss: 0.1000\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb57772c280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_327 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 0.4410 - val_loss: 0.0366\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1772 - val_loss: 0.0360\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0798 - val_loss: 0.0371\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb55a24e310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_328 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2759WARNING:tensorflow:5 out of the last 19 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb559987940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 0.2431 - val_loss: 0.0386\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0972 - val_loss: 0.0531\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5808eb700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_329 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6060WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb55c01f5e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.5471 - val_loss: 0.0489\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1718 - val_loss: 0.0562\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb55debc3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_330 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5099WARNING:tensorflow:6 out of the last 14 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb55ee9a670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 156ms/step - loss: 0.4017 - val_loss: 0.0372\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1520 - val_loss: 0.0348\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0609 - val_loss: 0.0355\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb55a7b23a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_331 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6675WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb55e9d60d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 0.4538 - val_loss: 0.0545\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.1223 - val_loss: 0.0611\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb55ec259d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_332 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6074WARNING:tensorflow:6 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb56213e310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.5369 - val_loss: 0.0466\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1727 - val_loss: 0.0454\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1222 - val_loss: 0.0447\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0675 - val_loss: 0.0407\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0753 - val_loss: 0.0398\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0539 - val_loss: 0.0395\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0306 - val_loss: 0.0397\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb55ecb1dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_333 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.7121 - val_loss: 0.0395\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.2636 - val_loss: 0.0425\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb55e9d6940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_334 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.7090 - val_loss: 0.0364\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2065 - val_loss: 0.0350\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1639 - val_loss: 0.0365\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb55c01f0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_335 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 2.3369 - val_loss: 0.0413\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.0958 - val_loss: 0.0456\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb56a4bfdc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_336 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 3.1638WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb56e0bd1f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 2.3403 - val_loss: 0.0387\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.0979 - val_loss: 0.0379\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5498 - val_loss: 0.0371\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2767 - val_loss: 0.0388\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb57779aee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_337 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.7079WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb56c6245e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.5324 - val_loss: 0.0434\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1986 - val_loss: 0.0489\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5924c1040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_338 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.8288WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb570201a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.7604 - val_loss: 0.0388\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2022 - val_loss: 0.0379\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1090 - val_loss: 0.0386\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb579a73af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_339 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.9541WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb57c111c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 122ms/step - loss: 0.7263 - val_loss: 0.0402\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2882 - val_loss: 0.0406\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb57781b550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_340 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4731WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb55d8c7d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.3610 - val_loss: 0.0345\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1329 - val_loss: 0.0411\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb573dc6e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_341 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.7068WARNING:tensorflow:6 out of the last 14 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb5601948b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 1.3291 - val_loss: 0.0435\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4072 - val_loss: 0.0542\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb55c873670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_342 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.8207WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb55c189670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 0.7641 - val_loss: 0.0356\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2630 - val_loss: 0.0346\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0921 - val_loss: 0.0348\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb56111e040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_343 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2557WARNING:tensorflow:6 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb561514280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.1987 - val_loss: 0.0328\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0775 - val_loss: 0.0345\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb56159b040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_344 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6919WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb5637453a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.5346 - val_loss: 0.0427\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1349 - val_loss: 0.0415\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0630 - val_loss: 0.0410\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0516 - val_loss: 0.0428\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb563a97b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_345 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.7120WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb55ba18790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 0.5989 - val_loss: 0.0332\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2120 - val_loss: 0.0365\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb56159b790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_346 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.3807WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb55e987af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.9160 - val_loss: 0.0474\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1604 - val_loss: 0.0400\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1026 - val_loss: 0.0347\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0795 - val_loss: 0.0335\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0686 - val_loss: 0.0324\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0526 - val_loss: 0.0321\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0456 - val_loss: 0.0323\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb55b144c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_347 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 0.8015 - val_loss: 0.0356\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5091 - val_loss: 0.0359\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb55d8c7550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_348 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 1.4151 - val_loss: 0.0351\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7063 - val_loss: 0.0430\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb56bc7c040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_349 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.2428 - val_loss: 0.0339\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0694 - val_loss: 0.0366\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5703baca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_350 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0939WARNING:tensorflow:5 out of the last 14 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb5778bcf70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.9266 - val_loss: 0.0522\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.3650 - val_loss: 0.0349\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1519 - val_loss: 0.0328\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0877 - val_loss: 0.0375\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb57772cb80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_351 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2465WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb557c910d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 1.0397 - val_loss: 0.0362\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.3669 - val_loss: 0.0407\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb559987e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_352 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2708WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb55c01f9d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.9573 - val_loss: 0.1487\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3177 - val_loss: 0.1570\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb560738d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_353 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5926WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb55ecb1b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.5107 - val_loss: 0.0346\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2027 - val_loss: 0.0352\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb55ec251f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_354 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6005WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb5621c50d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.5464 - val_loss: 0.0431\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2414 - val_loss: 0.0438\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5621c5e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_355 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6120WARNING:tensorflow:6 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb56060b0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.6893 - val_loss: 0.0351\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2186 - val_loss: 0.0340\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1553 - val_loss: 0.0345\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5617b2700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_356 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4494WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb5625a6550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.4084 - val_loss: 0.0336\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1100 - val_loss: 0.0338\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5630f8b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_357 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5406WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb566aad670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 0.4236 - val_loss: 0.0326\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2434 - val_loss: 0.0318\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1028 - val_loss: 0.0319\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb566efb5e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_358 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.3480WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb5625a6ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 160ms/step - loss: 0.3466 - val_loss: 0.0350\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2132 - val_loss: 0.0345\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.1007 - val_loss: 0.0342\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0621 - val_loss: 0.0358\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb562445040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_359 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2683WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb55c6daa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.3452 - val_loss: 0.0838\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1332 - val_loss: 0.1183\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5651ce1f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_360 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.9822WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb55e9d63a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.8367 - val_loss: 0.0355\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2850 - val_loss: 0.0561\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb55a7b2790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_361 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.7506WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb55de3cc10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 2.2792 - val_loss: 0.1931\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6828 - val_loss: 0.1536\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.2757 - val_loss: 0.1350\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1904 - val_loss: 0.1249\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1436 - val_loss: 0.1190\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1089 - val_loss: 0.1176\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0842 - val_loss: 0.1184\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb557c91940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_362 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 0.3502 - val_loss: 0.0291\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1222 - val_loss: 0.0301\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5778bc0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_363 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 1.0262 - val_loss: 0.0344\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3677 - val_loss: 0.0294\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1629 - val_loss: 0.0300\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb557c49940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_364 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.9948 - val_loss: 0.0352\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4759 - val_loss: 0.0288\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.1552 - val_loss: 0.0285\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0797 - val_loss: 0.0297\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb55d30f940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_365 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.9013WARNING:tensorflow:5 out of the last 17 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb560194280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 0.7554 - val_loss: 0.0744\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2668 - val_loss: 0.0854\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb56111eb80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_366 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6501WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb55a2c1f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.5772 - val_loss: 0.0320\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2148 - val_loss: 0.0400\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5702e1040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_367 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.7809WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb5622683a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.7508 - val_loss: 0.0349\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3138 - val_loss: 0.0318\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1455 - val_loss: 0.0321\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb55c1b69d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_368 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.3005WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb561067ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 1.1864 - val_loss: 0.0298\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2856 - val_loss: 0.0334\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb56304ed30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_369 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.3659WARNING:tensorflow:6 out of the last 14 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb5637f9e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.2997 - val_loss: 0.0294\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1724 - val_loss: 0.0287\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0630 - val_loss: 0.0306\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb564f53790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_370 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6750WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb547f3b1f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 0.6975 - val_loss: 0.0283\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3294 - val_loss: 0.0305\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb54979f040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_371 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1819WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb55debc790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 1.0172 - val_loss: 0.0381\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4172 - val_loss: 0.0449\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb560738820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_372 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4055WARNING:tensorflow:6 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb55a76baf0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 0.3349 - val_loss: 0.0334\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1610 - val_loss: 0.0350\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb55c7beb80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_373 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4276WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb5924c18b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.3487 - val_loss: 0.0339\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.1469 - val_loss: 0.0387\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb55ebb6040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_374 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.0137WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb56015c700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 1.8240 - val_loss: 0.0297\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7456 - val_loss: 0.0274\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.3442 - val_loss: 0.0283\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb5601f69d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_375 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.4523WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb57c1119d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 1.0865 - val_loss: 0.0330\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.3944 - val_loss: 0.0322\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3733 - val_loss: 0.0329\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb572916550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_376 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5464WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb57779aca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 0.4229 - val_loss: 0.0436\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1934 - val_loss: 0.0352\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.1017 - val_loss: 0.0334\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0886 - val_loss: 0.0325\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0578 - val_loss: 0.0319\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0455 - val_loss: 0.0317\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0475 - val_loss: 0.0318\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb55a0bbe50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_377 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 1.6880 - val_loss: 0.0311\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.7956 - val_loss: 0.0289\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.3627 - val_loss: 0.0284\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2012 - val_loss: 0.0299\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb560709040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_378 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 0.6394 - val_loss: 0.0249\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2640 - val_loss: 0.0268\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb55ec259d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_379 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.7649 - val_loss: 0.0265\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2516 - val_loss: 0.0273\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb586f06dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layer layer_normalization_380 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss = []\n",
    "preds = []\n",
    "seed(1)\n",
    "for retrain_idx in range(552):\n",
    "    X = Xl.iloc[t_train_start[retrain_idx]:t_train_end[retrain_idx],:]\n",
    "    X_idx = X.apply(pd.Series.nunique) != 1\n",
    "    X = X.loc[:,X_idx]\n",
    "    X_val = Xl.loc[t_val_start[retrain_idx]:t_val_end[retrain_idx],X_idx]\n",
    "    X_test = Xl.loc[t_test_start[retrain_idx]:t_test_end[retrain_idx],X_idx]\n",
    "    y = y_agg.iloc[t_train_start[retrain_idx]:t_train_end[retrain_idx],:]\n",
    "    y_val = y_agg.loc[t_val_start[retrain_idx]:t_val_end[retrain_idx],:]\n",
    "    y_test = y_agg.loc[t_test_start[retrain_idx]:t_test_end[retrain_idx],:]\n",
    "    model = Sequential()\n",
    "    model.add(LayerNormalization())\n",
    "    model.add(Dense(16,activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(16,activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(16,activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(16,activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(16,activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(16,activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    optimizer = Adam(learning_rate=0.005)\n",
    "    model.compile(optimizer=optimizer,loss='mse')\n",
    "    early_stop = EarlyStopping(monitor='val_loss', verbose=0, patience=1)\n",
    "    history = model.fit(x=X,y=y,validation_data=(X_val,y_val), batch_size=64, epochs=60,verbose=1,callbacks=[early_stop])\n",
    "    preds.append(model.predict(X_test))\n",
    "    loss.append(min(history.history['val_loss']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_org = y_agg.loc[t_test_start[0]:t_test_end[551],:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate R^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1-np.sum((np.squeeze(y_org)-np.squeeze(preds))**2)/np.sum((y_org-np.mean(y_org))**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A good R^2 is expected to be between 0 to 0.05."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Finance.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
